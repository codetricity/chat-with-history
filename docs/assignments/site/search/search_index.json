{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FastOpp UI Development Assignments","text":"<p>Welcome to the comprehensive guide for building modern UI interfaces for FastOpp using various frameworks and technologies.</p>"},{"location":"#what-youll-learn","title":"\ud83d\ude80 What You'll Learn","text":"<p>This documentation provides step-by-step assignments for creating alternative interfaces to the default FastOpp system, covering:</p> <ul> <li>Modern UI Frameworks - React, Flutter, Vue.js</li> <li>Mobile-First Design - Touch-optimized interfaces</li> <li>Collaborative Features - Real-time team collaboration</li> <li>Advanced Topics - Data processing, ML pipelines, search algorithms</li> </ul>"},{"location":"#assignment-tracks","title":"\ud83d\udcda Assignment Tracks","text":""},{"location":"#1-react-modern-ui","title":"1. React Modern UI","text":"<p>Build a sophisticated React application with component-based architecture, advanced state management, and real-time updates.</p>"},{"location":"#2-flutter-web-app","title":"2. Flutter Web App","text":"<p>Create a cross-platform Flutter web app with Material Design 3, smooth animations, and offline-first architecture.</p>"},{"location":"#3-vuejs-dashboard","title":"3. Vue.js Dashboard","text":"<p>Develop a lightweight, reactive Vue.js dashboard with Composition API and TypeScript support.</p>"},{"location":"#4-mobile-first-design","title":"4. Mobile-First Design","text":"<p>Design touch-optimized interfaces with Progressive Web App features and gesture-based navigation.</p>"},{"location":"#5-collaborative-workspace","title":"5. Collaborative Workspace","text":"<p>Build real-time team collaboration features with WebSocket integration and shared workspaces.</p>"},{"location":"#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<p>Before starting any assignment, make sure you have:</p> <ul> <li>Basic understanding of the FastOpp API structure</li> <li>Familiarity with your chosen UI framework</li> <li>Understanding of REST APIs and authentication</li> <li>Design thinking for user experience</li> <li>Problem-solving mindset for unique use cases</li> </ul>"},{"location":"#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<p>By completing these assignments, you'll develop skills in:</p> <ul> <li>API Integration - Connect frontend to FastAPI backend</li> <li>State Management - Handle complex conversation data</li> <li>User Experience Design - Create intuitive interfaces</li> <li>Responsive Design - Build for multiple screen sizes</li> <li>Performance Optimization - Efficient data loading and rendering</li> </ul>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<ol> <li>Explore the API - Test endpoints with Postman/curl</li> <li>Choose your track - Pick the UI framework you want to learn</li> <li>Set up your environment - Install tools and dependencies</li> <li>Study the data models - Understand conversation structure</li> <li>Start with wireframes - Plan your interface before coding</li> </ol>"},{"location":"#documentation-structure","title":"\ud83d\udcd6 Documentation Structure","text":"<ul> <li>Getting Started - Overview and prerequisites</li> <li>UI Development Tracks - Detailed assignments for each framework</li> <li>Advanced Topics - Data processing, ML, and search algorithms</li> </ul>"},{"location":"#additional-resources","title":"Additional Resources","text":"<p>For additional learning materials and slides, please check the main project documentation in the parent directory.</p>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>We welcome contributions! If you have improvements, additional assignments, or bug fixes, please:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Submit a pull request</li> </ol>"},{"location":"#support","title":"\ud83d\udcde Support","text":"<p>Need help? Check out our:</p> <ul> <li>GitHub Issues</li> <li>Discord Community</li> <li>Documentation</li> </ul> <p>Ready to start building? Choose your track and let's create something amazing! \ud83d\ude80</p>"},{"location":"01_ui_development_overview/","title":"Overview","text":""},{"location":"01_ui_development_overview/#ui-development-assignments","title":"UI Development Assignments","text":""},{"location":"01_ui_development_overview/#building-alternative-interfaces-for-fastopp","title":"Building Alternative Interfaces for FastOpp","text":"<p>Create Modern UIs with React, Flutter, Vue, and More</p>"},{"location":"01_ui_development_overview/#assignment-overview","title":"Assignment Overview","text":""},{"location":"01_ui_development_overview/#what-youll-build","title":"What You'll Build","text":"<ul> <li>Alternative conversation browsers using different UI frameworks</li> <li>Custom organization systems tailored to specific use cases</li> <li>Mobile-first interfaces for on-the-go access</li> <li>Collaborative workspaces for team environments</li> <li>Specialized dashboards for different business needs</li> </ul>"},{"location":"01_ui_development_overview/#the-challenge","title":"The Challenge","text":""},{"location":"01_ui_development_overview/#beyond-the-default-ui","title":"Beyond the Default UI","text":"<p>The current FastOpp system provides a solid foundation with: - FastAPI backend with comprehensive APIs - Business context integration (clients, projects, folders) - Advanced search capabilities (hybrid search, filtering) - Authentication system with user management</p> <p>Your mission: Create better, more specialized UIs that leverage these APIs.</p>"},{"location":"01_ui_development_overview/#assignment-structure","title":"Assignment Structure","text":""},{"location":"01_ui_development_overview/#5-ui-development-tracks","title":"5 UI Development Tracks","text":"<ol> <li>React Modern UI - Component-based conversation management</li> <li>Flutter Web App - Cross-platform responsive design</li> <li>Vue.js Dashboard - Lightweight, reactive interface</li> <li>Mobile-First Design - Touch-optimized conversation browser</li> <li>Collaborative Workspace - Real-time team collaboration features</li> </ol>"},{"location":"01_ui_development_overview/#prerequisites","title":"Prerequisites","text":""},{"location":"01_ui_development_overview/#what-you-need","title":"What You Need","text":"<ul> <li>Basic understanding of the FastOpp API structure</li> <li>Familiarity with your chosen UI framework</li> <li>Understanding of REST APIs and authentication</li> <li>Design thinking for user experience</li> <li>Problem-solving mindset for unique use cases</li> </ul>"},{"location":"01_ui_development_overview/#learning-objectives","title":"Learning Objectives","text":""},{"location":"01_ui_development_overview/#skills-youll-develop","title":"Skills You'll Develop","text":"<ul> <li>API Integration - Connect frontend to FastAPI backend</li> <li>State Management - Handle complex conversation data</li> <li>User Experience Design - Create intuitive interfaces</li> <li>Responsive Design - Build for multiple screen sizes</li> <li>Performance Optimization - Efficient data loading and rendering</li> </ul>"},{"location":"01_ui_development_overview/#assignment-framework","title":"Assignment Framework","text":""},{"location":"01_ui_development_overview/#each-assignment-includes","title":"Each Assignment Includes","text":"<ol> <li>Problem Statement - Specific UI challenge to solve</li> <li>API Requirements - Which endpoints you'll need</li> <li>Design Specifications - UI/UX requirements</li> <li>Technical Requirements - Framework and tools</li> <li>Success Criteria - How to measure completion</li> <li>Bonus Challenges - Advanced features to implement</li> </ol>"},{"location":"01_ui_development_overview/#getting-started","title":"Getting Started","text":""},{"location":"01_ui_development_overview/#first-steps","title":"First Steps","text":"<ol> <li>Explore the API - Test endpoints with Postman/curl</li> <li>Choose your track - Pick the UI framework you want to learn</li> <li>Set up your environment - Install tools and dependencies</li> <li>Study the data models - Understand conversation structure</li> <li>Start with wireframes - Plan your interface before coding</li> </ol>"},{"location":"01_ui_development_overview/#api-endpoints-overview","title":"API Endpoints Overview","text":""},{"location":"01_ui_development_overview/#core-endpoints-youll-use","title":"Core Endpoints You'll Use","text":"<pre><code>GET /api/conversations          # List all conversations\nGET /api/folders               # List conversation folders\nGET /api/clients               # List clients\nGET /api/projects              # List projects\nGET /api/search                # Hybrid search conversations\nPOST /api/conversations        # Create new conversation\nPUT /api/conversations/{id}    # Update conversation\nDELETE /api/conversations/{id} # Delete conversation\n</code></pre>"},{"location":"01_ui_development_overview/#authentication","title":"Authentication","text":""},{"location":"01_ui_development_overview/#how-to-authenticate","title":"How to Authenticate","text":"<pre><code>// Include JWT token in requests\nconst headers = {\n  'Authorization': `Bearer ${token}`,\n  'Content-Type': 'application/json'\n}\n\n// Login endpoint\nPOST /api/auth/login\n{\n  \"username\": \"your_username\",\n  \"password\": \"your_password\"\n}\n</code></pre>"},{"location":"01_ui_development_overview/#data-models","title":"Data Models","text":""},{"location":"01_ui_development_overview/#key-data-structures","title":"Key Data Structures","text":"<pre><code>interface Conversation {\n  id: string;\n  title: string;\n  folder_id?: string;\n  created_at: string;\n  updated_at: string;\n  is_active: boolean;\n}\n\ninterface Folder {\n  id: string;\n  name: string;\n  project_id?: string;\n  parent_folder_id?: string;\n  description?: string;\n}\n\ninterface Client {\n  id: string;\n  name: string;\n  company: string;\n  email: string;\n  industry: string;\n}\n</code></pre>"},{"location":"01_ui_development_overview/#design-principles","title":"Design Principles","text":""},{"location":"01_ui_development_overview/#uiux-guidelines","title":"UI/UX Guidelines","text":"<ul> <li>Mobile-first approach - Design for small screens first</li> <li>Accessibility - Follow WCAG guidelines</li> <li>Performance - Optimize for fast loading</li> <li>Consistency - Maintain design system</li> <li>Intuitive navigation - Easy to find and organize conversations</li> </ul>"},{"location":"01_ui_development_overview/#success-metrics","title":"Success Metrics","text":""},{"location":"01_ui_development_overview/#how-to-measure-success","title":"How to Measure Success","text":"<ul> <li>Functionality - All required features work correctly</li> <li>Performance - Fast loading and smooth interactions</li> <li>Usability - Intuitive and easy to use</li> <li>Responsiveness - Works on all screen sizes</li> <li>Code Quality - Clean, maintainable code</li> </ul>"},{"location":"01_ui_development_overview/#next-steps","title":"Next Steps","text":""},{"location":"01_ui_development_overview/#choose-your-track","title":"Choose Your Track","text":"<ol> <li>React Modern UI - For component-based development</li> <li>Flutter Web App - For cross-platform solutions</li> <li>Vue.js Dashboard - For lightweight applications</li> <li>Mobile-First Design - For touch interfaces</li> <li>Collaborative Workspace - For team features</li> </ol> <p>Each track has detailed assignments and examples!</p>"},{"location":"01_ui_development_overview/#lets-build-something-amazing","title":"Let's Build Something Amazing!","text":""},{"location":"01_ui_development_overview/#ready-to-start","title":"Ready to Start?","text":"<p>The best way to learn is by building!</p> <p>Pick your track and start creating interfaces that go beyond what's possible with generic AI chat tools.</p> <p>Let's create the future of conversation management! \ud83d\ude80</p>"},{"location":"02_react_modern_ui/","title":"React Modern UI","text":""},{"location":"02_react_modern_ui/#react-modern-ui-assignment","title":"React Modern UI Assignment","text":""},{"location":"02_react_modern_ui/#component-based-conversation-management","title":"Component-Based Conversation Management","text":"<p>Build a sophisticated React interface for FastOpp</p>"},{"location":"02_react_modern_ui/#assignment-overview","title":"Assignment Overview","text":""},{"location":"02_react_modern_ui/#what-youll-build","title":"What You'll Build","text":"<p>A modern React application that provides an alternative to the default FastOpp UI, focusing on: - Component-based architecture with reusable UI elements - Advanced state management using Redux or Zustand - Real-time updates with WebSocket integration - Drag-and-drop organization using React DnD - Advanced filtering and search with instant results</p>"},{"location":"02_react_modern_ui/#problem-statement","title":"Problem Statement","text":""},{"location":"02_react_modern_ui/#current-ui-limitations","title":"Current UI Limitations","text":"<p>The existing FastOpp UI, while functional, has some limitations: - Monolithic structure - Hard to customize individual components - Limited real-time features - No live updates - Basic drag-and-drop - Limited organization options - Static filtering - No instant search results - Desktop-focused - Not optimized for mobile workflows</p>"},{"location":"02_react_modern_ui/#your-solution","title":"Your Solution","text":""},{"location":"02_react_modern_ui/#react-powered-interface","title":"React-Powered Interface","text":"<p>Create a React application that addresses these limitations:</p> <ol> <li>Modular Components - Reusable conversation cards, folder trees, search bars</li> <li>Real-time Updates - Live conversation updates and collaboration</li> <li>Advanced Organization - Nested drag-and-drop with visual feedback</li> <li>Instant Search - Real-time filtering as you type</li> <li>Mobile-First Design - Touch-optimized for all devices</li> </ol>"},{"location":"02_react_modern_ui/#technical-requirements","title":"Technical Requirements","text":""},{"location":"02_react_modern_ui/#tech-stack","title":"Tech Stack","text":"<ul> <li>React 18+ with TypeScript</li> <li>State Management - Redux Toolkit or Zustand</li> <li>UI Library - Material-UI, Chakra UI, or Tailwind CSS</li> <li>Drag &amp; Drop - React DnD or @dnd-kit</li> <li>HTTP Client - Axios or React Query</li> <li>Routing - React Router v6</li> <li>Build Tool - Vite or Create React App</li> </ul>"},{"location":"02_react_modern_ui/#project-structure","title":"Project Structure","text":""},{"location":"02_react_modern_ui/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>src/\n\u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 ConversationCard/\n\u2502   \u251c\u2500\u2500 FolderTree/\n\u2502   \u251c\u2500\u2500 SearchBar/\n\u2502   \u251c\u2500\u2500 FilterPanel/\n\u2502   \u2514\u2500\u2500 ConversationList/\n\u251c\u2500\u2500 hooks/\n\u2502   \u251c\u2500\u2500 useConversations.ts\n\u2502   \u251c\u2500\u2500 useFolders.ts\n\u2502   \u2514\u2500\u2500 useSearch.ts\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 api.ts\n\u2502   \u2514\u2500\u2500 websocket.ts\n\u251c\u2500\u2500 store/\n\u2502   \u251c\u2500\u2500 conversationSlice.ts\n\u2502   \u2514\u2500\u2500 folderSlice.ts\n\u2514\u2500\u2500 types/\n    \u2514\u2500\u2500 index.ts\n</code></pre>"},{"location":"02_react_modern_ui/#core-components","title":"Core Components","text":""},{"location":"02_react_modern_ui/#1-conversationcard-component","title":"1. ConversationCard Component","text":"<pre><code>interface ConversationCardProps {\n  conversation: Conversation;\n  onEdit: (id: string) =&gt; void;\n  onDelete: (id: string) =&gt; void;\n  onMove: (id: string, folderId: string) =&gt; void;\n  isSelected: boolean;\n  onSelect: (id: string) =&gt; void;\n}\n\nconst ConversationCard: React.FC&lt;ConversationCardProps&gt; = ({\n  conversation,\n  onEdit,\n  onDelete,\n  onMove,\n  isSelected,\n  onSelect\n}) =&gt; {\n  // Component implementation\n};\n</code></pre>"},{"location":"02_react_modern_ui/#core-components_1","title":"Core Components","text":""},{"location":"02_react_modern_ui/#2-foldertree-component","title":"2. FolderTree Component","text":"<pre><code>interface FolderTreeProps {\n  folders: Folder[];\n  onFolderSelect: (folderId: string) =&gt; void;\n  onFolderCreate: (parentId?: string) =&gt; void;\n  onFolderEdit: (folderId: string) =&gt; void;\n  onFolderDelete: (folderId: string) =&gt; void;\n  selectedFolderId?: string;\n}\n\nconst FolderTree: React.FC&lt;FolderTreeProps&gt; = ({\n  folders,\n  onFolderSelect,\n  onFolderCreate,\n  onFolderEdit,\n  onFolderDelete,\n  selectedFolderId\n}) =&gt; {\n  // Hierarchical folder display with drag-and-drop\n};\n</code></pre>"},{"location":"02_react_modern_ui/#state-management","title":"State Management","text":""},{"location":"02_react_modern_ui/#redux-toolkit-setup","title":"Redux Toolkit Setup","text":"<pre><code>// store/conversationSlice.ts\nimport { createSlice, createAsyncThunk } from '@reduxjs/toolkit';\n\ninterface ConversationState {\n  conversations: Conversation[];\n  loading: boolean;\n  error: string | null;\n  selectedConversation: string | null;\n  filters: ConversationFilters;\n}\n\nconst conversationSlice = createSlice({\n  name: 'conversations',\n  initialState,\n  reducers: {\n    setSelectedConversation: (state, action) =&gt; {\n      state.selectedConversation = action.payload;\n    },\n    updateFilters: (state, action) =&gt; {\n      state.filters = { ...state.filters, ...action.payload };\n    }\n  },\n  extraReducers: (builder) =&gt; {\n    // Async thunks for API calls\n  }\n});\n</code></pre>"},{"location":"02_react_modern_ui/#api-integration","title":"API Integration","text":""},{"location":"02_react_modern_ui/#custom-hooks","title":"Custom Hooks","text":"<pre><code>// hooks/useConversations.ts\nexport const useConversations = () =&gt; {\n  const dispatch = useAppDispatch();\n  const { conversations, loading, error } = useAppSelector(\n    (state) =&gt; state.conversations\n  );\n\n  const fetchConversations = useCallback(async () =&gt; {\n    try {\n      dispatch(fetchConversationsStart());\n      const data = await conversationAPI.getAll();\n      dispatch(fetchConversationsSuccess(data));\n    } catch (err) {\n      dispatch(fetchConversationsFailure(err.message));\n    }\n  }, [dispatch]);\n\n  return {\n    conversations,\n    loading,\n    error,\n    fetchConversations\n  };\n};\n</code></pre>"},{"location":"02_react_modern_ui/#real-time-features","title":"Real-time Features","text":""},{"location":"02_react_modern_ui/#websocket-integration","title":"WebSocket Integration","text":"<pre><code>// services/websocket.ts\nclass ConversationWebSocket {\n  private ws: WebSocket | null = null;\n  private reconnectAttempts = 0;\n  private maxReconnectAttempts = 5;\n\n  connect(token: string) {\n    this.ws = new WebSocket(`ws://localhost:8000/ws?token=${token}`);\n\n    this.ws.onmessage = (event) =&gt; {\n      const data = JSON.parse(event.data);\n      this.handleMessage(data);\n    };\n  }\n\n  private handleMessage(data: any) {\n    switch (data.type) {\n      case 'conversation_updated':\n        // Update conversation in store\n        break;\n      case 'conversation_created':\n        // Add new conversation to store\n        break;\n      case 'conversation_deleted':\n        // Remove conversation from store\n        break;\n    }\n  }\n}\n</code></pre>"},{"location":"02_react_modern_ui/#advanced-search","title":"Advanced Search","text":""},{"location":"02_react_modern_ui/#real-time-filtering","title":"Real-time Filtering","text":"<pre><code>// components/SearchBar.tsx\nconst SearchBar: React.FC = () =&gt; {\n  const [searchTerm, setSearchTerm] = useState('');\n  const [debouncedSearchTerm] = useDebounce(searchTerm, 300);\n  const { conversations, setFilteredConversations } = useConversations();\n\n  useEffect(() =&gt; {\n    if (debouncedSearchTerm) {\n      const filtered = conversations.filter(conversation =&gt;\n        conversation.title.toLowerCase().includes(debouncedSearchTerm.toLowerCase())\n      );\n      setFilteredConversations(filtered);\n    } else {\n      setFilteredConversations(conversations);\n    }\n  }, [debouncedSearchTerm, conversations]);\n\n  return (\n    &lt;input\n      type=\"text\"\n      value={searchTerm}\n      onChange={(e) =&gt; setSearchTerm(e.target.value)}\n      placeholder=\"Search conversations...\"\n      className=\"w-full p-3 border rounded-lg\"\n    /&gt;\n  );\n};\n</code></pre>"},{"location":"02_react_modern_ui/#drag-and-drop","title":"Drag and Drop","text":""},{"location":"02_react_modern_ui/#react-dnd-implementation","title":"React DnD Implementation","text":"<pre><code>// components/DraggableConversationCard.tsx\nimport { useDrag, useDrop } from 'react-dnd';\n\nconst DraggableConversationCard: React.FC&lt;Props&gt; = ({ conversation, onMove }) =&gt; {\n  const [{ isDragging }, drag] = useDrag({\n    type: 'conversation',\n    item: { id: conversation.id, type: 'conversation' },\n    collect: (monitor) =&gt; ({\n      isDragging: monitor.isDragging()\n    })\n  });\n\n  const [{ isOver }, drop] = useDrop({\n    accept: 'conversation',\n    drop: (item: any) =&gt; {\n      if (item.id !== conversation.id) {\n        onMove(item.id, conversation.folder_id);\n      }\n    },\n    collect: (monitor) =&gt; ({\n      isOver: monitor.isOver()\n    })\n  });\n\n  return (\n    &lt;div\n      ref={(node) =&gt; drag(drop(node))}\n      className={`p-4 border rounded-lg ${\n        isDragging ? 'opacity-50' : ''\n      } ${isOver ? 'bg-blue-50' : ''}`}\n    &gt;\n      {/* Card content */}\n    &lt;/div&gt;\n  );\n};\n</code></pre>"},{"location":"02_react_modern_ui/#mobile-optimization","title":"Mobile Optimization","text":""},{"location":"02_react_modern_ui/#responsive-design","title":"Responsive Design","text":"<pre><code>// components/ConversationList.tsx\nconst ConversationList: React.FC = () =&gt; {\n  const [isMobile, setIsMobile] = useState(false);\n\n  useEffect(() =&gt; {\n    const checkMobile = () =&gt; {\n      setIsMobile(window.innerWidth &lt; 768);\n    };\n\n    checkMobile();\n    window.addEventListener('resize', checkMobile);\n    return () =&gt; window.removeEventListener('resize', checkMobile);\n  }, []);\n\n  return (\n    &lt;div className={`${isMobile ? 'grid-cols-1' : 'grid-cols-3'} grid gap-4`}&gt;\n      {conversations.map(conversation =&gt; (\n        &lt;ConversationCard\n          key={conversation.id}\n          conversation={conversation}\n          isMobile={isMobile}\n        /&gt;\n      ))}\n    &lt;/div&gt;\n  );\n};\n</code></pre>"},{"location":"02_react_modern_ui/#performance-optimization","title":"Performance Optimization","text":""},{"location":"02_react_modern_ui/#reactmemo-and-usememo","title":"React.memo and useMemo","text":"<pre><code>// components/ConversationCard.tsx\nconst ConversationCard = React.memo&lt;ConversationCardProps&gt;(({\n  conversation,\n  onEdit,\n  onDelete,\n  onMove,\n  isSelected,\n  onSelect\n}) =&gt; {\n  const handleEdit = useCallback(() =&gt; {\n    onEdit(conversation.id);\n  }, [conversation.id, onEdit]);\n\n  const handleDelete = useCallback(() =&gt; {\n    onDelete(conversation.id);\n  }, [conversation.id, onDelete]);\n\n  const handleMove = useCallback((folderId: string) =&gt; {\n    onMove(conversation.id, folderId);\n  }, [conversation.id, onMove]);\n\n  return (\n    &lt;div className={`conversation-card ${isSelected ? 'selected' : ''}`}&gt;\n      {/* Card content */}\n    &lt;/div&gt;\n  );\n});\n</code></pre>"},{"location":"02_react_modern_ui/#testing-strategy","title":"Testing Strategy","text":""},{"location":"02_react_modern_ui/#component-testing","title":"Component Testing","text":"<pre><code>// __tests__/ConversationCard.test.tsx\nimport { render, screen, fireEvent } from '@testing-library/react';\nimport { ConversationCard } from '../ConversationCard';\n\ndescribe('ConversationCard', () =&gt; {\n  const mockConversation = {\n    id: '1',\n    title: 'Test Conversation',\n    created_at: '2024-01-01T00:00:00Z',\n    updated_at: '2024-01-01T00:00:00Z',\n    is_active: true\n  };\n\n  it('renders conversation title', () =&gt; {\n    render(\n      &lt;ConversationCard\n        conversation={mockConversation}\n        onEdit={jest.fn()}\n        onDelete={jest.fn()}\n        onMove={jest.fn()}\n        isSelected={false}\n        onSelect={jest.fn()}\n      /&gt;\n    );\n\n    expect(screen.getByText('Test Conversation')).toBeInTheDocument();\n  });\n\n  it('calls onEdit when edit button is clicked', () =&gt; {\n    const mockOnEdit = jest.fn();\n    render(\n      &lt;ConversationCard\n        conversation={mockConversation}\n        onEdit={mockOnEdit}\n        onDelete={jest.fn()}\n        onMove={jest.fn()}\n        isSelected={false}\n        onSelect={jest.fn()}\n      /&gt;\n    );\n\n    fireEvent.click(screen.getByRole('button', { name: /edit/i }));\n    expect(mockOnEdit).toHaveBeenCalledWith('1');\n  });\n});\n</code></pre>"},{"location":"02_react_modern_ui/#success-criteria","title":"Success Criteria","text":""},{"location":"02_react_modern_ui/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Conversation List - Display all conversations with proper pagination</li> <li> Folder Organization - Hierarchical folder structure with drag-and-drop</li> <li> Search &amp; Filter - Real-time search with multiple filter options</li> <li> CRUD Operations - Create, read, update, delete conversations</li> <li> Responsive Design - Works on desktop, tablet, and mobile</li> <li> Authentication - Proper login/logout functionality</li> <li> Error Handling - Graceful error states and loading indicators</li> </ul>"},{"location":"02_react_modern_ui/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"02_react_modern_ui/#advanced-features","title":"Advanced Features","text":"<ul> <li> Real-time Collaboration - Live updates when others make changes</li> <li> Keyboard Shortcuts - Power user keyboard navigation</li> <li> Bulk Operations - Select multiple conversations for batch actions</li> <li> Export/Import - Export conversations to various formats</li> <li> Dark Mode - Theme switching capability</li> <li> Offline Support - PWA with offline functionality</li> <li> Voice Search - Speech-to-text search functionality</li> </ul>"},{"location":"02_react_modern_ui/#getting-started","title":"Getting Started","text":""},{"location":"02_react_modern_ui/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Clone the repository and explore the API</li> <li>Create a new React app with TypeScript</li> <li>Install required dependencies (Redux Toolkit, React DnD, etc.)</li> <li>Set up the project structure as outlined above</li> <li>Start with the ConversationCard component - build the foundation</li> <li>Add state management - implement Redux slices</li> <li>Integrate with the API - create custom hooks</li> <li>Add advanced features - search, drag-and-drop, real-time updates</li> </ol>"},{"location":"02_react_modern_ui/#resources","title":"Resources","text":""},{"location":"02_react_modern_ui/#helpful-links","title":"Helpful Links","text":"<ul> <li>React Documentation - https://react.dev/</li> <li>Redux Toolkit - https://redux-toolkit.js.org/</li> <li>React DnD - https://react-dnd.github.io/react-dnd/</li> <li>Material-UI - https://mui.com/</li> <li>Chakra UI - https://chakra-ui.com/</li> <li>React Query - https://tanstack.com/query/latest</li> </ul>"},{"location":"02_react_modern_ui/#lets-build","title":"Let's Build!","text":""},{"location":"02_react_modern_ui/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Modern React patterns and best practices - Advanced state management techniques - Real-time application development - Performance optimization strategies - Mobile-first responsive design</p> <p>Start with the ConversationCard component and build up from there!</p>"},{"location":"02_react_modern_ui/#next-steps","title":"Next Steps","text":""},{"location":"02_react_modern_ui/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Share your code - Create a GitHub repository</li> <li>Document your approach - Write a README explaining your decisions</li> <li>Deploy your app - Use Vercel, Netlify, or similar</li> <li>Get feedback - Share with the community</li> <li>Move to the next track - Try Flutter or Vue.js next!</li> </ol> <p>Happy coding! \ud83d\ude80</p>"},{"location":"03_flutter_web_app/","title":"Flutter Web App","text":""},{"location":"03_flutter_web_app/#flutter-web-app-assignment","title":"Flutter Web App Assignment","text":""},{"location":"03_flutter_web_app/#cross-platform-conversation-management","title":"Cross-Platform Conversation Management","text":"<p>Build a beautiful Flutter web app for FastOpp</p>"},{"location":"03_flutter_web_app/#assignment-overview","title":"Assignment Overview","text":""},{"location":"03_flutter_web_app/#what-youll-build","title":"What You'll Build","text":"<p>A Flutter web application that provides a modern, responsive interface for FastOpp, featuring: - Cross-platform compatibility - Works on web, mobile, and desktop - Material Design 3 - Modern, beautiful UI components - Smooth animations - Delightful user interactions - Offline-first architecture - Works without internet connection - Native performance - Fast, responsive interface</p>"},{"location":"03_flutter_web_app/#problem-statement","title":"Problem Statement","text":""},{"location":"03_flutter_web_app/#why-flutter-for-web","title":"Why Flutter for Web?","text":"<p>The current FastOpp UI is built with traditional web technologies, which have limitations: - Platform-specific code - Different codebases for web and mobile - Performance issues - JavaScript can be slow for complex UIs - Inconsistent UX - Different experiences across platforms - Limited offline support - Requires constant internet connection - Complex state management - Hard to maintain across components</p>"},{"location":"03_flutter_web_app/#your-solution","title":"Your Solution","text":""},{"location":"03_flutter_web_app/#flutter-powered-interface","title":"Flutter-Powered Interface","text":"<p>Create a Flutter web app that addresses these limitations:</p> <ol> <li>Single Codebase - One app for web, mobile, and desktop</li> <li>High Performance - Compiled to native code</li> <li>Consistent UX - Same experience across all platforms</li> <li>Offline Support - Local storage and sync capabilities</li> <li>Beautiful Animations - Smooth, native-feeling interactions</li> </ol>"},{"location":"03_flutter_web_app/#technical-requirements","title":"Technical Requirements","text":""},{"location":"03_flutter_web_app/#tech-stack","title":"Tech Stack","text":"<ul> <li>Flutter 3.0+ with Dart 3.0+</li> <li>State Management - Riverpod or Bloc</li> <li>HTTP Client - Dio or http package</li> <li>Local Storage - Hive or SQLite</li> <li>UI Framework - Material Design 3</li> <li>Routing - GoRouter</li> <li>Build Tool - Flutter web build</li> </ul>"},{"location":"03_flutter_web_app/#project-structure","title":"Project Structure","text":""},{"location":"03_flutter_web_app/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>lib/\n\u251c\u2500\u2500 main.dart\n\u251c\u2500\u2500 app/\n\u2502   \u251c\u2500\u2500 app.dart\n\u2502   \u2514\u2500\u2500 routes.dart\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 constants/\n\u2502   \u251c\u2500\u2500 errors/\n\u2502   \u251c\u2500\u2500 network/\n\u2502   \u2514\u2500\u2500 utils/\n\u251c\u2500\u2500 features/\n\u2502   \u251c\u2500\u2500 conversations/\n\u2502   \u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u251c\u2500\u2500 domain/\n\u2502   \u2502   \u2514\u2500\u2500 presentation/\n\u2502   \u251c\u2500\u2500 folders/\n\u2502   \u2514\u2500\u2500 search/\n\u251c\u2500\u2500 shared/\n\u2502   \u251c\u2500\u2500 widgets/\n\u2502   \u251c\u2500\u2500 services/\n\u2502   \u2514\u2500\u2500 models/\n\u2514\u2500\u2500 theme/\n    \u2514\u2500\u2500 app_theme.dart\n</code></pre>"},{"location":"03_flutter_web_app/#core-features","title":"Core Features","text":""},{"location":"03_flutter_web_app/#1-conversation-list","title":"1. Conversation List","text":"<pre><code>// features/conversations/presentation/widgets/conversation_list.dart\nclass ConversationList extends ConsumerWidget {\n  @override\n  Widget build(BuildContext context, WidgetRef ref) {\n    final conversations = ref.watch(conversationProvider);\n    final isLoading = ref.watch(conversationLoadingProvider);\n\n    if (isLoading) {\n      return const Center(child: CircularProgressIndicator());\n    }\n\n    return ListView.builder(\n      itemCount: conversations.length,\n      itemBuilder: (context, index) {\n        final conversation = conversations[index];\n        return ConversationCard(conversation: conversation);\n      },\n    );\n  }\n}\n</code></pre>"},{"location":"03_flutter_web_app/#core-features_1","title":"Core Features","text":""},{"location":"03_flutter_web_app/#2-conversation-card","title":"2. Conversation Card","text":"<pre><code>// features/conversations/presentation/widgets/conversation_card.dart\nclass ConversationCard extends ConsumerWidget {\n  final Conversation conversation;\n\n  const ConversationCard({Key? key, required this.conversation}) : super(key: key);\n\n  @override\n  Widget build(BuildContext context, WidgetRef ref) {\n    return Card(\n      elevation: 2,\n      child: ListTile(\n        leading: CircleAvatar(\n          backgroundColor: Theme.of(context).primaryColor,\n          child: Text(conversation.title[0].toUpperCase()),\n        ),\n        title: Text(conversation.title),\n        subtitle: Text(\n          _formatDate(conversation.updatedAt),\n          style: Theme.of(context).textTheme.bodySmall,\n        ),\n        trailing: PopupMenuButton(\n          itemBuilder: (context) =&gt; [\n            PopupMenuItem(\n              value: 'edit',\n              child: const Text('Edit'),\n            ),\n            PopupMenuItem(\n              value: 'delete',\n              child: const Text('Delete'),\n            ),\n          ],\n          onSelected: (value) =&gt; _handleMenuAction(value, ref),\n        ),\n        onTap: () =&gt; _navigateToConversation(context, conversation.id),\n      ),\n    );\n  }\n}\n</code></pre>"},{"location":"03_flutter_web_app/#state-management","title":"State Management","text":""},{"location":"03_flutter_web_app/#riverpod-setup","title":"Riverpod Setup","text":"<pre><code>// features/conversations/data/providers/conversation_provider.dart\nfinal conversationProvider = StateNotifierProvider&lt;ConversationNotifier, List&lt;Conversation&gt;&gt;(\n  (ref) =&gt; ConversationNotifier(ref.read(conversationRepositoryProvider)),\n);\n\nfinal conversationLoadingProvider = StateProvider&lt;bool&gt;((ref) =&gt; false);\n\nclass ConversationNotifier extends StateNotifier&lt;List&lt;Conversation&gt;&gt; {\n  final ConversationRepository _repository;\n\n  ConversationNotifier(this._repository) : super([]) {\n    loadConversations();\n  }\n\n  Future&lt;void&gt; loadConversations() async {\n    try {\n      state = await _repository.getConversations();\n    } catch (e) {\n      // Handle error\n    }\n  }\n\n  Future&lt;void&gt; createConversation(Conversation conversation) async {\n    final newConversation = await _repository.createConversation(conversation);\n    state = [...state, newConversation];\n  }\n\n  Future&lt;void&gt; deleteConversation(String id) async {\n    await _repository.deleteConversation(id);\n    state = state.where((c) =&gt; c.id != id).toList();\n  }\n}\n</code></pre>"},{"location":"03_flutter_web_app/#api-integration","title":"API Integration","text":""},{"location":"03_flutter_web_app/#repository-pattern","title":"Repository Pattern","text":"<pre><code>// features/conversations/data/repositories/conversation_repository.dart\nabstract class ConversationRepository {\n  Future&lt;List&lt;Conversation&gt;&gt; getConversations();\n  Future&lt;Conversation&gt; getConversation(String id);\n  Future&lt;Conversation&gt; createConversation(Conversation conversation);\n  Future&lt;Conversation&gt; updateConversation(Conversation conversation);\n  Future&lt;void&gt; deleteConversation(String id);\n}\n\nclass ConversationRepositoryImpl implements ConversationRepository {\n  final ApiClient _apiClient;\n\n  ConversationRepositoryImpl(this._apiClient);\n\n  @override\n  Future&lt;List&lt;Conversation&gt;&gt; getConversations() async {\n    try {\n      final response = await _apiClient.get('/api/conversations');\n      return (response.data as List)\n          .map((json) =&gt; Conversation.fromJson(json))\n          .toList();\n    } catch (e) {\n      throw ServerException('Failed to load conversations');\n    }\n  }\n\n  @override\n  Future&lt;Conversation&gt; createConversation(Conversation conversation) async {\n    try {\n      final response = await _apiClient.post(\n        '/api/conversations',\n        data: conversation.toJson(),\n      );\n      return Conversation.fromJson(response.data);\n    } catch (e) {\n      throw ServerException('Failed to create conversation');\n    }\n  }\n}\n</code></pre>"},{"location":"03_flutter_web_app/#offline-support","title":"Offline Support","text":""},{"location":"03_flutter_web_app/#local-storage","title":"Local Storage","text":"<pre><code>// core/storage/local_storage.dart\nclass LocalStorage {\n  static const String _conversationsKey = 'conversations';\n  static const String _foldersKey = 'folders';\n\n  static Future&lt;void&gt; saveConversations(List&lt;Conversation&gt; conversations) async {\n    final prefs = await SharedPreferences.getInstance();\n    final jsonList = conversations.map((c) =&gt; c.toJson()).toList();\n    await prefs.setString(_conversationsKey, jsonEncode(jsonList));\n  }\n\n  static Future&lt;List&lt;Conversation&gt;&gt; loadConversations() async {\n    final prefs = await SharedPreferences.getInstance();\n    final jsonString = prefs.getString(_conversationsKey);\n\n    if (jsonString == null) return [];\n\n    final jsonList = jsonDecode(jsonString) as List;\n    return jsonList.map((json) =&gt; Conversation.fromJson(json)).toList();\n  }\n\n  static Future&lt;void&gt; syncWithServer() async {\n    // Implement sync logic\n    final localConversations = await loadConversations();\n    final serverConversations = await _apiClient.getConversations();\n\n    // Merge and resolve conflicts\n    final mergedConversations = _mergeConversations(localConversations, serverConversations);\n    await saveConversations(mergedConversations);\n  }\n}\n</code></pre>"},{"location":"03_flutter_web_app/#search-functionality","title":"Search Functionality","text":""},{"location":"03_flutter_web_app/#real-time-search","title":"Real-time Search","text":"<pre><code>// features/search/presentation/widgets/search_bar.dart\nclass SearchBar extends ConsumerStatefulWidget {\n  @override\n  _SearchBarState createState() =&gt; _SearchBarState();\n}\n\nclass _SearchBarState extends ConsumerState&lt;SearchBar&gt; {\n  final TextEditingController _controller = TextEditingController();\n  Timer? _debounceTimer;\n\n  @override\n  void dispose() {\n    _controller.dispose();\n    _debounceTimer?.cancel();\n    super.dispose();\n  }\n\n  void _onSearchChanged(String query) {\n    _debounceTimer?.cancel();\n    _debounceTimer = Timer(const Duration(milliseconds: 300), () {\n      ref.read(searchQueryProvider.notifier).update((state) =&gt; query);\n    });\n  }\n\n  @override\n  Widget build(BuildContext context) {\n    return TextField(\n      controller: _controller,\n      onChanged: _onSearchChanged,\n      decoration: InputDecoration(\n        hintText: 'Search conversations...',\n        prefixIcon: const Icon(Icons.search),\n        suffixIcon: _controller.text.isNotEmpty\n            ? IconButton(\n                icon: const Icon(Icons.clear),\n                onPressed: () {\n                  _controller.clear();\n                  _onSearchChanged('');\n                },\n              )\n            : null,\n        border: OutlineInputBorder(\n          borderRadius: BorderRadius.circular(12),\n        ),\n      ),\n    );\n  }\n}\n</code></pre>"},{"location":"03_flutter_web_app/#folder-organization","title":"Folder Organization","text":""},{"location":"03_flutter_web_app/#drag-and-drop","title":"Drag and Drop","text":"<pre><code>// features/folders/presentation/widgets/folder_tree.dart\nclass FolderTree extends ConsumerWidget {\n  @override\n  Widget build(BuildContext context, WidgetRef ref) {\n    final folders = ref.watch(folderProvider);\n    final conversations = ref.watch(conversationProvider);\n\n    return ReorderableListView.builder(\n      itemCount: folders.length,\n      onReorder: (oldIndex, newIndex) {\n        ref.read(folderProvider.notifier).reorderFolders(oldIndex, newIndex);\n      },\n      itemBuilder: (context, index) {\n        final folder = folders[index];\n        return FolderTile(\n          key: ValueKey(folder.id),\n          folder: folder,\n          conversations: conversations.where((c) =&gt; c.folderId == folder.id).toList(),\n        );\n      },\n    );\n  }\n}\n\nclass FolderTile extends StatelessWidget {\n  final Folder folder;\n  final List&lt;Conversation&gt; conversations;\n\n  const FolderTile({\n    Key? key,\n    required this.folder,\n    required this.conversations,\n  }) : super(key: key);\n\n  @override\n  Widget build(BuildContext context) {\n    return ExpansionTile(\n      title: Text(folder.name),\n      subtitle: Text('${conversations.length} conversations'),\n      children: conversations.map((conversation) =&gt; \n        ConversationCard(conversation: conversation)\n      ).toList(),\n    );\n  }\n}\n</code></pre>"},{"location":"03_flutter_web_app/#responsive-design","title":"Responsive Design","text":""},{"location":"03_flutter_web_app/#adaptive-layout","title":"Adaptive Layout","text":"<pre><code>// shared/widgets/responsive_layout.dart\nclass ResponsiveLayout extends StatelessWidget {\n  final Widget mobile;\n  final Widget? tablet;\n  final Widget desktop;\n\n  const ResponsiveLayout({\n    Key? key,\n    required this.mobile,\n    this.tablet,\n    required this.desktop,\n  }) : super(key: key);\n\n  @override\n  Widget build(BuildContext context) {\n    return LayoutBuilder(\n      builder: (context, constraints) {\n        if (constraints.maxWidth &lt; 600) {\n          return mobile;\n        } else if (constraints.maxWidth &lt; 1200) {\n          return tablet ?? desktop;\n        } else {\n          return desktop;\n        }\n      },\n    );\n  }\n}\n\n// Usage\nResponsiveLayout(\n  mobile: MobileConversationView(),\n  tablet: TabletConversationView(),\n  desktop: DesktopConversationView(),\n)\n</code></pre>"},{"location":"03_flutter_web_app/#animations","title":"Animations","text":""},{"location":"03_flutter_web_app/#smooth-transitions","title":"Smooth Transitions","text":"<pre><code>// shared/widgets/animated_conversation_card.dart\nclass AnimatedConversationCard extends StatefulWidget {\n  final Conversation conversation;\n  final VoidCallback onTap;\n\n  @override\n  _AnimatedConversationCardState createState() =&gt; _AnimatedConversationCardState();\n}\n\nclass _AnimatedConversationCardState extends State&lt;AnimatedConversationCard&gt;\n    with SingleTickerProviderStateMixin {\n  late AnimationController _controller;\n  late Animation&lt;double&gt; _scaleAnimation;\n\n  @override\n  void initState() {\n    super.initState();\n    _controller = AnimationController(\n      duration: const Duration(milliseconds: 200),\n      vsync: this,\n    );\n    _scaleAnimation = Tween&lt;double&gt;(\n      begin: 1.0,\n      end: 0.95,\n    ).animate(CurvedAnimation(\n      parent: _controller,\n      curve: Curves.easeInOut,\n    ));\n  }\n\n  @override\n  Widget build(BuildContext context) {\n    return GestureDetector(\n      onTapDown: (_) =&gt; _controller.forward(),\n      onTapUp: (_) {\n        _controller.reverse();\n        widget.onTap();\n      },\n      onTapCancel: () =&gt; _controller.reverse(),\n      child: AnimatedBuilder(\n        animation: _scaleAnimation,\n        builder: (context, child) {\n          return Transform.scale(\n            scale: _scaleAnimation.value,\n            child: ConversationCard(conversation: widget.conversation),\n          );\n        },\n      ),\n    );\n  }\n}\n</code></pre>"},{"location":"03_flutter_web_app/#testing","title":"Testing","text":""},{"location":"03_flutter_web_app/#widget-tests","title":"Widget Tests","text":"<pre><code>// test/features/conversations/presentation/widgets/conversation_card_test.dart\nvoid main() {\n  group('ConversationCard', () {\n    testWidgets('displays conversation title', (WidgetTester tester) async {\n      final conversation = Conversation(\n        id: '1',\n        title: 'Test Conversation',\n        createdAt: DateTime.now(),\n        updatedAt: DateTime.now(),\n        isActive: true,\n      );\n\n      await tester.pumpWidget(\n        MaterialApp(\n          home: ConversationCard(conversation: conversation),\n        ),\n      );\n\n      expect(find.text('Test Conversation'), findsOneWidget);\n    });\n\n    testWidgets('calls onTap when tapped', (WidgetTester tester) async {\n      bool wasTapped = false;\n      final conversation = Conversation(\n        id: '1',\n        title: 'Test Conversation',\n        createdAt: DateTime.now(),\n        updatedAt: DateTime.now(),\n        isActive: true,\n      );\n\n      await tester.pumpWidget(\n        MaterialApp(\n          home: ConversationCard(\n            conversation: conversation,\n            onTap: () =&gt; wasTapped = true,\n          ),\n        ),\n      );\n\n      await tester.tap(find.byType(ConversationCard));\n      expect(wasTapped, isTrue);\n    });\n  });\n}\n</code></pre>"},{"location":"03_flutter_web_app/#success-criteria","title":"Success Criteria","text":""},{"location":"03_flutter_web_app/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Conversation Management - CRUD operations for conversations</li> <li> Folder Organization - Hierarchical folder structure</li> <li> Search &amp; Filter - Real-time search functionality</li> <li> Responsive Design - Works on all screen sizes</li> <li> Offline Support - Local storage and sync</li> <li> Authentication - Login/logout functionality</li> <li> Smooth Animations - Delightful user interactions</li> <li> Error Handling - Graceful error states</li> </ul>"},{"location":"03_flutter_web_app/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"03_flutter_web_app/#advanced-features","title":"Advanced Features","text":"<ul> <li> Real-time Updates - WebSocket integration</li> <li> Push Notifications - Browser notifications</li> <li> PWA Features - Installable web app</li> <li> Dark Mode - Theme switching</li> <li> Keyboard Shortcuts - Power user features</li> <li> Bulk Operations - Multi-select actions</li> <li> Export/Import - Data portability</li> <li> Voice Search - Speech-to-text</li> </ul>"},{"location":"03_flutter_web_app/#getting-started","title":"Getting Started","text":""},{"location":"03_flutter_web_app/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Install Flutter - Get Flutter SDK and enable web support</li> <li>Create new project - <code>flutter create fastopp_web</code></li> <li>Add dependencies - Add required packages to pubspec.yaml</li> <li>Set up project structure - Create the folder structure above</li> <li>Start with models - Define your data models</li> <li>Build the UI - Create your first screens</li> <li>Add state management - Implement Riverpod providers</li> <li>Integrate with API - Connect to FastOpp backend</li> </ol>"},{"location":"03_flutter_web_app/#dependencies","title":"Dependencies","text":""},{"location":"03_flutter_web_app/#pubspecyaml","title":"pubspec.yaml","text":"<pre><code>dependencies:\n  flutter:\n    sdk: flutter\n  cupertino_icons: ^1.0.2\n\n  # State Management\n  flutter_riverpod: ^2.4.9\n\n  # HTTP Client\n  dio: ^5.3.2\n\n  # Local Storage\n  shared_preferences: ^2.2.2\n  hive: ^2.2.3\n  hive_flutter: ^1.1.0\n\n  # UI\n  material_design_icons_flutter: ^7.0.7296\n\n  # Utils\n  intl: ^0.18.1\n  uuid: ^4.2.1\n\ndev_dependencies:\n  flutter_test:\n    sdk: flutter\n  flutter_lints: ^3.0.0\n  hive_generator: ^2.0.1\n  build_runner: ^2.4.7\n</code></pre>"},{"location":"03_flutter_web_app/#resources","title":"Resources","text":""},{"location":"03_flutter_web_app/#helpful-links","title":"Helpful Links","text":"<ul> <li>Flutter Documentation - https://flutter.dev/docs</li> <li>Riverpod - https://riverpod.dev/</li> <li>Material Design 3 - https://m3.material.io/</li> <li>Flutter Web - https://flutter.dev/web</li> <li>Dio HTTP - https://pub.dev/packages/dio</li> <li>Hive Database - https://pub.dev/packages/hive</li> </ul>"},{"location":"03_flutter_web_app/#lets-build","title":"Let's Build!","text":""},{"location":"03_flutter_web_app/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Flutter web development - Cross-platform UI design - State management with Riverpod - Offline-first architecture - Material Design 3 principles - Performance optimization</p> <p>Start with the basic app structure and build up from there!</p>"},{"location":"03_flutter_web_app/#next-steps","title":"Next Steps","text":""},{"location":"03_flutter_web_app/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Deploy your app - Use Firebase Hosting or similar</li> <li>Test on different devices - Ensure cross-platform compatibility</li> <li>Share your code - Create a GitHub repository</li> <li>Document your approach - Write a comprehensive README</li> <li>Move to the next track - Try Vue.js or mobile development next!</li> </ol> <p>Happy coding! \ud83d\ude80</p>"},{"location":"04_vue_js_dashboard/","title":"Vue.js Dashboard","text":""},{"location":"04_vue_js_dashboard/#vuejs-dashboard-assignment","title":"Vue.js Dashboard Assignment","text":""},{"location":"04_vue_js_dashboard/#lightweight-reactive-interface","title":"Lightweight, Reactive Interface","text":"<p>Build a modern Vue.js dashboard for FastOpp</p>"},{"location":"04_vue_js_dashboard/#assignment-overview","title":"Assignment Overview","text":""},{"location":"04_vue_js_dashboard/#what-youll-build","title":"What You'll Build","text":"<p>A Vue.js application that provides a clean, lightweight interface for FastOpp, featuring: - Reactive data binding - Automatic UI updates - Component-based architecture - Reusable, maintainable code - Lightweight framework - Fast loading and minimal bundle size - Composition API - Modern Vue 3 patterns - TypeScript support - Type-safe development</p>"},{"location":"04_vue_js_dashboard/#problem-statement","title":"Problem Statement","text":""},{"location":"04_vue_js_dashboard/#why-vuejs","title":"Why Vue.js?","text":"<p>The current FastOpp UI, while functional, could benefit from a lighter, more reactive approach: - Heavy JavaScript frameworks - Slow initial load times - Complex state management - Over-engineered solutions - Poor developer experience - Hard to maintain and extend - Limited reactivity - Manual DOM updates - Bundle size - Large JavaScript payloads</p>"},{"location":"04_vue_js_dashboard/#your-solution","title":"Your Solution","text":""},{"location":"04_vue_js_dashboard/#vuejs-powered-interface","title":"Vue.js-Powered Interface","text":"<p>Create a Vue.js application that addresses these limitations:</p> <ol> <li>Lightweight Framework - Small bundle size, fast loading</li> <li>Reactive Data - Automatic UI updates when data changes</li> <li>Simple State Management - Pinia for clean state management</li> <li>Component Reusability - Easy to maintain and extend</li> <li>Great DX - Excellent developer experience with TypeScript</li> </ol>"},{"location":"04_vue_js_dashboard/#technical-requirements","title":"Technical Requirements","text":""},{"location":"04_vue_js_dashboard/#tech-stack","title":"Tech Stack","text":"<ul> <li>Vue 3 with Composition API</li> <li>TypeScript for type safety</li> <li>Pinia for state management</li> <li>Vue Router for navigation</li> <li>Axios for HTTP requests</li> <li>Tailwind CSS for styling</li> <li>Vite for build tooling</li> </ul>"},{"location":"04_vue_js_dashboard/#project-structure","title":"Project Structure","text":""},{"location":"04_vue_js_dashboard/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>src/\n\u251c\u2500\u2500 main.ts\n\u251c\u2500\u2500 App.vue\n\u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 ConversationCard.vue\n\u2502   \u251c\u2500\u2500 FolderTree.vue\n\u2502   \u251c\u2500\u2500 SearchBar.vue\n\u2502   \u2514\u2500\u2500 ConversationList.vue\n\u251c\u2500\u2500 views/\n\u2502   \u251c\u2500\u2500 Dashboard.vue\n\u2502   \u251c\u2500\u2500 ConversationDetail.vue\n\u2502   \u2514\u2500\u2500 Settings.vue\n\u251c\u2500\u2500 stores/\n\u2502   \u251c\u2500\u2500 conversation.ts\n\u2502   \u251c\u2500\u2500 folder.ts\n\u2502   \u2514\u2500\u2500 auth.ts\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 api.ts\n\u2502   \u2514\u2500\u2500 websocket.ts\n\u251c\u2500\u2500 types/\n\u2502   \u2514\u2500\u2500 index.ts\n\u2514\u2500\u2500 composables/\n    \u251c\u2500\u2500 useConversations.ts\n    \u251c\u2500\u2500 useFolders.ts\n    \u2514\u2500\u2500 useSearch.ts\n</code></pre>"},{"location":"04_vue_js_dashboard/#core-components","title":"Core Components","text":""},{"location":"04_vue_js_dashboard/#1-conversation-card","title":"1. Conversation Card","text":"<pre><code>&lt;!-- components/ConversationCard.vue --&gt;\n&lt;template&gt;\n  &lt;div\n    class=\"bg-white rounded-lg shadow-md p-4 hover:shadow-lg transition-shadow cursor-pointer\"\n    @click=\"handleClick\"\n  &gt;\n    &lt;div class=\"flex items-center justify-between\"&gt;\n      &lt;div class=\"flex-1\"&gt;\n        &lt;h3 class=\"text-lg font-semibold text-gray-900\"&gt;\n          {{ conversation.title }}\n        &lt;/h3&gt;\n        &lt;p class=\"text-sm text-gray-500 mt-1\"&gt;\n          {{ formatDate(conversation.updatedAt) }}\n        &lt;/p&gt;\n      &lt;/div&gt;\n      &lt;div class=\"flex items-center space-x-2\"&gt;\n        &lt;button\n          @click.stop=\"handleEdit\"\n          class=\"p-2 text-gray-400 hover:text-blue-500 transition-colors\"\n        &gt;\n          &lt;EditIcon class=\"w-4 h-4\" /&gt;\n        &lt;/button&gt;\n        &lt;button\n          @click.stop=\"handleDelete\"\n          class=\"p-2 text-gray-400 hover:text-red-500 transition-colors\"\n        &gt;\n          &lt;DeleteIcon class=\"w-4 h-4\" /&gt;\n        &lt;/button&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script setup lang=\"ts\"&gt;\nimport { computed } from 'vue'\nimport { useRouter } from 'vue-router'\nimport { useConversationStore } from '@/stores/conversation'\nimport type { Conversation } from '@/types'\n\ninterface Props {\n  conversation: Conversation\n}\n\nconst props = defineProps&lt;Props&gt;()\nconst router = useRouter()\nconst conversationStore = useConversationStore()\n\nconst formatDate = (date: string) =&gt; {\n  return new Date(date).toLocaleDateString()\n}\n\nconst handleClick = () =&gt; {\n  router.push(`/conversations/${props.conversation.id}`)\n}\n\nconst handleEdit = () =&gt; {\n  conversationStore.setEditingConversation(props.conversation)\n}\n\nconst handleDelete = async () =&gt; {\n  if (confirm('Are you sure you want to delete this conversation?')) {\n    await conversationStore.deleteConversation(props.conversation.id)\n  }\n}\n&lt;/script&gt;\n</code></pre>"},{"location":"04_vue_js_dashboard/#core-components_1","title":"Core Components","text":""},{"location":"04_vue_js_dashboard/#2-folder-tree","title":"2. Folder Tree","text":"<pre><code>&lt;!-- components/FolderTree.vue --&gt;\n&lt;template&gt;\n  &lt;div class=\"space-y-2\"&gt;\n    &lt;div\n      v-for=\"folder in folders\"\n      :key=\"folder.id\"\n      class=\"folder-item\"\n    &gt;\n      &lt;div\n        class=\"flex items-center justify-between p-2 rounded hover:bg-gray-100 cursor-pointer\"\n        @click=\"toggleFolder(folder.id)\"\n      &gt;\n        &lt;div class=\"flex items-center space-x-2\"&gt;\n          &lt;ChevronRightIcon\n            :class=\"[\n              'w-4 h-4 transition-transform',\n              expandedFolders.has(folder.id) ? 'rotate-90' : ''\n            ]\"\n          /&gt;\n          &lt;FolderIcon class=\"w-4 h-4 text-blue-500\" /&gt;\n          &lt;span class=\"text-sm font-medium\"&gt;{{ folder.name }}&lt;/span&gt;\n        &lt;/div&gt;\n        &lt;div class=\"flex items-center space-x-1\"&gt;\n          &lt;span class=\"text-xs text-gray-500\"&gt;\n            {{ getConversationCount(folder.id) }}\n          &lt;/span&gt;\n          &lt;button\n            @click.stop=\"handleAddConversation(folder.id)\"\n            class=\"p-1 text-gray-400 hover:text-blue-500\"\n          &gt;\n            &lt;PlusIcon class=\"w-3 h-3\" /&gt;\n          &lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n\n      &lt;div\n        v-if=\"expandedFolders.has(folder.id)\"\n        class=\"ml-6 space-y-1\"\n      &gt;\n        &lt;ConversationCard\n          v-for=\"conversation in getConversationsInFolder(folder.id)\"\n          :key=\"conversation.id\"\n          :conversation=\"conversation\"\n        /&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script setup lang=\"ts\"&gt;\nimport { ref, computed } from 'vue'\nimport { useConversationStore } from '@/stores/conversation'\nimport { useFolderStore } from '@/stores/folder'\nimport ConversationCard from './ConversationCard.vue'\nimport type { Folder } from '@/types'\n\nconst conversationStore = useConversationStore()\nconst folderStore = useFolderStore()\n\nconst expandedFolders = ref(new Set&lt;string&gt;())\n\nconst folders = computed(() =&gt; folderStore.folders)\nconst conversations = computed(() =&gt; conversationStore.conversations)\n\nconst toggleFolder = (folderId: string) =&gt; {\n  if (expandedFolders.value.has(folderId)) {\n    expandedFolders.value.delete(folderId)\n  } else {\n    expandedFolders.value.add(folderId)\n  }\n}\n\nconst getConversationCount = (folderId: string) =&gt; {\n  return conversations.value.filter(c =&gt; c.folderId === folderId).length\n}\n\nconst getConversationsInFolder = (folderId: string) =&gt; {\n  return conversations.value.filter(c =&gt; c.folderId === folderId)\n}\n\nconst handleAddConversation = (folderId: string) =&gt; {\n  conversationStore.createConversation({ folderId })\n}\n&lt;/script&gt;\n</code></pre>"},{"location":"04_vue_js_dashboard/#state-management","title":"State Management","text":""},{"location":"04_vue_js_dashboard/#pinia-store","title":"Pinia Store","text":"<pre><code>// stores/conversation.ts\nimport { defineStore } from 'pinia'\nimport { ref, computed } from 'vue'\nimport { conversationApi } from '@/services/api'\nimport type { Conversation, CreateConversationData } from '@/types'\n\nexport const useConversationStore = defineStore('conversation', () =&gt; {\n  const conversations = ref&lt;Conversation[]&gt;([])\n  const loading = ref(false)\n  const error = ref&lt;string | null&gt;(null)\n  const selectedConversation = ref&lt;Conversation | null&gt;(null)\n  const editingConversation = ref&lt;Conversation | null&gt;(null)\n\n  const activeConversations = computed(() =&gt;\n    conversations.value.filter(c =&gt; c.isActive)\n  )\n\n  const getConversationById = computed(() =&gt; (id: string) =&gt;\n    conversations.value.find(c =&gt; c.id === id)\n  )\n\n  const fetchConversations = async () =&gt; {\n    loading.value = true\n    error.value = null\n\n    try {\n      const data = await conversationApi.getAll()\n      conversations.value = data\n    } catch (err) {\n      error.value = err instanceof Error ? err.message : 'Failed to fetch conversations'\n    } finally {\n      loading.value = false\n    }\n  }\n\n  const createConversation = async (data: CreateConversationData) =&gt; {\n    try {\n      const newConversation = await conversationApi.create(data)\n      conversations.value.push(newConversation)\n      return newConversation\n    } catch (err) {\n      error.value = err instanceof Error ? err.message : 'Failed to create conversation'\n      throw err\n    }\n  }\n\n  const updateConversation = async (id: string, data: Partial&lt;Conversation&gt;) =&gt; {\n    try {\n      const updatedConversation = await conversationApi.update(id, data)\n      const index = conversations.value.findIndex(c =&gt; c.id === id)\n      if (index !== -1) {\n        conversations.value[index] = updatedConversation\n      }\n      return updatedConversation\n    } catch (err) {\n      error.value = err instanceof Error ? err.message : 'Failed to update conversation'\n      throw err\n    }\n  }\n\n  const deleteConversation = async (id: string) =&gt; {\n    try {\n      await conversationApi.delete(id)\n      conversations.value = conversations.value.filter(c =&gt; c.id !== id)\n    } catch (err) {\n      error.value = err instanceof Error ? err.message : 'Failed to delete conversation'\n      throw err\n    }\n  }\n\n  const setSelectedConversation = (conversation: Conversation | null) =&gt; {\n    selectedConversation.value = conversation\n  }\n\n  const setEditingConversation = (conversation: Conversation | null) =&gt; {\n    editingConversation.value = conversation\n  }\n\n  return {\n    conversations,\n    loading,\n    error,\n    selectedConversation,\n    editingConversation,\n    activeConversations,\n    getConversationById,\n    fetchConversations,\n    createConversation,\n    updateConversation,\n    deleteConversation,\n    setSelectedConversation,\n    setEditingConversation\n  }\n})\n</code></pre>"},{"location":"04_vue_js_dashboard/#composables","title":"Composables","text":""},{"location":"04_vue_js_dashboard/#custom-hooks","title":"Custom Hooks","text":"<pre><code>// composables/useConversations.ts\nimport { computed } from 'vue'\nimport { useConversationStore } from '@/stores/conversation'\nimport { useSearchStore } from '@/stores/search'\n\nexport function useConversations() {\n  const conversationStore = useConversationStore()\n  const searchStore = useSearchStore()\n\n  const filteredConversations = computed(() =&gt; {\n    if (!searchStore.query) {\n      return conversationStore.activeConversations\n    }\n\n    return conversationStore.activeConversations.filter(conversation =&gt;\n      conversation.title.toLowerCase().includes(searchStore.query.toLowerCase())\n    )\n  })\n\n  const conversationsByFolder = computed(() =&gt; {\n    const grouped: Record&lt;string, typeof conversationStore.conversations&gt; = {}\n\n    filteredConversations.value.forEach(conversation =&gt; {\n      const folderId = conversation.folderId || 'unorganized'\n      if (!grouped[folderId]) {\n        grouped[folderId] = []\n      }\n      grouped[folderId].push(conversation)\n    })\n\n    return grouped\n  })\n\n  const getConversationsInFolder = (folderId: string) =&gt; {\n    return conversationsByFolder.value[folderId] || []\n  }\n\n  return {\n    conversations: filteredConversations,\n    conversationsByFolder,\n    getConversationsInFolder,\n    loading: conversationStore.loading,\n    error: conversationStore.error,\n    fetchConversations: conversationStore.fetchConversations,\n    createConversation: conversationStore.createConversation,\n    updateConversation: conversationStore.updateConversation,\n    deleteConversation: conversationStore.deleteConversation\n  }\n}\n</code></pre>"},{"location":"04_vue_js_dashboard/#api-integration","title":"API Integration","text":""},{"location":"04_vue_js_dashboard/#service-layer","title":"Service Layer","text":"<pre><code>// services/api.ts\nimport axios from 'axios'\nimport type { Conversation, Folder, Client, Project } from '@/types'\n\nconst api = axios.create({\n  baseURL: import.meta.env.VITE_API_BASE_URL || 'http://localhost:8000',\n  headers: {\n    'Content-Type': 'application/json'\n  }\n})\n\n// Request interceptor for auth\napi.interceptors.request.use((config) =&gt; {\n  const token = localStorage.getItem('auth_token')\n  if (token) {\n    config.headers.Authorization = `Bearer ${token}`\n  }\n  return config\n})\n\n// Response interceptor for error handling\napi.interceptors.response.use(\n  (response) =&gt; response,\n  (error) =&gt; {\n    if (error.response?.status === 401) {\n      // Handle unauthorized\n      localStorage.removeItem('auth_token')\n      window.location.href = '/login'\n    }\n    return Promise.reject(error)\n  }\n)\n\nexport const conversationApi = {\n  getAll: () =&gt; api.get&lt;Conversation[]&gt;('/api/conversations').then(res =&gt; res.data),\n  getById: (id: string) =&gt; api.get&lt;Conversation&gt;(`/api/conversations/${id}`).then(res =&gt; res.data),\n  create: (data: Partial&lt;Conversation&gt;) =&gt; api.post&lt;Conversation&gt;('/api/conversations', data).then(res =&gt; res.data),\n  update: (id: string, data: Partial&lt;Conversation&gt;) =&gt; api.put&lt;Conversation&gt;(`/api/conversations/${id}`, data).then(res =&gt; res.data),\n  delete: (id: string) =&gt; api.delete(`/api/conversations/${id}`)\n}\n\nexport const folderApi = {\n  getAll: () =&gt; api.get&lt;Folder[]&gt;('/api/folders').then(res =&gt; res.data),\n  create: (data: Partial&lt;Folder&gt;) =&gt; api.post&lt;Folder&gt;('/api/folders', data).then(res =&gt; res.data),\n  update: (id: string, data: Partial&lt;Folder&gt;) =&gt; api.put&lt;Folder&gt;(`/api/folders/${id}`, data).then(res =&gt; res.data),\n  delete: (id: string) =&gt; api.delete(`/api/folders/${id}`)\n}\n\nexport const searchApi = {\n  search: (query: string) =&gt; api.get(`/api/search?q=${encodeURIComponent(query)}`).then(res =&gt; res.data)\n}\n</code></pre>"},{"location":"04_vue_js_dashboard/#search-functionality","title":"Search Functionality","text":""},{"location":"04_vue_js_dashboard/#real-time-search","title":"Real-time Search","text":"<pre><code>&lt;!-- components/SearchBar.vue --&gt;\n&lt;template&gt;\n  &lt;div class=\"relative\"&gt;\n    &lt;div class=\"absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none\"&gt;\n      &lt;SearchIcon class=\"h-5 w-5 text-gray-400\" /&gt;\n    &lt;/div&gt;\n    &lt;input\n      v-model=\"searchQuery\"\n      type=\"text\"\n      class=\"block w-full pl-10 pr-3 py-2 border border-gray-300 rounded-md leading-5 bg-white placeholder-gray-500 focus:outline-none focus:placeholder-gray-400 focus:ring-1 focus:ring-blue-500 focus:border-blue-500\"\n      placeholder=\"Search conversations...\"\n      @input=\"handleSearch\"\n    /&gt;\n    &lt;div\n      v-if=\"searchQuery\"\n      class=\"absolute inset-y-0 right-0 pr-3 flex items-center\"\n    &gt;\n      &lt;button\n        @click=\"clearSearch\"\n        class=\"text-gray-400 hover:text-gray-600\"\n      &gt;\n        &lt;XIcon class=\"h-5 w-5\" /&gt;\n      &lt;/button&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script setup lang=\"ts\"&gt;\nimport { ref, watch } from 'vue'\nimport { useSearchStore } from '@/stores/search'\nimport { useDebounce } from '@/composables/useDebounce'\n\nconst searchStore = useSearchStore()\nconst searchQuery = ref('')\n\nconst debouncedSearchQuery = useDebounce(searchQuery, 300)\n\nwatch(debouncedSearchQuery, (newQuery) =&gt; {\n  searchStore.setQuery(newQuery)\n})\n\nconst handleSearch = () =&gt; {\n  // Search is handled by the watcher\n}\n\nconst clearSearch = () =&gt; {\n  searchQuery.value = ''\n  searchStore.setQuery('')\n}\n&lt;/script&gt;\n</code></pre>"},{"location":"04_vue_js_dashboard/#responsive-design","title":"Responsive Design","text":""},{"location":"04_vue_js_dashboard/#mobile-first-layout","title":"Mobile-First Layout","text":"<pre><code>&lt;!-- views/Dashboard.vue --&gt;\n&lt;template&gt;\n  &lt;div class=\"min-h-screen bg-gray-50\"&gt;\n    &lt;!-- Header --&gt;\n    &lt;header class=\"bg-white shadow-sm border-b\"&gt;\n      &lt;div class=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\"&gt;\n        &lt;div class=\"flex justify-between items-center h-16\"&gt;\n          &lt;h1 class=\"text-xl font-semibold text-gray-900\"&gt;\n            FastOpp Dashboard\n          &lt;/h1&gt;\n          &lt;div class=\"flex items-center space-x-4\"&gt;\n            &lt;SearchBar /&gt;\n            &lt;button\n              @click=\"showNewConversationModal = true\"\n              class=\"bg-blue-600 text-white px-4 py-2 rounded-md hover:bg-blue-700 transition-colors\"\n            &gt;\n              New Conversation\n            &lt;/button&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/header&gt;\n\n    &lt;!-- Main Content --&gt;\n    &lt;div class=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-6\"&gt;\n      &lt;div class=\"grid grid-cols-1 lg:grid-cols-4 gap-6\"&gt;\n        &lt;!-- Sidebar --&gt;\n        &lt;aside class=\"lg:col-span-1\"&gt;\n          &lt;div class=\"bg-white rounded-lg shadow-sm p-4\"&gt;\n            &lt;h2 class=\"text-lg font-medium text-gray-900 mb-4\"&gt;Folders&lt;/h2&gt;\n            &lt;FolderTree /&gt;\n          &lt;/div&gt;\n        &lt;/aside&gt;\n\n        &lt;!-- Main Content --&gt;\n        &lt;main class=\"lg:col-span-3\"&gt;\n          &lt;div class=\"bg-white rounded-lg shadow-sm\"&gt;\n            &lt;div class=\"p-4 border-b\"&gt;\n              &lt;h2 class=\"text-lg font-medium text-gray-900\"&gt;\n                Conversations\n                &lt;span class=\"text-sm text-gray-500 ml-2\"&gt;\n                  ({{ conversations.length }})\n                &lt;/span&gt;\n              &lt;/h2&gt;\n            &lt;/div&gt;\n            &lt;div class=\"p-4\"&gt;\n              &lt;ConversationList :conversations=\"conversations\" /&gt;\n            &lt;/div&gt;\n          &lt;/div&gt;\n        &lt;/main&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n\n    &lt;!-- Modals --&gt;\n    &lt;NewConversationModal\n      v-if=\"showNewConversationModal\"\n      @close=\"showNewConversationModal = false\"\n    /&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n\n&lt;script setup lang=\"ts\"&gt;\nimport { ref, onMounted } from 'vue'\nimport { useConversations } from '@/composables/useConversations'\nimport SearchBar from '@/components/SearchBar.vue'\nimport FolderTree from '@/components/FolderTree.vue'\nimport ConversationList from '@/components/ConversationList.vue'\nimport NewConversationModal from '@/components/NewConversationModal.vue'\n\nconst { conversations, fetchConversations } = useConversations()\nconst showNewConversationModal = ref(false)\n\nonMounted(() =&gt; {\n  fetchConversations()\n})\n&lt;/script&gt;\n</code></pre>"},{"location":"04_vue_js_dashboard/#testing","title":"Testing","text":""},{"location":"04_vue_js_dashboard/#component-tests","title":"Component Tests","text":"<pre><code>// tests/components/ConversationCard.test.ts\nimport { mount } from '@vue/test-utils'\nimport { createPinia, setActivePinia } from 'pinia'\nimport ConversationCard from '@/components/ConversationCard.vue'\nimport type { Conversation } from '@/types'\n\ndescribe('ConversationCard', () =&gt; {\n  beforeEach(() =&gt; {\n    setActivePinia(createPinia())\n  })\n\n  it('renders conversation title', () =&gt; {\n    const conversation: Conversation = {\n      id: '1',\n      title: 'Test Conversation',\n      createdAt: '2024-01-01T00:00:00Z',\n      updatedAt: '2024-01-01T00:00:00Z',\n      isActive: true\n    }\n\n    const wrapper = mount(ConversationCard, {\n      props: { conversation }\n    })\n\n    expect(wrapper.text()).toContain('Test Conversation')\n  })\n\n  it('emits click event when clicked', async () =&gt; {\n    const conversation: Conversation = {\n      id: '1',\n      title: 'Test Conversation',\n      createdAt: '2024-01-01T00:00:00Z',\n      updatedAt: '2024-01-01T00:00:00Z',\n      isActive: true\n    }\n\n    const wrapper = mount(ConversationCard, {\n      props: { conversation }\n    })\n\n    await wrapper.trigger('click')\n    expect(wrapper.emitted('click')).toBeTruthy()\n  })\n})\n</code></pre>"},{"location":"04_vue_js_dashboard/#success-criteria","title":"Success Criteria","text":""},{"location":"04_vue_js_dashboard/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Conversation Management - CRUD operations for conversations</li> <li> Folder Organization - Hierarchical folder structure</li> <li> Search &amp; Filter - Real-time search functionality</li> <li> Responsive Design - Works on all screen sizes</li> <li> State Management - Clean Pinia store implementation</li> <li> TypeScript - Type-safe development</li> <li> Component Architecture - Reusable, maintainable components</li> <li> Error Handling - Graceful error states</li> </ul>"},{"location":"04_vue_js_dashboard/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"04_vue_js_dashboard/#advanced-features","title":"Advanced Features","text":"<ul> <li> Real-time Updates - WebSocket integration</li> <li> Offline Support - Service worker implementation</li> <li> Dark Mode - Theme switching</li> <li> Keyboard Shortcuts - Power user features</li> <li> Bulk Operations - Multi-select actions</li> <li> Export/Import - Data portability</li> <li> PWA Features - Installable web app</li> <li> Performance Optimization - Lazy loading, virtual scrolling</li> </ul>"},{"location":"04_vue_js_dashboard/#getting-started","title":"Getting Started","text":""},{"location":"04_vue_js_dashboard/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Create Vue project - <code>npm create vue@latest fastopp-vue</code></li> <li>Install dependencies - Add Pinia, Axios, Tailwind CSS</li> <li>Set up project structure - Create the folder structure above</li> <li>Configure TypeScript - Set up type definitions</li> <li>Create stores - Implement Pinia stores</li> <li>Build components - Start with basic components</li> <li>Add routing - Set up Vue Router</li> <li>Integrate with API - Connect to FastOpp backend</li> </ol>"},{"location":"04_vue_js_dashboard/#dependencies","title":"Dependencies","text":""},{"location":"04_vue_js_dashboard/#packagejson","title":"package.json","text":"<pre><code>{\n  \"dependencies\": {\n    \"vue\": \"^3.3.4\",\n    \"vue-router\": \"^4.2.4\",\n    \"pinia\": \"^2.1.6\",\n    \"axios\": \"^1.5.0\",\n    \"@headlessui/vue\": \"^1.7.16\",\n    \"@heroicons/vue\": \"^2.0.18\"\n  },\n  \"devDependencies\": {\n    \"@vitejs/plugin-vue\": \"^4.3.4\",\n    \"typescript\": \"^5.1.6\",\n    \"vite\": \"^4.4.9\",\n    \"tailwindcss\": \"^3.3.3\",\n    \"autoprefixer\": \"^10.4.15\",\n    \"postcss\": \"^8.4.29\",\n    \"@vue/test-utils\": \"^2.4.1\",\n    \"vitest\": \"^0.34.3\"\n  }\n}\n</code></pre>"},{"location":"04_vue_js_dashboard/#resources","title":"Resources","text":""},{"location":"04_vue_js_dashboard/#helpful-links","title":"Helpful Links","text":"<ul> <li>Vue.js Documentation - https://vuejs.org/</li> <li>Pinia - https://pinia.vuejs.org/</li> <li>Vue Router - https://router.vuejs.org/</li> <li>Tailwind CSS - https://tailwindcss.com/</li> <li>Vite - https://vitejs.dev/</li> <li>TypeScript - https://www.typescriptlang.org/</li> </ul>"},{"location":"04_vue_js_dashboard/#lets-build","title":"Let's Build!","text":""},{"location":"04_vue_js_dashboard/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Vue.js 3 with Composition API - Modern state management with Pinia - TypeScript integration - Component-based architecture - Reactive programming patterns - Performance optimization</p> <p>Start with the basic app structure and build up from there!</p>"},{"location":"04_vue_js_dashboard/#next-steps","title":"Next Steps","text":""},{"location":"04_vue_js_dashboard/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Deploy your app - Use Vercel, Netlify, or similar</li> <li>Test thoroughly - Ensure all features work correctly</li> <li>Share your code - Create a GitHub repository</li> <li>Document your approach - Write a comprehensive README</li> <li>Move to the next track - Try mobile development or collaborative features next!</li> </ol> <p>Happy coding! \ud83d\ude80</p>"},{"location":"05_mobile_first_design/","title":"Mobile-First Design","text":""},{"location":"05_mobile_first_design/#mobile-first-design-assignment","title":"Mobile-First Design Assignment","text":""},{"location":"05_mobile_first_design/#touch-optimized-conversation-management","title":"Touch-Optimized Conversation Management","text":"<p>Build a mobile-first interface for FastOpp</p>"},{"location":"05_mobile_first_design/#assignment-overview","title":"Assignment Overview","text":""},{"location":"05_mobile_first_design/#what-youll-build","title":"What You'll Build","text":"<p>A mobile-first web application that provides an optimized touch interface for FastOpp, featuring: - Touch-optimized interactions - Swipe gestures, touch targets - Progressive Web App - Installable, offline-capable - Responsive design - Works on phones, tablets, and desktops - Gesture-based navigation - Intuitive mobile patterns - Performance optimization - Fast loading on mobile networks</p>"},{"location":"05_mobile_first_design/#problem-statement","title":"Problem Statement","text":""},{"location":"05_mobile_first_design/#mobile-usage-challenges","title":"Mobile Usage Challenges","text":"<p>The current FastOpp UI, while responsive, has limitations for mobile users: - Desktop-first design - Not optimized for touch interactions - Small touch targets - Hard to tap on mobile devices - Complex navigation - Too many clicks to access features - Poor offline experience - Requires constant internet connection - Slow loading - Not optimized for mobile networks</p>"},{"location":"05_mobile_first_design/#your-solution","title":"Your Solution","text":""},{"location":"05_mobile_first_design/#mobile-first-interface","title":"Mobile-First Interface","text":"<p>Create a mobile-first application that addresses these limitations:</p> <ol> <li>Touch-Optimized UI - Large touch targets, swipe gestures</li> <li>Progressive Web App - Installable, works offline</li> <li>Gesture Navigation - Swipe to navigate, pull to refresh</li> <li>Mobile-First Layout - Designed for small screens first</li> <li>Performance Focused - Fast loading, smooth animations</li> </ol>"},{"location":"05_mobile_first_design/#technical-requirements","title":"Technical Requirements","text":""},{"location":"05_mobile_first_design/#tech-stack-options","title":"Tech Stack Options","text":"<p>Option 1: React Native Web - React Native with Expo - Cross-platform mobile and web - Native performance</p> <p>Option 2: Flutter Web - Flutter with web support - Single codebase for all platforms - Material Design components</p> <p>Option 3: PWA with Framework - React, Vue, or Angular - Service Worker for offline support - Web App Manifest for installation</p>"},{"location":"05_mobile_first_design/#project-structure","title":"Project Structure","text":""},{"location":"05_mobile_first_design/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>src/\n\u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 mobile/\n\u2502   \u2502   \u251c\u2500\u2500 ConversationCard.tsx\n\u2502   \u2502   \u251c\u2500\u2500 SwipeableCard.tsx\n\u2502   \u2502   \u251c\u2500\u2500 BottomSheet.tsx\n\u2502   \u2502   \u2514\u2500\u2500 TouchableList.tsx\n\u2502   \u251c\u2500\u2500 gestures/\n\u2502   \u2502   \u251c\u2500\u2500 SwipeGesture.tsx\n\u2502   \u2502   \u251c\u2500\u2500 PullToRefresh.tsx\n\u2502   \u2502   \u2514\u2500\u2500 PinchToZoom.tsx\n\u2502   \u2514\u2500\u2500 shared/\n\u251c\u2500\u2500 hooks/\n\u2502   \u251c\u2500\u2500 useSwipeGesture.ts\n\u2502   \u251c\u2500\u2500 usePullToRefresh.ts\n\u2502   \u2514\u2500\u2500 useOfflineSync.ts\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 pwa.ts\n\u2502   \u251c\u2500\u2500 offline.ts\n\u2502   \u2514\u2500\u2500 push-notifications.ts\n\u2514\u2500\u2500 styles/\n    \u251c\u2500\u2500 mobile.css\n    \u2514\u2500\u2500 animations.css\n</code></pre>"},{"location":"05_mobile_first_design/#core-components","title":"Core Components","text":""},{"location":"05_mobile_first_design/#1-swipeable-conversation-card","title":"1. Swipeable Conversation Card","text":"<pre><code>// components/mobile/SwipeableCard.tsx\nimport React, { useRef } from 'react'\nimport { useSwipeGesture } from '@/hooks/useSwipeGesture'\n\ninterface SwipeableCardProps {\n  conversation: Conversation\n  onSwipeLeft: () =&gt; void\n  onSwipeRight: () =&gt; void\n  onTap: () =&gt; void\n}\n\nconst SwipeableCard: React.FC&lt;SwipeableCardProps&gt; = ({\n  conversation,\n  onSwipeLeft,\n  onSwipeRight,\n  onTap\n}) =&gt; {\n  const cardRef = useRef&lt;HTMLDivElement&gt;(null)\n\n  const { swipeDirection, isDragging } = useSwipeGesture(cardRef, {\n    onSwipeLeft,\n    onSwipeRight,\n    threshold: 100\n  })\n\n  return (\n    &lt;div\n      ref={cardRef}\n      className={`\n        relative bg-white rounded-lg shadow-md p-4 mb-2\n        transition-transform duration-200 ease-out\n        ${isDragging ? 'scale-105 shadow-lg' : ''}\n        ${swipeDirection === 'left' ? 'bg-red-50' : ''}\n        ${swipeDirection === 'right' ? 'bg-green-50' : ''}\n      `}\n      onClick={onTap}\n    &gt;\n      &lt;div className=\"flex items-center justify-between\"&gt;\n        &lt;div className=\"flex-1\"&gt;\n          &lt;h3 className=\"text-lg font-semibold text-gray-900\"&gt;\n            {conversation.title}\n          &lt;/h3&gt;\n          &lt;p className=\"text-sm text-gray-500 mt-1\"&gt;\n            {formatDate(conversation.updatedAt)}\n          &lt;/p&gt;\n        &lt;/div&gt;\n        &lt;div className=\"flex items-center space-x-2\"&gt;\n          {swipeDirection === 'left' &amp;&amp; (\n            &lt;span className=\"text-red-500 text-sm\"&gt;Delete&lt;/span&gt;\n          )}\n          {swipeDirection === 'right' &amp;&amp; (\n            &lt;span className=\"text-green-500 text-sm\"&gt;Archive&lt;/span&gt;\n          )}\n        &lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"05_mobile_first_design/#core-components_1","title":"Core Components","text":""},{"location":"05_mobile_first_design/#2-bottom-sheet-modal","title":"2. Bottom Sheet Modal","text":"<pre><code>// components/mobile/BottomSheet.tsx\nimport React, { useEffect, useRef } from 'react'\nimport { createPortal } from 'react-dom'\n\ninterface BottomSheetProps {\n  isOpen: boolean\n  onClose: () =&gt; void\n  children: React.ReactNode\n  title?: string\n}\n\nconst BottomSheet: React.FC&lt;BottomSheetProps&gt; = ({\n  isOpen,\n  onClose,\n  children,\n  title\n}) =&gt; {\n  const sheetRef = useRef&lt;HTMLDivElement&gt;(null)\n\n  useEffect(() =&gt; {\n    if (isOpen) {\n      document.body.style.overflow = 'hidden'\n    } else {\n      document.body.style.overflow = 'unset'\n    }\n\n    return () =&gt; {\n      document.body.style.overflow = 'unset'\n    }\n  }, [isOpen])\n\n  if (!isOpen) return null\n\n  return createPortal(\n    &lt;div className=\"fixed inset-0 z-50 flex items-end\"&gt;\n      {/* Backdrop */}\n      &lt;div\n        className=\"absolute inset-0 bg-black bg-opacity-50\"\n        onClick={onClose}\n      /&gt;\n\n      {/* Sheet */}\n      &lt;div\n        ref={sheetRef}\n        className=\"relative bg-white rounded-t-lg w-full max-h-[80vh] overflow-hidden\"\n        style={{\n          animation: 'slideUp 0.3s ease-out'\n        }}\n      &gt;\n        {/* Handle */}\n        &lt;div className=\"flex justify-center py-2\"&gt;\n          &lt;div className=\"w-12 h-1 bg-gray-300 rounded-full\" /&gt;\n        &lt;/div&gt;\n\n        {/* Header */}\n        {title &amp;&amp; (\n          &lt;div className=\"px-4 py-3 border-b\"&gt;\n            &lt;h2 className=\"text-lg font-semibold text-gray-900\"&gt;{title}&lt;/h2&gt;\n          &lt;/div&gt;\n        )}\n\n        {/* Content */}\n        &lt;div className=\"px-4 py-4 overflow-y-auto\"&gt;\n          {children}\n        &lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;,\n    document.body\n  )\n}\n</code></pre>"},{"location":"05_mobile_first_design/#gesture-hooks","title":"Gesture Hooks","text":""},{"location":"05_mobile_first_design/#swipe-gesture-hook","title":"Swipe Gesture Hook","text":"<pre><code>// hooks/useSwipeGesture.ts\nimport { useRef, useCallback } from 'react'\n\ninterface SwipeGestureOptions {\n  onSwipeLeft?: () =&gt; void\n  onSwipeRight?: () =&gt; void\n  onSwipeUp?: () =&gt; void\n  onSwipeDown?: () =&gt; void\n  threshold?: number\n}\n\nexport const useSwipeGesture = (\n  elementRef: React.RefObject&lt;HTMLElement&gt;,\n  options: SwipeGestureOptions\n) =&gt; {\n  const startPos = useRef({ x: 0, y: 0 })\n  const currentPos = useRef({ x: 0, y: 0 })\n  const isDragging = useRef(false)\n\n  const handleTouchStart = useCallback((e: TouchEvent) =&gt; {\n    const touch = e.touches[0]\n    startPos.current = { x: touch.clientX, y: touch.clientY }\n    currentPos.current = { x: touch.clientX, y: touch.clientY }\n    isDragging.current = true\n  }, [])\n\n  const handleTouchMove = useCallback((e: TouchEvent) =&gt; {\n    if (!isDragging.current) return\n\n    const touch = e.touches[0]\n    currentPos.current = { x: touch.clientX, y: touch.clientY }\n  }, [])\n\n  const handleTouchEnd = useCallback(() =&gt; {\n    if (!isDragging.current) return\n\n    const deltaX = currentPos.current.x - startPos.current.x\n    const deltaY = currentPos.current.y - startPos.current.y\n    const threshold = options.threshold || 50\n\n    if (Math.abs(deltaX) &gt; Math.abs(deltaY)) {\n      // Horizontal swipe\n      if (deltaX &gt; threshold &amp;&amp; options.onSwipeRight) {\n        options.onSwipeRight()\n      } else if (deltaX &lt; -threshold &amp;&amp; options.onSwipeLeft) {\n        options.onSwipeLeft()\n      }\n    } else {\n      // Vertical swipe\n      if (deltaY &gt; threshold &amp;&amp; options.onSwipeDown) {\n        options.onSwipeDown()\n      } else if (deltaY &lt; -threshold &amp;&amp; options.onSwipeUp) {\n        options.onSwipeUp()\n      }\n    }\n\n    isDragging.current = false\n  }, [options])\n\n  useEffect(() =&gt; {\n    const element = elementRef.current\n    if (!element) return\n\n    element.addEventListener('touchstart', handleTouchStart)\n    element.addEventListener('touchmove', handleTouchMove)\n    element.addEventListener('touchend', handleTouchEnd)\n\n    return () =&gt; {\n      element.removeEventListener('touchstart', handleTouchStart)\n      element.removeEventListener('touchmove', handleTouchMove)\n      element.removeEventListener('touchend', handleTouchEnd)\n    }\n  }, [elementRef, handleTouchStart, handleTouchMove, handleTouchEnd])\n\n  return {\n    isDragging: isDragging.current,\n    swipeDirection: isDragging.current ? \n      (Math.abs(currentPos.current.x - startPos.current.x) &gt; Math.abs(currentPos.current.y - startPos.current.y) ?\n        (currentPos.current.x &gt; startPos.current.x ? 'right' : 'left') :\n        (currentPos.current.y &gt; startPos.current.y ? 'down' : 'up')\n      ) : null\n  }\n}\n</code></pre>"},{"location":"05_mobile_first_design/#pwa-features","title":"PWA Features","text":""},{"location":"05_mobile_first_design/#service-worker","title":"Service Worker","text":"<pre><code>// public/sw.js\nconst CACHE_NAME = 'fastopp-v1'\nconst urlsToCache = [\n  '/',\n  '/static/js/bundle.js',\n  '/static/css/main.css',\n  '/manifest.json'\n]\n\nself.addEventListener('install', (event) =&gt; {\n  event.waitUntil(\n    caches.open(CACHE_NAME)\n      .then((cache) =&gt; cache.addAll(urlsToCache))\n  )\n})\n\nself.addEventListener('fetch', (event) =&gt; {\n  event.respondWith(\n    caches.match(event.request)\n      .then((response) =&gt; {\n        // Return cached version or fetch from network\n        return response || fetch(event.request)\n      })\n  )\n})\n\nself.addEventListener('sync', (event) =&gt; {\n  if (event.tag === 'background-sync') {\n    event.waitUntil(doBackgroundSync())\n  }\n})\n\nasync function doBackgroundSync() {\n  // Sync offline data when connection is restored\n  const offlineData = await getOfflineData()\n  for (const item of offlineData) {\n    try {\n      await syncItem(item)\n    } catch (error) {\n      console.error('Sync failed:', error)\n    }\n  }\n}\n</code></pre>"},{"location":"05_mobile_first_design/#pwa-features_1","title":"PWA Features","text":""},{"location":"05_mobile_first_design/#web-app-manifest","title":"Web App Manifest","text":"<pre><code>// public/manifest.json\n{\n  \"name\": \"FastOpp Mobile\",\n  \"short_name\": \"FastOpp\",\n  \"description\": \"Mobile conversation management for FastOpp\",\n  \"start_url\": \"/\",\n  \"display\": \"standalone\",\n  \"background_color\": \"#ffffff\",\n  \"theme_color\": \"#3B82F6\",\n  \"orientation\": \"portrait\",\n  \"icons\": [\n    {\n      \"src\": \"/icons/icon-192x192.png\",\n      \"sizes\": \"192x192\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/icon-512x512.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\"\n    }\n  ],\n  \"categories\": [\"productivity\", \"business\"],\n  \"screenshots\": [\n    {\n      \"src\": \"/screenshots/mobile-1.png\",\n      \"sizes\": \"390x844\",\n      \"type\": \"image/png\",\n      \"form_factor\": \"narrow\"\n    }\n  ]\n}\n</code></pre>"},{"location":"05_mobile_first_design/#offline-support","title":"Offline Support","text":""},{"location":"05_mobile_first_design/#offline-sync-hook","title":"Offline Sync Hook","text":"<pre><code>// hooks/useOfflineSync.ts\nimport { useState, useEffect } from 'react'\nimport { useConversationStore } from '@/stores/conversation'\n\nexport const useOfflineSync = () =&gt; {\n  const [isOnline, setIsOnline] = useState(navigator.onLine)\n  const [pendingChanges, setPendingChanges] = useState&lt;any[]&gt;([])\n  const conversationStore = useConversationStore()\n\n  useEffect(() =&gt; {\n    const handleOnline = () =&gt; {\n      setIsOnline(true)\n      syncPendingChanges()\n    }\n\n    const handleOffline = () =&gt; {\n      setIsOnline(false)\n    }\n\n    window.addEventListener('online', handleOnline)\n    window.addEventListener('offline', handleOffline)\n\n    return () =&gt; {\n      window.removeEventListener('online', handleOnline)\n      window.removeEventListener('offline', handleOffline)\n    }\n  }, [])\n\n  const syncPendingChanges = async () =&gt; {\n    if (pendingChanges.length === 0) return\n\n    try {\n      for (const change of pendingChanges) {\n        await conversationStore.syncChange(change)\n      }\n      setPendingChanges([])\n    } catch (error) {\n      console.error('Sync failed:', error)\n    }\n  }\n\n  const queueChange = (change: any) =&gt; {\n    if (isOnline) {\n      // Try to sync immediately\n      conversationStore.syncChange(change).catch(() =&gt; {\n        setPendingChanges(prev =&gt; [...prev, change])\n      })\n    } else {\n      // Queue for later sync\n      setPendingChanges(prev =&gt; [...prev, change])\n    }\n  }\n\n  return {\n    isOnline,\n    pendingChanges: pendingChanges.length,\n    queueChange\n  }\n}\n</code></pre>"},{"location":"05_mobile_first_design/#mobile-layout","title":"Mobile Layout","text":""},{"location":"05_mobile_first_design/#responsive-grid","title":"Responsive Grid","text":"<pre><code>// components/mobile/ConversationGrid.tsx\nimport React from 'react'\nimport { SwipeableCard } from './SwipeableCard'\n\ninterface ConversationGridProps {\n  conversations: Conversation[]\n  onConversationTap: (id: string) =&gt; void\n  onConversationSwipeLeft: (id: string) =&gt; void\n  onConversationSwipeRight: (id: string) =&gt; void\n}\n\nconst ConversationGrid: React.FC&lt;ConversationGridProps&gt; = ({\n  conversations,\n  onConversationTap,\n  onConversationSwipeLeft,\n  onConversationSwipeRight\n}) =&gt; {\n  return (\n    &lt;div className=\"grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-4 p-4\"&gt;\n      {conversations.map((conversation) =&gt; (\n        &lt;SwipeableCard\n          key={conversation.id}\n          conversation={conversation}\n          onTap={() =&gt; onConversationTap(conversation.id)}\n          onSwipeLeft={() =&gt; onConversationSwipeLeft(conversation.id)}\n          onSwipeRight={() =&gt; onConversationSwipeRight(conversation.id)}\n        /&gt;\n      ))}\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"05_mobile_first_design/#performance-optimization","title":"Performance Optimization","text":""},{"location":"05_mobile_first_design/#lazy-loading","title":"Lazy Loading","text":"<pre><code>// components/mobile/LazyConversationList.tsx\nimport React, { useState, useEffect, useRef } from 'react'\nimport { useInView } from 'react-intersection-observer'\n\ninterface LazyConversationListProps {\n  conversations: Conversation[]\n  onLoadMore: () =&gt; void\n  hasMore: boolean\n}\n\nconst LazyConversationList: React.FC&lt;LazyConversationListProps&gt; = ({\n  conversations,\n  onLoadMore,\n  hasMore\n}) =&gt; {\n  const [visibleConversations, setVisibleConversations] = useState&lt;Conversation[]&gt;([])\n  const [page, setPage] = useState(0)\n  const itemsPerPage = 20\n\n  const { ref: loadMoreRef, inView } = useInView({\n    threshold: 0.1,\n    triggerOnce: false\n  })\n\n  useEffect(() =&gt; {\n    const startIndex = page * itemsPerPage\n    const endIndex = startIndex + itemsPerPage\n    const newConversations = conversations.slice(0, endIndex)\n    setVisibleConversations(newConversations)\n  }, [conversations, page])\n\n  useEffect(() =&gt; {\n    if (inView &amp;&amp; hasMore) {\n      setPage(prev =&gt; prev + 1)\n      onLoadMore()\n    }\n  }, [inView, hasMore, onLoadMore])\n\n  return (\n    &lt;div className=\"space-y-4\"&gt;\n      {visibleConversations.map((conversation) =&gt; (\n        &lt;ConversationCard\n          key={conversation.id}\n          conversation={conversation}\n        /&gt;\n      ))}\n      {hasMore &amp;&amp; (\n        &lt;div ref={loadMoreRef} className=\"flex justify-center py-4\"&gt;\n          &lt;div className=\"animate-spin rounded-full h-8 w-8 border-b-2 border-blue-600\" /&gt;\n        &lt;/div&gt;\n      )}\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"05_mobile_first_design/#testing","title":"Testing","text":""},{"location":"05_mobile_first_design/#mobile-testing","title":"Mobile Testing","text":"<pre><code>// tests/mobile/ConversationCard.test.tsx\nimport { render, fireEvent, waitFor } from '@testing-library/react'\nimport { SwipeableCard } from '@/components/mobile/SwipeableCard'\n\ndescribe('SwipeableCard', () =&gt; {\n  it('handles swipe left gesture', async () =&gt; {\n    const onSwipeLeft = jest.fn()\n    const conversation = {\n      id: '1',\n      title: 'Test Conversation',\n      updatedAt: '2024-01-01T00:00:00Z'\n    }\n\n    const { getByText } = render(\n      &lt;SwipeableCard\n        conversation={conversation}\n        onSwipeLeft={onSwipeLeft}\n        onSwipeRight={jest.fn()}\n        onTap={jest.fn()}\n      /&gt;\n    )\n\n    const card = getByText('Test Conversation').closest('div')\n\n    // Simulate swipe left\n    fireEvent.touchStart(card!, { touches: [{ clientX: 100, clientY: 0 }] })\n    fireEvent.touchMove(card!, { touches: [{ clientX: 0, clientY: 0 }] })\n    fireEvent.touchEnd(card!)\n\n    await waitFor(() =&gt; {\n      expect(onSwipeLeft).toHaveBeenCalled()\n    })\n  })\n})\n</code></pre>"},{"location":"05_mobile_first_design/#success-criteria","title":"Success Criteria","text":""},{"location":"05_mobile_first_design/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Touch-Optimized UI - Large touch targets, swipe gestures</li> <li> PWA Features - Installable, offline-capable</li> <li> Responsive Design - Works on all screen sizes</li> <li> Gesture Navigation - Swipe, pull-to-refresh</li> <li> Performance - Fast loading, smooth animations</li> <li> Offline Support - Works without internet connection</li> <li> Mobile-First Layout - Designed for small screens first</li> <li> Accessibility - Screen reader support, keyboard navigation</li> </ul>"},{"location":"05_mobile_first_design/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"05_mobile_first_design/#advanced-features","title":"Advanced Features","text":"<ul> <li> Push Notifications - Real-time updates</li> <li> Haptic Feedback - Vibration on interactions</li> <li> Voice Commands - Speech-to-text search</li> <li> Biometric Auth - Fingerprint/face recognition</li> <li> Dark Mode - Theme switching</li> <li> Multi-language - Internationalization</li> <li> Advanced Gestures - Pinch to zoom, long press</li> <li> Background Sync - Sync when app is closed</li> </ul>"},{"location":"05_mobile_first_design/#getting-started","title":"Getting Started","text":""},{"location":"05_mobile_first_design/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Choose your approach - React Native Web, Flutter, or PWA</li> <li>Set up the project - Create new project with mobile focus</li> <li>Configure PWA - Add manifest and service worker</li> <li>Implement gestures - Add swipe and touch interactions</li> <li>Build mobile components - Create touch-optimized UI</li> <li>Add offline support - Implement caching and sync</li> <li>Test on devices - Use real devices for testing</li> <li>Optimize performance - Lazy loading, image optimization</li> </ol>"},{"location":"05_mobile_first_design/#resources","title":"Resources","text":""},{"location":"05_mobile_first_design/#helpful-links","title":"Helpful Links","text":"<ul> <li>PWA Documentation - https://web.dev/progressive-web-apps/</li> <li>Touch Events - https://developer.mozilla.org/en-US/docs/Web/API/Touch_events</li> <li>Service Workers - https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API</li> <li>React Native Web - https://necolas.github.io/react-native-web/</li> <li>Flutter Web - https://flutter.dev/web</li> <li>Mobile Testing - https://web.dev/test-mobile/</li> </ul>"},{"location":"05_mobile_first_design/#lets-build","title":"Let's Build!","text":""},{"location":"05_mobile_first_design/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Mobile-first design principles - Touch gesture implementation - Progressive Web App development - Offline-first architecture - Performance optimization for mobile - Cross-platform development</p> <p>Start with the basic mobile layout and build up from there!</p>"},{"location":"05_mobile_first_design/#next-steps","title":"Next Steps","text":""},{"location":"05_mobile_first_design/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Test on real devices - Use various phones and tablets</li> <li>Deploy as PWA - Make it installable</li> <li>Share your code - Create a GitHub repository</li> <li>Document your approach - Write a comprehensive README</li> <li>Move to the next track - Try collaborative features or advanced UI patterns next!</li> </ol> <p>Happy coding! \ud83d\ude80</p>"},{"location":"06_collaborative_workspace/","title":"Collaborative Workspace","text":""},{"location":"06_collaborative_workspace/#collaborative-workspace-assignment","title":"Collaborative Workspace Assignment","text":""},{"location":"06_collaborative_workspace/#real-time-team-collaboration","title":"Real-Time Team Collaboration","text":"<p>Build a collaborative workspace for FastOpp</p>"},{"location":"06_collaborative_workspace/#assignment-overview","title":"Assignment Overview","text":""},{"location":"06_collaborative_workspace/#what-youll-build","title":"What You'll Build","text":"<p>A collaborative workspace application that enables real-time team collaboration on FastOpp conversations, featuring: - Real-time collaboration - Live updates when team members make changes - User presence - See who's online and what they're working on - Shared workspaces - Team-based conversation organization - Comment system - Discuss conversations with team members - Permission management - Control who can access what</p>"},{"location":"06_collaborative_workspace/#problem-statement","title":"Problem Statement","text":""},{"location":"06_collaborative_workspace/#team-collaboration-challenges","title":"Team Collaboration Challenges","text":"<p>The current FastOpp system, while powerful, lacks team collaboration features: - No real-time updates - Changes aren't reflected immediately - No user presence - Can't see who's online or working on what - No shared workspaces - Conversations are isolated per user - No commenting system - Can't discuss conversations with team - No permission control - All users have the same access level</p>"},{"location":"06_collaborative_workspace/#your-solution","title":"Your Solution","text":""},{"location":"06_collaborative_workspace/#collaborative-workspace","title":"Collaborative Workspace","text":"<p>Create a collaborative workspace that addresses these limitations:</p> <ol> <li>Real-time Updates - WebSocket-based live collaboration</li> <li>User Presence - Show online status and current activity</li> <li>Shared Workspaces - Team-based conversation organization</li> <li>Comment System - Threaded discussions on conversations</li> <li>Permission Management - Role-based access control</li> </ol>"},{"location":"06_collaborative_workspace/#technical-requirements","title":"Technical Requirements","text":""},{"location":"06_collaborative_workspace/#tech-stack","title":"Tech Stack","text":"<ul> <li>Frontend Framework - React, Vue, or Angular</li> <li>Real-time Communication - Socket.io or WebSocket</li> <li>State Management - Redux, Pinia, or NgRx</li> <li>Authentication - JWT with role-based permissions</li> <li>Database - PostgreSQL with real-time subscriptions</li> <li>Backend - FastAPI with WebSocket support</li> </ul>"},{"location":"06_collaborative_workspace/#project-structure","title":"Project Structure","text":""},{"location":"06_collaborative_workspace/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>src/\n\u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 collaboration/\n\u2502   \u2502   \u251c\u2500\u2500 UserPresence.tsx\n\u2502   \u2502   \u251c\u2500\u2500 CommentThread.tsx\n\u2502   \u2502   \u251c\u2500\u2500 SharedWorkspace.tsx\n\u2502   \u2502   \u2514\u2500\u2500 PermissionManager.tsx\n\u2502   \u251c\u2500\u2500 realtime/\n\u2502   \u2502   \u251c\u2500\u2500 RealtimeProvider.tsx\n\u2502   \u2502   \u251c\u2500\u2500 PresenceIndicator.tsx\n\u2502   \u2502   \u2514\u2500\u2500 ActivityFeed.tsx\n\u2502   \u2514\u2500\u2500 shared/\n\u251c\u2500\u2500 hooks/\n\u2502   \u251c\u2500\u2500 useWebSocket.ts\n\u2502   \u251c\u2500\u2500 usePresence.ts\n\u2502   \u251c\u2500\u2500 useComments.ts\n\u2502   \u2514\u2500\u2500 usePermissions.ts\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 websocket.ts\n\u2502   \u251c\u2500\u2500 collaboration.ts\n\u2502   \u2514\u2500\u2500 permissions.ts\n\u2514\u2500\u2500 stores/\n    \u251c\u2500\u2500 collaboration.ts\n    \u251c\u2500\u2500 presence.ts\n    \u2514\u2500\u2500 comments.ts\n</code></pre>"},{"location":"06_collaborative_workspace/#core-components","title":"Core Components","text":""},{"location":"06_collaborative_workspace/#1-user-presence-component","title":"1. User Presence Component","text":"<pre><code>// components/collaboration/UserPresence.tsx\nimport React from 'react'\nimport { usePresence } from '@/hooks/usePresence'\n\ninterface UserPresenceProps {\n  conversationId: string\n}\n\nconst UserPresence: React.FC&lt;UserPresenceProps&gt; = ({ conversationId }) =&gt; {\n  const { onlineUsers, currentUser } = usePresence(conversationId)\n\n  return (\n    &lt;div className=\"flex items-center space-x-2\"&gt;\n      &lt;span className=\"text-sm text-gray-500\"&gt;Online:&lt;/span&gt;\n      &lt;div className=\"flex -space-x-2\"&gt;\n        {onlineUsers.map((user) =&gt; (\n          &lt;div\n            key={user.id}\n            className=\"relative\"\n            title={`${user.name} - ${user.activity}`}\n          &gt;\n            &lt;div className=\"w-8 h-8 rounded-full bg-blue-500 flex items-center justify-center text-white text-xs font-medium\"&gt;\n              {user.name[0].toUpperCase()}\n            &lt;/div&gt;\n            &lt;div className=\"absolute -bottom-1 -right-1 w-3 h-3 bg-green-500 rounded-full border-2 border-white\" /&gt;\n          &lt;/div&gt;\n        ))}\n      &lt;/div&gt;\n      {onlineUsers.length &gt; 3 &amp;&amp; (\n        &lt;span className=\"text-sm text-gray-500\"&gt;\n          +{onlineUsers.length - 3} more\n        &lt;/span&gt;\n      )}\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"06_collaborative_workspace/#core-components_1","title":"Core Components","text":""},{"location":"06_collaborative_workspace/#2-comment-thread-component","title":"2. Comment Thread Component","text":"<pre><code>// components/collaboration/CommentThread.tsx\nimport React, { useState } from 'react'\nimport { useComments } from '@/hooks/useComments'\nimport { useAuth } from '@/hooks/useAuth'\n\ninterface CommentThreadProps {\n  conversationId: string\n  parentId?: string\n}\n\nconst CommentThread: React.FC&lt;CommentThreadProps&gt; = ({\n  conversationId,\n  parentId\n}) =&gt; {\n  const { comments, addComment, updateComment, deleteComment } = useComments(conversationId, parentId)\n  const { user } = useAuth()\n  const [newComment, setNewComment] = useState('')\n  const [editingComment, setEditingComment] = useState&lt;string | null&gt;(null)\n\n  const handleSubmit = async (e: React.FormEvent) =&gt; {\n    e.preventDefault()\n    if (!newComment.trim()) return\n\n    try {\n      await addComment({\n        content: newComment,\n        conversationId,\n        parentId\n      })\n      setNewComment('')\n    } catch (error) {\n      console.error('Failed to add comment:', error)\n    }\n  }\n\n  const handleEdit = async (commentId: string, content: string) =&gt; {\n    try {\n      await updateComment(commentId, { content })\n      setEditingComment(null)\n    } catch (error) {\n      console.error('Failed to update comment:', error)\n    }\n  }\n\n  const handleDelete = async (commentId: string) =&gt; {\n    if (confirm('Are you sure you want to delete this comment?')) {\n      try {\n        await deleteComment(commentId)\n      } catch (error) {\n        console.error('Failed to delete comment:', error)\n      }\n    }\n  }\n\n  return (\n    &lt;div className=\"space-y-4\"&gt;\n      {/* Comment Form */}\n      &lt;form onSubmit={handleSubmit} className=\"flex space-x-2\"&gt;\n        &lt;input\n          type=\"text\"\n          value={newComment}\n          onChange={(e) =&gt; setNewComment(e.target.value)}\n          placeholder=\"Add a comment...\"\n          className=\"flex-1 px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500\"\n        /&gt;\n        &lt;button\n          type=\"submit\"\n          disabled={!newComment.trim()}\n          className=\"px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 disabled:opacity-50\"\n        &gt;\n          Comment\n        &lt;/button&gt;\n      &lt;/form&gt;\n\n      {/* Comments List */}\n      &lt;div className=\"space-y-3\"&gt;\n        {comments.map((comment) =&gt; (\n          &lt;div key={comment.id} className=\"bg-gray-50 rounded-lg p-3\"&gt;\n            &lt;div className=\"flex items-start justify-between\"&gt;\n              &lt;div className=\"flex-1\"&gt;\n                &lt;div className=\"flex items-center space-x-2\"&gt;\n                  &lt;span className=\"font-medium text-sm\"&gt;{comment.author.name}&lt;/span&gt;\n                  &lt;span className=\"text-xs text-gray-500\"&gt;\n                    {formatDate(comment.createdAt)}\n                  &lt;/span&gt;\n                  {comment.updatedAt !== comment.createdAt &amp;&amp; (\n                    &lt;span className=\"text-xs text-gray-400\"&gt;(edited)&lt;/span&gt;\n                  )}\n                &lt;/div&gt;\n                {editingComment === comment.id ? (\n                  &lt;EditCommentForm\n                    comment={comment}\n                    onSave={(content) =&gt; handleEdit(comment.id, content)}\n                    onCancel={() =&gt; setEditingComment(null)}\n                  /&gt;\n                ) : (\n                  &lt;p className=\"text-sm text-gray-700 mt-1\"&gt;{comment.content}&lt;/p&gt;\n                )}\n              &lt;/div&gt;\n              {comment.author.id === user?.id &amp;&amp; (\n                &lt;div className=\"flex space-x-1\"&gt;\n                  &lt;button\n                    onClick={() =&gt; setEditingComment(comment.id)}\n                    className=\"text-xs text-blue-600 hover:text-blue-800\"\n                  &gt;\n                    Edit\n                  &lt;/button&gt;\n                  &lt;button\n                    onClick={() =&gt; handleDelete(comment.id)}\n                    className=\"text-xs text-red-600 hover:text-red-800\"\n                  &gt;\n                    Delete\n                  &lt;/button&gt;\n                &lt;/div&gt;\n              )}\n            &lt;/div&gt;\n          &lt;/div&gt;\n        ))}\n      &lt;/div&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"06_collaborative_workspace/#real-time-communication","title":"Real-time Communication","text":""},{"location":"06_collaborative_workspace/#websocket-hook","title":"WebSocket Hook","text":"<pre><code>// hooks/useWebSocket.ts\nimport { useEffect, useRef, useState } from 'react'\nimport { io, Socket } from 'socket.io-client'\n\ninterface WebSocketHook {\n  socket: Socket | null\n  isConnected: boolean\n  emit: (event: string, data: any) =&gt; void\n  on: (event: string, callback: (data: any) =&gt; void) =&gt; void\n  off: (event: string, callback: (data: any) =&gt; void) =&gt; void\n}\n\nexport const useWebSocket = (url: string): WebSocketHook =&gt; {\n  const [socket, setSocket] = useState&lt;Socket | null&gt;(null)\n  const [isConnected, setIsConnected] = useState(false)\n  const socketRef = useRef&lt;Socket | null&gt;(null)\n\n  useEffect(() =&gt; {\n    const newSocket = io(url, {\n      auth: {\n        token: localStorage.getItem('auth_token')\n      }\n    })\n\n    newSocket.on('connect', () =&gt; {\n      setIsConnected(true)\n      console.log('Connected to WebSocket')\n    })\n\n    newSocket.on('disconnect', () =&gt; {\n      setIsConnected(false)\n      console.log('Disconnected from WebSocket')\n    })\n\n    newSocket.on('error', (error) =&gt; {\n      console.error('WebSocket error:', error)\n    })\n\n    setSocket(newSocket)\n    socketRef.current = newSocket\n\n    return () =&gt; {\n      newSocket.close()\n    }\n  }, [url])\n\n  const emit = (event: string, data: any) =&gt; {\n    if (socketRef.current) {\n      socketRef.current.emit(event, data)\n    }\n  }\n\n  const on = (event: string, callback: (data: any) =&gt; void) =&gt; {\n    if (socketRef.current) {\n      socketRef.current.on(event, callback)\n    }\n  }\n\n  const off = (event: string, callback: (data: any) =&gt; void) =&gt; {\n    if (socketRef.current) {\n      socketRef.current.off(event, callback)\n    }\n  }\n\n  return {\n    socket,\n    isConnected,\n    emit,\n    on,\n    off\n  }\n}\n</code></pre>"},{"location":"06_collaborative_workspace/#presence-management","title":"Presence Management","text":""},{"location":"06_collaborative_workspace/#presence-hook","title":"Presence Hook","text":"<pre><code>// hooks/usePresence.ts\nimport { useState, useEffect } from 'react'\nimport { useWebSocket } from './useWebSocket'\nimport { useAuth } from './useAuth'\n\ninterface User {\n  id: string\n  name: string\n  email: string\n  avatar?: string\n  activity: string\n  lastSeen: Date\n}\n\nexport const usePresence = (conversationId: string) =&gt; {\n  const [onlineUsers, setOnlineUsers] = useState&lt;User[]&gt;([])\n  const [currentUser, setCurrentUser] = useState&lt;User | null&gt;(null)\n  const { socket, isConnected, emit, on, off } = useWebSocket(process.env.REACT_APP_WS_URL || 'ws://localhost:8000')\n  const { user } = useAuth()\n\n  useEffect(() =&gt; {\n    if (!socket || !isConnected) return\n\n    // Join conversation room\n    emit('join_conversation', { conversationId })\n\n    // Listen for presence updates\n    const handlePresenceUpdate = (data: { users: User[] }) =&gt; {\n      setOnlineUsers(data.users)\n    }\n\n    const handleUserJoined = (data: { user: User }) =&gt; {\n      setOnlineUsers(prev =&gt; [...prev.filter(u =&gt; u.id !== data.user.id), data.user])\n    }\n\n    const handleUserLeft = (data: { userId: string }) =&gt; {\n      setOnlineUsers(prev =&gt; prev.filter(u =&gt; u.id !== data.userId))\n    }\n\n    const handleActivityUpdate = (data: { userId: string, activity: string }) =&gt; {\n      setOnlineUsers(prev =&gt; \n        prev.map(u =&gt; u.id === data.userId ? { ...u, activity: data.activity } : u)\n      )\n    }\n\n    on('presence_update', handlePresenceUpdate)\n    on('user_joined', handleUserJoined)\n    on('user_left', handleUserLeft)\n    on('activity_update', handleActivityUpdate)\n\n    // Set current user\n    if (user) {\n      setCurrentUser({\n        id: user.id,\n        name: user.name,\n        email: user.email,\n        activity: 'viewing conversation',\n        lastSeen: new Date()\n      })\n    }\n\n    return () =&gt; {\n      emit('leave_conversation', { conversationId })\n      off('presence_update', handlePresenceUpdate)\n      off('user_joined', handleUserJoined)\n      off('user_left', handleUserLeft)\n      off('activity_update', handleActivityUpdate)\n    }\n  }, [socket, isConnected, conversationId, user, emit, on, off])\n\n  const updateActivity = (activity: string) =&gt; {\n    if (socket &amp;&amp; isConnected) {\n      emit('update_activity', { conversationId, activity })\n    }\n  }\n\n  return {\n    onlineUsers,\n    currentUser,\n    updateActivity\n  }\n}\n</code></pre>"},{"location":"06_collaborative_workspace/#permission-management","title":"Permission Management","text":""},{"location":"06_collaborative_workspace/#permission-hook","title":"Permission Hook","text":"<pre><code>// hooks/usePermissions.ts\nimport { useState, useEffect } from 'react'\nimport { useAuth } from './useAuth'\n\nexport type Permission = \n  | 'read_conversation'\n  | 'write_conversation'\n  | 'delete_conversation'\n  | 'add_comment'\n  | 'edit_comment'\n  | 'delete_comment'\n  | 'manage_permissions'\n  | 'invite_users'\n\nexport type Role = 'owner' | 'admin' | 'editor' | 'viewer'\n\ninterface PermissionMap {\n  [key: string]: Permission[]\n}\n\nconst ROLE_PERMISSIONS: PermissionMap = {\n  owner: [\n    'read_conversation',\n    'write_conversation',\n    'delete_conversation',\n    'add_comment',\n    'edit_comment',\n    'delete_comment',\n    'manage_permissions',\n    'invite_users'\n  ],\n  admin: [\n    'read_conversation',\n    'write_conversation',\n    'delete_conversation',\n    'add_comment',\n    'edit_comment',\n    'delete_comment',\n    'invite_users'\n  ],\n  editor: [\n    'read_conversation',\n    'write_conversation',\n    'add_comment',\n    'edit_comment'\n  ],\n  viewer: [\n    'read_conversation',\n    'add_comment'\n  ]\n}\n\nexport const usePermissions = (conversationId: string) =&gt; {\n  const [userRole, setUserRole] = useState&lt;Role | null&gt;(null)\n  const [permissions, setPermissions] = useState&lt;Permission[]&gt;([])\n  const { user } = useAuth()\n\n  useEffect(() =&gt; {\n    if (!user || !conversationId) return\n\n    // Fetch user role for this conversation\n    fetchUserRole(conversationId)\n      .then(role =&gt; {\n        setUserRole(role)\n        setPermissions(ROLE_PERMISSIONS[role] || [])\n      })\n      .catch(error =&gt; {\n        console.error('Failed to fetch user role:', error)\n        setUserRole('viewer')\n        setPermissions(ROLE_PERMISSIONS.viewer)\n      })\n  }, [user, conversationId])\n\n  const hasPermission = (permission: Permission): boolean =&gt; {\n    return permissions.includes(permission)\n  }\n\n  const canRead = () =&gt; hasPermission('read_conversation')\n  const canWrite = () =&gt; hasPermission('write_conversation')\n  const canDelete = () =&gt; hasPermission('delete_conversation')\n  const canComment = () =&gt; hasPermission('add_comment')\n  const canManagePermissions = () =&gt; hasPermission('manage_permissions')\n\n  return {\n    userRole,\n    permissions,\n    hasPermission,\n    canRead,\n    canWrite,\n    canDelete,\n    canComment,\n    canManagePermissions\n  }\n}\n</code></pre>"},{"location":"06_collaborative_workspace/#shared-workspace","title":"Shared Workspace","text":""},{"location":"06_collaborative_workspace/#workspace-component","title":"Workspace Component","text":"<pre><code>// components/collaboration/SharedWorkspace.tsx\nimport React, { useState } from 'react'\nimport { usePermissions } from '@/hooks/usePermissions'\nimport { usePresence } from '@/hooks/usePresence'\nimport { CommentThread } from './CommentThread'\n\ninterface SharedWorkspaceProps {\n  conversationId: string\n  conversation: Conversation\n}\n\nconst SharedWorkspace: React.FC&lt;SharedWorkspaceProps&gt; = ({\n  conversationId,\n  conversation\n}) =&gt; {\n  const { canRead, canWrite, canComment } = usePermissions(conversationId)\n  const { onlineUsers, updateActivity } = usePresence(conversationId)\n  const [activeTab, setActiveTab] = useState&lt;'conversation' | 'comments'&gt;('conversation')\n\n  useEffect(() =&gt; {\n    updateActivity('viewing conversation')\n  }, [updateActivity])\n\n  if (!canRead()) {\n    return (\n      &lt;div className=\"flex items-center justify-center h-64\"&gt;\n        &lt;div className=\"text-center\"&gt;\n          &lt;h3 className=\"text-lg font-medium text-gray-900\"&gt;Access Denied&lt;/h3&gt;\n          &lt;p className=\"text-gray-500\"&gt;You don't have permission to view this conversation.&lt;/p&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n    )\n  }\n\n  return (\n    &lt;div className=\"h-full flex flex-col\"&gt;\n      {/* Header */}\n      &lt;div className=\"bg-white border-b px-6 py-4\"&gt;\n        &lt;div className=\"flex items-center justify-between\"&gt;\n          &lt;div&gt;\n            &lt;h1 className=\"text-xl font-semibold text-gray-900\"&gt;\n              {conversation.title}\n            &lt;/h1&gt;\n            &lt;UserPresence conversationId={conversationId} /&gt;\n          &lt;/div&gt;\n          &lt;div className=\"flex items-center space-x-4\"&gt;\n            &lt;div className=\"flex space-x-1\"&gt;\n              &lt;button\n                onClick={() =&gt; setActiveTab('conversation')}\n                className={`px-3 py-2 text-sm font-medium rounded-md ${\n                  activeTab === 'conversation'\n                    ? 'bg-blue-100 text-blue-700'\n                    : 'text-gray-500 hover:text-gray-700'\n                }`}\n              &gt;\n                Conversation\n              &lt;/button&gt;\n              &lt;button\n                onClick={() =&gt; setActiveTab('comments')}\n                className={`px-3 py-2 text-sm font-medium rounded-md ${\n                  activeTab === 'comments'\n                    ? 'bg-blue-100 text-blue-700'\n                    : 'text-gray-500 hover:text-gray-700'\n                }`}\n              &gt;\n                Comments ({conversation.commentCount || 0})\n              &lt;/button&gt;\n            &lt;/div&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n\n      {/* Content */}\n      &lt;div className=\"flex-1 overflow-hidden\"&gt;\n        {activeTab === 'conversation' ? (\n          &lt;ConversationView\n            conversation={conversation}\n            canWrite={canWrite()}\n            canDelete={canDelete()}\n          /&gt;\n        ) : (\n          &lt;div className=\"h-full overflow-y-auto p-6\"&gt;\n            &lt;CommentThread conversationId={conversationId} /&gt;\n          &lt;/div&gt;\n        )}\n      &lt;/div&gt;\n    &lt;/div&gt;\n  )\n}\n</code></pre>"},{"location":"06_collaborative_workspace/#activity-feed","title":"Activity Feed","text":""},{"location":"06_collaborative_workspace/#activity-component","title":"Activity Component","text":"<pre><code>// components/realtime/ActivityFeed.tsx\nimport React from 'react'\nimport { useActivity } from '@/hooks/useActivity'\n\ninterface Activity {\n  id: string\n  type: 'conversation_created' | 'conversation_updated' | 'comment_added' | 'user_joined'\n  user: {\n    id: string\n    name: string\n    avatar?: string\n  }\n  data: any\n  timestamp: Date\n}\n\nconst ActivityFeed: React.FC = () =&gt; {\n  const { activities, isLoading } = useActivity()\n\n  if (isLoading) {\n    return (\n      &lt;div className=\"space-y-4\"&gt;\n        {[...Array(5)].map((_, i) =&gt; (\n          &lt;div key={i} className=\"animate-pulse\"&gt;\n            &lt;div className=\"h-4 bg-gray-200 rounded w-3/4 mb-2\" /&gt;\n            &lt;div className=\"h-3 bg-gray-200 rounded w-1/2\" /&gt;\n          &lt;/div&gt;\n        ))}\n      &lt;/div&gt;\n    )\n  }\n\n  return (\n    &lt;div className=\"space-y-4\"&gt;\n      {activities.map((activity) =&gt; (\n        &lt;div key={activity.id} className=\"flex items-start space-x-3\"&gt;\n          &lt;div className=\"w-8 h-8 rounded-full bg-blue-500 flex items-center justify-center text-white text-xs font-medium\"&gt;\n            {activity.user.name[0].toUpperCase()}\n          &lt;/div&gt;\n          &lt;div className=\"flex-1\"&gt;\n            &lt;p className=\"text-sm text-gray-900\"&gt;\n              &lt;span className=\"font-medium\"&gt;{activity.user.name}&lt;/span&gt;{' '}\n              {getActivityText(activity)}\n            &lt;/p&gt;\n            &lt;p className=\"text-xs text-gray-500\"&gt;\n              {formatRelativeTime(activity.timestamp)}\n            &lt;/p&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      ))}\n    &lt;/div&gt;\n  )\n}\n\nconst getActivityText = (activity: Activity): string =&gt; {\n  switch (activity.type) {\n    case 'conversation_created':\n      return 'created a new conversation'\n    case 'conversation_updated':\n      return 'updated the conversation'\n    case 'comment_added':\n      return 'added a comment'\n    case 'user_joined':\n      return 'joined the workspace'\n    default:\n      return 'performed an action'\n  }\n}\n</code></pre>"},{"location":"06_collaborative_workspace/#testing","title":"Testing","text":""},{"location":"06_collaborative_workspace/#collaboration-tests","title":"Collaboration Tests","text":"<pre><code>// tests/collaboration/UserPresence.test.tsx\nimport { render, screen, waitFor } from '@testing-library/react'\nimport { UserPresence } from '@/components/collaboration/UserPresence'\nimport { WebSocketProvider } from '@/contexts/WebSocketContext'\n\nconst mockWebSocket = {\n  emit: jest.fn(),\n  on: jest.fn(),\n  off: jest.fn(),\n  connected: true\n}\n\ndescribe('UserPresence', () =&gt; {\n  it('displays online users', async () =&gt; {\n    const mockUsers = [\n      { id: '1', name: 'John Doe', activity: 'viewing conversation' },\n      { id: '2', name: 'Jane Smith', activity: 'editing conversation' }\n    ]\n\n    render(\n      &lt;WebSocketProvider value={mockWebSocket}&gt;\n        &lt;UserPresence conversationId=\"test-conversation\" /&gt;\n      &lt;/WebSocketProvider&gt;\n    )\n\n    // Simulate presence update\n    const presenceHandler = mockWebSocket.on.mock.calls.find(\n      call =&gt; call[0] === 'presence_update'\n    )?.[1]\n\n    if (presenceHandler) {\n      presenceHandler({ users: mockUsers })\n    }\n\n    await waitFor(() =&gt; {\n      expect(screen.getByText('John Doe')).toBeInTheDocument()\n      expect(screen.getByText('Jane Smith')).toBeInTheDocument()\n    })\n  })\n})\n</code></pre>"},{"location":"06_collaborative_workspace/#success-criteria","title":"Success Criteria","text":""},{"location":"06_collaborative_workspace/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Real-time Updates - Live collaboration on conversations</li> <li> User Presence - Show online users and their activity</li> <li> Comment System - Threaded discussions on conversations</li> <li> Permission Management - Role-based access control</li> <li> Shared Workspaces - Team-based conversation organization</li> <li> Activity Feed - Real-time activity updates</li> <li> WebSocket Integration - Stable real-time communication</li> <li> Error Handling - Graceful handling of connection issues</li> </ul>"},{"location":"06_collaborative_workspace/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"06_collaborative_workspace/#advanced-features","title":"Advanced Features","text":"<ul> <li> Video Calls - Integrated video conferencing</li> <li> Screen Sharing - Share screens during collaboration</li> <li> File Sharing - Upload and share files in conversations</li> <li> Notifications - Push notifications for important events</li> <li> Conflict Resolution - Handle simultaneous edits</li> <li> Version History - Track changes over time</li> <li> Advanced Permissions - Granular permission control</li> <li> Team Analytics - Usage and collaboration metrics</li> </ul>"},{"location":"06_collaborative_workspace/#getting-started","title":"Getting Started","text":""},{"location":"06_collaborative_workspace/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Set up WebSocket server - Add WebSocket support to FastAPI</li> <li>Choose your frontend framework - React, Vue, or Angular</li> <li>Implement real-time communication - Socket.io or native WebSocket</li> <li>Add presence management - Track user online status</li> <li>Build comment system - Threaded discussions</li> <li>Implement permissions - Role-based access control</li> <li>Add shared workspaces - Team-based organization</li> <li>Test collaboration - Multi-user testing</li> </ol>"},{"location":"06_collaborative_workspace/#resources","title":"Resources","text":""},{"location":"06_collaborative_workspace/#helpful-links","title":"Helpful Links","text":"<ul> <li>Socket.io - https://socket.io/</li> <li>WebSocket API - https://developer.mozilla.org/en-US/docs/Web/API/WebSocket</li> <li>Real-time Collaboration - https://web.dev/real-time-collaboration/</li> <li>Presence Systems - https://pusher.com/guides/presence-channels</li> <li>Permission Management - https://auth0.com/blog/role-based-access-control-rbac/</li> </ul>"},{"location":"06_collaborative_workspace/#lets-build","title":"Let's Build!","text":""},{"location":"06_collaborative_workspace/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Real-time web application development - WebSocket communication - User presence management - Collaborative editing - Permission systems - Team workspace design</p> <p>Start with basic WebSocket integration and build up from there!</p>"},{"location":"06_collaborative_workspace/#next-steps","title":"Next Steps","text":""},{"location":"06_collaborative_workspace/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Test with multiple users - Ensure real-time features work correctly</li> <li>Deploy your app - Use a platform that supports WebSockets</li> <li>Share your code - Create a GitHub repository</li> <li>Document your approach - Write a comprehensive README</li> <li>Move to the next track - Try advanced UI patterns or mobile development next!</li> </ol> <p>Happy coding! \ud83d\ude80</p>"},{"location":"07_data_processing_overview/","title":"Data Processing","text":""},{"location":"07_data_processing_overview/#data-processing-assignments","title":"Data Processing Assignments","text":""},{"location":"07_data_processing_overview/#advanced-analytics-social-media-integration","title":"Advanced Analytics &amp; Social Media Integration","text":"<p>Explore customer data, social media APIs, and advanced search algorithms</p>"},{"location":"07_data_processing_overview/#assignment-overview","title":"Assignment Overview","text":""},{"location":"07_data_processing_overview/#what-youll-build","title":"What You'll Build","text":"<p>A comprehensive data processing system that handles: - Customer data analysis - Process mixed customer records and leads - Social media integration - Connect to Reddit, YouTube, and other APIs - Advanced search algorithms - Beyond basic cosine similarity - Database exploration - SQLite, FAISS, and beyond - Machine learning pipelines - Data preprocessing and analysis - Real-time data processing - Streaming and batch processing</p>"},{"location":"07_data_processing_overview/#the-challenge","title":"The Challenge","text":""},{"location":"07_data_processing_overview/#data-processing-complexity","title":"Data Processing Complexity","text":"<p>The current FastOpp system has basic search capabilities, but real-world applications need: - Mixed data sources - Customers, leads, social media users - Advanced algorithms - Beyond simple cosine similarity - Real-time processing - Live data from multiple APIs - Scalable storage - Handle large datasets efficiently - Data quality - Clean and normalize diverse data sources - Privacy compliance - Handle sensitive customer data</p>"},{"location":"07_data_processing_overview/#your-solution","title":"Your Solution","text":""},{"location":"07_data_processing_overview/#advanced-data-processing-system","title":"Advanced Data Processing System","text":"<p>Create a comprehensive data processing system that addresses these challenges:</p> <ol> <li>Multi-source Data Integration - Combine customer records with social media data</li> <li>Advanced Search Algorithms - Implement multiple similarity measures</li> <li>Real-time API Integration - Connect to Reddit, YouTube, and other platforms</li> <li>Scalable Database Design - Choose the right database for each use case</li> <li>Machine Learning Pipelines - Automated data processing and insights</li> <li>Data Privacy &amp; Security - Implement proper data handling practices</li> </ol>"},{"location":"07_data_processing_overview/#assignment-structure","title":"Assignment Structure","text":""},{"location":"07_data_processing_overview/#6-data-processing-tracks","title":"6 Data Processing Tracks","text":"<ol> <li>Fake Data Generation - Create realistic test datasets</li> <li>Social Media Integration - Reddit, YouTube, and Twitter APIs</li> <li>Advanced Search Algorithms - Beyond cosine similarity</li> <li>Database Exploration - SQLite, FAISS, PostgreSQL, and more</li> <li>Machine Learning Pipeline - Data preprocessing and analysis</li> <li>Real-time Processing - Streaming data and live updates</li> </ol>"},{"location":"07_data_processing_overview/#prerequisites","title":"Prerequisites","text":""},{"location":"07_data_processing_overview/#what-you-need","title":"What You Need","text":"<ul> <li>Python knowledge - Data processing and API integration</li> <li>Database experience - SQL and NoSQL databases</li> <li>API understanding - REST APIs and authentication</li> <li>Basic ML concepts - Data preprocessing and algorithms</li> <li>Data analysis skills - Pandas, NumPy, and visualization</li> <li>Privacy awareness - Data protection and compliance</li> </ul>"},{"location":"07_data_processing_overview/#learning-objectives","title":"Learning Objectives","text":""},{"location":"07_data_processing_overview/#skills-youll-develop","title":"Skills You'll Develop","text":"<ul> <li>Data Integration - Combine multiple data sources</li> <li>API Development - Build robust API integrations</li> <li>Algorithm Implementation - Advanced search and similarity measures</li> <li>Database Design - Choose and optimize database solutions</li> <li>Machine Learning - Data preprocessing and model training</li> <li>Real-time Processing - Streaming data and live updates</li> </ul>"},{"location":"07_data_processing_overview/#data-sources","title":"Data Sources","text":""},{"location":"07_data_processing_overview/#what-youll-work-with","title":"What You'll Work With","text":""},{"location":"07_data_processing_overview/#customer-data","title":"Customer Data","text":"<ul> <li>Customer records - Names, emails, purchase history</li> <li>Lead data - Whitepaper downloads, webinar registrations</li> <li>Forum users - Community engagement data</li> <li>Support tickets - Customer service interactions</li> </ul>"},{"location":"07_data_processing_overview/#social-media-data","title":"Social Media Data","text":"<ul> <li>Reddit posts - Technical discussions and comments</li> <li>YouTube videos - Influencer content and metadata</li> <li>Twitter/X data - Social media conversations</li> <li>LinkedIn profiles - Professional network data</li> </ul>"},{"location":"07_data_processing_overview/#generated-data","title":"Generated Data","text":"<ul> <li>Synthetic customers - Realistic fake data for testing</li> <li>Simulated interactions - Customer behavior patterns</li> <li>Mock social media - Generated posts and comments</li> <li>Test datasets - Various sizes and complexities</li> </ul>"},{"location":"07_data_processing_overview/#search-algorithms","title":"Search Algorithms","text":""},{"location":"07_data_processing_overview/#beyond-cosine-similarity","title":"Beyond Cosine Similarity","text":""},{"location":"07_data_processing_overview/#similarity-measures","title":"Similarity Measures","text":"<ul> <li>Cosine Similarity - Current implementation</li> <li>Jaccard Similarity - Set-based similarity</li> <li>Euclidean Distance - Geometric distance</li> <li>Manhattan Distance - L1 norm distance</li> <li>Pearson Correlation - Linear relationship</li> <li>Jensen-Shannon Divergence - Probability distribution similarity</li> </ul>"},{"location":"07_data_processing_overview/#advanced-techniques","title":"Advanced Techniques","text":"<ul> <li>Semantic Search - BERT, RoBERTa, and other transformers</li> <li>Fuzzy Matching - Approximate string matching</li> <li>Graph-based Search - Network analysis and recommendations</li> <li>Hybrid Search - Combine multiple algorithms</li> <li>Learning-to-Rank - ML-based ranking optimization</li> </ul>"},{"location":"07_data_processing_overview/#database-options","title":"Database Options","text":""},{"location":"07_data_processing_overview/#choose-the-right-tool","title":"Choose the Right Tool","text":""},{"location":"07_data_processing_overview/#vector-databases","title":"Vector Databases","text":"<ul> <li>FAISS - Facebook's similarity search</li> <li>Pinecone - Managed vector database</li> <li>Weaviate - Open-source vector search</li> <li>Chroma - Embedding database</li> <li>Qdrant - Vector similarity search</li> </ul>"},{"location":"07_data_processing_overview/#traditional-databases","title":"Traditional Databases","text":"<ul> <li>SQLite - Current implementation</li> <li>PostgreSQL - Advanced SQL features</li> <li>MongoDB - Document-based storage</li> <li>Elasticsearch - Full-text search</li> <li>Redis - In-memory caching</li> </ul>"},{"location":"07_data_processing_overview/#hybrid-solutions","title":"Hybrid Solutions","text":"<ul> <li>Multi-database architecture - Use different DBs for different purposes</li> <li>Data lakes - Store raw data for analysis</li> <li>Data warehouses - Structured data for reporting</li> <li>Graph databases - Network relationships</li> </ul>"},{"location":"07_data_processing_overview/#api-integrations","title":"API Integrations","text":""},{"location":"07_data_processing_overview/#social-media-platforms","title":"Social Media Platforms","text":""},{"location":"07_data_processing_overview/#reddit-api-praw","title":"Reddit API (PRAW)","text":"<pre><code>import praw\n\nreddit = praw.Reddit(\n    client_id=\"your_client_id\",\n    client_secret=\"your_client_secret\",\n    user_agent=\"FastOpp Data Processor\"\n)\n\n# Get posts from specific subreddit\nsubreddit = reddit.subreddit(\"MachineLearning\")\nfor post in subreddit.hot(limit=100):\n    process_reddit_post(post)\n</code></pre>"},{"location":"07_data_processing_overview/#youtube-data-api","title":"YouTube Data API","text":"<pre><code>from googleapiclient.discovery import build\n\nyoutube = build('youtube', 'v3', developerKey='your_api_key')\n\n# Search for videos\nsearch_response = youtube.search().list(\n    q='machine learning tutorial',\n    part='id,snippet',\n    maxResults=50\n).execute()\n</code></pre>"},{"location":"07_data_processing_overview/#twitter-api-v2","title":"Twitter API v2","text":"<pre><code>import tweepy\n\nclient = tweepy.Client(bearer_token='your_bearer_token')\n\n# Search for tweets\ntweets = client.search_recent_tweets(\n    query='machine learning',\n    max_results=100\n)\n</code></pre>"},{"location":"07_data_processing_overview/#data-processing-pipeline","title":"Data Processing Pipeline","text":""},{"location":"07_data_processing_overview/#end-to-end-workflow","title":"End-to-End Workflow","text":""},{"location":"07_data_processing_overview/#1-data-ingestion","title":"1. Data Ingestion","text":"<ul> <li>API connectors - Fetch data from various sources</li> <li>Data validation - Ensure data quality and format</li> <li>Rate limiting - Respect API limits and terms of service</li> <li>Error handling - Robust error recovery and logging</li> </ul>"},{"location":"07_data_processing_overview/#2-data-preprocessing","title":"2. Data Preprocessing","text":"<ul> <li>Cleaning - Remove duplicates, handle missing values</li> <li>Normalization - Standardize formats and units</li> <li>Enrichment - Add metadata and derived fields</li> <li>Deduplication - Identify and merge duplicate records</li> </ul>"},{"location":"07_data_processing_overview/#3-data-storage","title":"3. Data Storage","text":"<ul> <li>Database selection - Choose appropriate storage</li> <li>Schema design - Optimize for queries and performance</li> <li>Indexing - Speed up search and retrieval</li> <li>Backup strategy - Ensure data persistence</li> </ul>"},{"location":"07_data_processing_overview/#4-data-analysis","title":"4. Data Analysis","text":"<ul> <li>Similarity computation - Calculate relationships</li> <li>Clustering - Group similar records</li> <li>Trend analysis - Identify patterns over time</li> <li>Recommendation engine - Suggest relevant content</li> </ul>"},{"location":"07_data_processing_overview/#machine-learning-integration","title":"Machine Learning Integration","text":""},{"location":"07_data_processing_overview/#advanced-analytics","title":"Advanced Analytics","text":""},{"location":"07_data_processing_overview/#data-preprocessing","title":"Data Preprocessing","text":"<ul> <li>Feature engineering - Create meaningful features</li> <li>Text processing - NLP techniques for content analysis</li> <li>Dimensionality reduction - PCA, t-SNE, UMAP</li> <li>Data augmentation - Generate synthetic data</li> </ul>"},{"location":"07_data_processing_overview/#model-training","title":"Model Training","text":"<ul> <li>Classification - Categorize users and content</li> <li>Clustering - Group similar records</li> <li>Recommendation - Suggest relevant content</li> <li>Anomaly detection - Identify unusual patterns</li> </ul>"},{"location":"07_data_processing_overview/#model-deployment","title":"Model Deployment","text":"<ul> <li>API endpoints - Serve predictions via REST API</li> <li>Batch processing - Process large datasets</li> <li>Real-time inference - Live predictions</li> <li>Model monitoring - Track performance and drift</li> </ul>"},{"location":"07_data_processing_overview/#privacy-compliance","title":"Privacy &amp; Compliance","text":""},{"location":"07_data_processing_overview/#data-protection","title":"Data Protection","text":""},{"location":"07_data_processing_overview/#privacy-considerations","title":"Privacy Considerations","text":"<ul> <li>Data anonymization - Remove personally identifiable information</li> <li>Consent management - Track user permissions</li> <li>Data retention - Implement retention policies</li> <li>Access controls - Restrict data access by role</li> </ul>"},{"location":"07_data_processing_overview/#compliance-requirements","title":"Compliance Requirements","text":"<ul> <li>GDPR - European data protection regulation</li> <li>CCPA - California consumer privacy act</li> <li>SOC 2 - Security and availability standards</li> <li>HIPAA - Healthcare data protection (if applicable)</li> </ul>"},{"location":"07_data_processing_overview/#security-measures","title":"Security Measures","text":"<ul> <li>Encryption - Encrypt data at rest and in transit</li> <li>Authentication - Secure API access</li> <li>Audit logging - Track data access and modifications</li> <li>Regular backups - Ensure data recovery</li> </ul>"},{"location":"07_data_processing_overview/#success-criteria","title":"Success Criteria","text":""},{"location":"07_data_processing_overview/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Multi-source Integration - Connect to at least 3 data sources</li> <li> Advanced Search - Implement 3+ similarity algorithms</li> <li> Database Optimization - Choose appropriate storage solutions</li> <li> API Integration - Connect to Reddit, YouTube, or Twitter</li> <li> Data Quality - Implement data cleaning and validation</li> <li> Performance - Handle large datasets efficiently</li> <li> Documentation - Comprehensive code and API documentation</li> <li> Testing - Unit tests and integration tests</li> </ul>"},{"location":"07_data_processing_overview/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"07_data_processing_overview/#advanced-features","title":"Advanced Features","text":"<ul> <li> Real-time Processing - Stream processing with Apache Kafka</li> <li> Machine Learning - Train and deploy ML models</li> <li> Data Visualization - Interactive dashboards and charts</li> <li> A/B Testing - Compare different algorithms</li> <li> Scalability - Handle millions of records</li> <li> Monitoring - Real-time system monitoring</li> <li> Cost Optimization - Minimize API and storage costs</li> <li> Data Lineage - Track data flow and transformations</li> </ul>"},{"location":"07_data_processing_overview/#getting-started","title":"Getting Started","text":""},{"location":"07_data_processing_overview/#first-steps","title":"First Steps","text":"<ol> <li>Explore the data - Understand existing customer records</li> <li>Choose your track - Pick the assignment that interests you most</li> <li>Set up your environment - Install required tools and libraries</li> <li>Start with fake data - Generate realistic test datasets</li> <li>Implement basic algorithms - Start with simple similarity measures</li> <li>Connect to APIs - Begin with one social media platform</li> <li>Optimize performance - Scale up to larger datasets</li> <li>Add advanced features - Implement ML and real-time processing</li> </ol>"},{"location":"07_data_processing_overview/#resources","title":"Resources","text":""},{"location":"07_data_processing_overview/#helpful-links","title":"Helpful Links","text":"<ul> <li>PRAW (Reddit API) - https://praw.readthedocs.io/</li> <li>YouTube Data API - https://developers.google.com/youtube/v3</li> <li>Twitter API - https://developer.twitter.com/</li> <li>FAISS - https://github.com/facebookresearch/faiss</li> <li>Pinecone - https://www.pinecone.io/</li> <li>Pandas - https://pandas.pydata.org/</li> <li>Scikit-learn - https://scikit-learn.org/</li> </ul>"},{"location":"07_data_processing_overview/#lets-explore-data","title":"Let's Explore Data!","text":""},{"location":"07_data_processing_overview/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Advanced data processing techniques - API integration and rate limiting - Multiple similarity algorithms - Database selection and optimization - Machine learning pipelines - Privacy and compliance considerations</p> <p>Start with fake data generation and build up to real API integrations!</p>"},{"location":"07_data_processing_overview/#next-steps","title":"Next Steps","text":""},{"location":"07_data_processing_overview/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Share your insights - Document your findings and learnings</li> <li>Open source your code - Contribute to the community</li> <li>Write a blog post - Share your experience and results</li> <li>Present your work - Showcase your data processing skills</li> <li>Move to the next track - Try UI development or deployment next!</li> </ol> <p>Happy data processing! \ud83d\ude80</p>"},{"location":"08_fake_data_generation/","title":"Fake Data Generation","text":""},{"location":"08_fake_data_generation/#fake-data-generation-assignment","title":"Fake Data Generation Assignment","text":""},{"location":"08_fake_data_generation/#realistic-test-data-for-development","title":"Realistic Test Data for Development","text":"<p>Create comprehensive fake datasets for testing and development</p>"},{"location":"08_fake_data_generation/#assignment-overview","title":"Assignment Overview","text":""},{"location":"08_fake_data_generation/#what-youll-build","title":"What You'll Build","text":"<p>A sophisticated fake data generation system that creates: - Customer records - Realistic customer profiles and purchase history - Lead data - Whitepaper downloads, webinar registrations, and form submissions - Social media profiles - Fake Reddit users, YouTube creators, and Twitter accounts - Content data - Posts, comments, videos, and articles - Interaction data - User engagement, clicks, and behavior patterns - Temporal data - Realistic timestamps and event sequences</p>"},{"location":"08_fake_data_generation/#problem-statement","title":"Problem Statement","text":""},{"location":"08_fake_data_generation/#why-fake-data","title":"Why Fake Data?","text":"<p>Real-world data processing systems need realistic test data for: - Development testing - Test algorithms without real customer data - Performance testing - Scale testing with large datasets - Privacy protection - Avoid using sensitive real data - Reproducible results - Consistent data for testing - Edge case testing - Generate unusual scenarios - API rate limiting - Avoid hitting API limits during development</p>"},{"location":"08_fake_data_generation/#your-solution","title":"Your Solution","text":""},{"location":"08_fake_data_generation/#comprehensive-data-generation","title":"Comprehensive Data Generation","text":"<p>Create a fake data generation system that addresses these needs:</p> <ol> <li>Realistic Data - Statistically accurate fake data</li> <li>Configurable Scale - Generate datasets of any size</li> <li>Data Relationships - Maintain referential integrity</li> <li>Temporal Consistency - Realistic time-based data</li> <li>Edge Cases - Include unusual and boundary conditions</li> <li>Export Formats - Multiple output formats (JSON, CSV, SQL)</li> </ol>"},{"location":"08_fake_data_generation/#technical-requirements","title":"Technical Requirements","text":""},{"location":"08_fake_data_generation/#tech-stack","title":"Tech Stack","text":"<ul> <li>Python 3.8+ with type hints</li> <li>Faker - Primary fake data generation</li> <li>Pandas - Data manipulation and analysis</li> <li>NumPy - Numerical operations</li> <li>SQLAlchemy - Database operations</li> <li>Pydantic - Data validation</li> <li>Click - Command-line interface</li> <li>Tqdm - Progress bars</li> </ul>"},{"location":"08_fake_data_generation/#project-structure","title":"Project Structure","text":""},{"location":"08_fake_data_generation/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>fake_data_generator/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 generators/\n\u2502   \u2502   \u251c\u2500\u2500 base.py\n\u2502   \u2502   \u251c\u2500\u2500 customers.py\n\u2502   \u2502   \u251c\u2500\u2500 leads.py\n\u2502   \u2502   \u251c\u2500\u2500 social_media.py\n\u2502   \u2502   \u2514\u2500\u2500 content.py\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 customer.py\n\u2502   \u2502   \u251c\u2500\u2500 lead.py\n\u2502   \u2502   \u251c\u2500\u2500 social_profile.py\n\u2502   \u2502   \u2514\u2500\u2500 content.py\n\u2502   \u251c\u2500\u2500 utils/\n\u2502   \u2502   \u251c\u2500\u2500 data_validation.py\n\u2502   \u2502   \u251c\u2500\u2500 export.py\n\u2502   \u2502   \u2514\u2500\u2500 statistics.py\n\u2502   \u2514\u2500\u2500 cli.py\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 data_config.yaml\n\u2502   \u2514\u2500\u2500 database_config.yaml\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_generators.py\n\u2502   \u2514\u2500\u2500 test_models.py\n\u2514\u2500\u2500 requirements.txt\n</code></pre>"},{"location":"08_fake_data_generation/#core-components","title":"Core Components","text":""},{"location":"08_fake_data_generation/#1-base-generator-class","title":"1. Base Generator Class","text":"<pre><code># src/generators/base.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, List, Optional\nfrom faker import Faker\nimport random\nfrom datetime import datetime, timedelta\n\nclass BaseGenerator(ABC):\n    def __init__(self, locale: str = 'en_US', seed: Optional[int] = None):\n        self.fake = Faker(locale)\n        if seed:\n            Faker.seed(seed)\n            random.seed(seed)\n\n    @abstractmethod\n    def generate(self, count: int) -&gt; List[Dict[str, Any]]:\n        \"\"\"Generate a list of fake records\"\"\"\n        pass\n\n    def generate_batch(self, count: int, batch_size: int = 1000) -&gt; List[Dict[str, Any]]:\n        \"\"\"Generate records in batches for memory efficiency\"\"\"\n        all_records = []\n        for i in range(0, count, batch_size):\n            batch_count = min(batch_size, count - i)\n            batch = self.generate(batch_count)\n            all_records.extend(batch)\n            yield batch\n\n    def add_relationships(self, records: List[Dict[str, Any]], \n                         related_data: Dict[str, List[Any]]) -&gt; List[Dict[str, Any]]:\n        \"\"\"Add foreign key relationships to records\"\"\"\n        for record in records:\n            for field, related_list in related_data.items():\n                if related_list:\n                    record[field] = random.choice(related_list)\n        return records\n</code></pre>"},{"location":"08_fake_data_generation/#core-components_1","title":"Core Components","text":""},{"location":"08_fake_data_generation/#2-customer-generator","title":"2. Customer Generator","text":"<pre><code># src/generators/customers.py\nfrom typing import Dict, Any, List\nfrom .base import BaseGenerator\nfrom ..models.customer import Customer\n\nclass CustomerGenerator(BaseGenerator):\n    def __init__(self, locale: str = 'en_US', seed: Optional[int] = None):\n        super().__init__(locale, seed)\n        self.industries = [\n            'Technology', 'Healthcare', 'Finance', 'Education', \n            'Manufacturing', 'Retail', 'Consulting', 'Real Estate'\n        ]\n        self.company_sizes = ['Startup', 'Small', 'Medium', 'Large', 'Enterprise']\n\n    def generate(self, count: int) -&gt; List[Dict[str, Any]]:\n        customers = []\n        for _ in range(count):\n            customer = {\n                'id': self.fake.uuid4(),\n                'first_name': self.fake.first_name(),\n                'last_name': self.fake.last_name(),\n                'email': self.fake.email(),\n                'phone': self.fake.phone_number(),\n                'company': self.fake.company(),\n                'job_title': self.fake.job(),\n                'industry': random.choice(self.industries),\n                'company_size': random.choice(self.company_sizes),\n                'location': {\n                    'city': self.fake.city(),\n                    'state': self.fake.state(),\n                    'country': self.fake.country(),\n                    'postal_code': self.fake.postcode()\n                },\n                'created_at': self.fake.date_time_between(start_date='-2y', end_date='now'),\n                'last_activity': self.fake.date_time_between(start_date='-6m', end_date='now'),\n                'status': random.choices(\n                    ['active', 'inactive', 'prospect', 'churned'],\n                    weights=[0.6, 0.2, 0.15, 0.05]\n                )[0],\n                'lifetime_value': round(random.uniform(0, 50000), 2),\n                'lead_source': random.choice([\n                    'organic_search', 'paid_search', 'social_media', \n                    'referral', 'email_campaign', 'webinar', 'whitepaper'\n                ])\n            }\n            customers.append(customer)\n        return customers\n\n    def generate_purchase_history(self, customer_ids: List[str], \n                                count_per_customer: int = 5) -&gt; List[Dict[str, Any]]:\n        purchases = []\n        products = [\n            'Software License', 'Consulting Hours', 'Training Course',\n            'Support Package', 'Custom Development', 'Integration Service'\n        ]\n\n        for customer_id in customer_ids:\n            for _ in range(random.randint(1, count_per_customer)):\n                purchase = {\n                    'id': self.fake.uuid4(),\n                    'customer_id': customer_id,\n                    'product': random.choice(products),\n                    'amount': round(random.uniform(100, 10000), 2),\n                    'purchase_date': self.fake.date_time_between(start_date='-1y', end_date='now'),\n                    'status': random.choice(['completed', 'pending', 'cancelled']),\n                    'payment_method': random.choice(['credit_card', 'bank_transfer', 'paypal'])\n                }\n                purchases.append(purchase)\n        return purchases\n</code></pre>"},{"location":"08_fake_data_generation/#core-components_2","title":"Core Components","text":""},{"location":"08_fake_data_generation/#3-lead-generator","title":"3. Lead Generator","text":"<pre><code># src/generators/leads.py\nfrom typing import Dict, Any, List\nfrom .base import BaseGenerator\n\nclass LeadGenerator(BaseGenerator):\n    def __init__(self, locale: str = 'en_US', seed: Optional[int] = None):\n        super().__init__(locale, seed)\n        self.lead_sources = [\n            'whitepaper_download', 'webinar_registration', 'demo_request',\n            'newsletter_signup', 'contact_form', 'social_media',\n            'referral', 'trade_show', 'cold_outreach'\n        ]\n        self.content_types = [\n            'whitepaper', 'ebook', 'case_study', 'webinar', 'demo',\n            'trial', 'consultation', 'newsletter'\n        ]\n\n    def generate(self, count: int) -&gt; List[Dict[str, Any]]:\n        leads = []\n        for _ in range(count):\n            lead = {\n                'id': self.fake.uuid4(),\n                'email': self.fake.email(),\n                'first_name': self.fake.first_name(),\n                'last_name': self.fake.last_name(),\n                'company': self.fake.company(),\n                'job_title': self.fake.job(),\n                'phone': self.fake.phone_number(),\n                'lead_source': random.choice(self.lead_sources),\n                'content_type': random.choice(self.content_types),\n                'content_title': self.fake.sentence(nb_words=6),\n                'created_at': self.fake.date_time_between(start_date='-1y', end_date='now'),\n                'status': random.choices(\n                    ['new', 'contacted', 'qualified', 'unqualified', 'converted'],\n                    weights=[0.3, 0.25, 0.2, 0.15, 0.1]\n                )[0],\n                'score': random.randint(0, 100),\n                'notes': self.fake.text(max_nb_chars=200) if random.random() &lt; 0.3 else None,\n                'utm_source': random.choice(['google', 'facebook', 'linkedin', 'twitter', 'direct']),\n                'utm_medium': random.choice(['cpc', 'organic', 'social', 'email', 'referral']),\n                'utm_campaign': self.fake.word() + '_campaign'\n            }\n            leads.append(lead)\n        return leads\n\n    def generate_webinar_registrations(self, webinar_ids: List[str], \n                                     count_per_webinar: int = 50) -&gt; List[Dict[str, Any]]:\n        registrations = []\n        for webinar_id in webinar_ids:\n            for _ in range(random.randint(10, count_per_webinar)):\n                registration = {\n                    'id': self.fake.uuid4(),\n                    'webinar_id': webinar_id,\n                    'email': self.fake.email(),\n                    'first_name': self.fake.first_name(),\n                    'last_name': self.fake.last_name(),\n                    'company': self.fake.company(),\n                    'job_title': self.fake.job(),\n                    'registered_at': self.fake.date_time_between(start_date='-3m', end_date='now'),\n                    'attended': random.choice([True, False]),\n                    'attendance_duration': random.randint(0, 60) if random.choice([True, False]) else 0,\n                    'feedback_score': random.randint(1, 5) if random.choice([True, False]) else None\n                }\n                registrations.append(registration)\n        return registrations\n</code></pre>"},{"location":"08_fake_data_generation/#core-components_3","title":"Core Components","text":""},{"location":"08_fake_data_generation/#4-social-media-generator","title":"4. Social Media Generator","text":"<pre><code># src/generators/social_media.py\nfrom typing import Dict, Any, List\nfrom .base import BaseGenerator\n\nclass SocialMediaGenerator(BaseGenerator):\n    def __init__(self, locale: str = 'en_US', seed: Optional[int] = None):\n        super().__init__(locale, seed)\n        self.platforms = ['reddit', 'youtube', 'twitter', 'linkedin', 'github']\n        self.subreddits = [\n            'MachineLearning', 'datascience', 'Python', 'programming',\n            'webdev', 'startups', 'entrepreneur', 'technology'\n        ]\n        self.video_categories = [\n            'Tutorial', 'Review', 'News', 'Entertainment', 'Educational',\n            'Product Demo', 'Interview', 'Live Stream'\n        ]\n\n    def generate_reddit_users(self, count: int) -&gt; List[Dict[str, Any]]:\n        users = []\n        for _ in range(count):\n            user = {\n                'id': self.fake.uuid4(),\n                'username': self.fake.user_name(),\n                'display_name': self.fake.name(),\n                'email': self.fake.email() if random.random() &lt; 0.3 else None,\n                'created_at': self.fake.date_time_between(start_date='-5y', end_date='now'),\n                'karma': random.randint(0, 50000),\n                'verified': random.choice([True, False]),\n                'premium': random.choice([True, False]),\n                'bio': self.fake.text(max_nb_chars=160) if random.random() &lt; 0.7 else None,\n                'location': self.fake.city() if random.random() &lt; 0.4 else None,\n                'interests': random.sample(self.subreddits, random.randint(1, 5))\n            }\n            users.append(user)\n        return users\n\n    def generate_reddit_posts(self, user_ids: List[str], count: int) -&gt; List[Dict[str, Any]]:\n        posts = []\n        for _ in range(count):\n            post = {\n                'id': self.fake.uuid4(),\n                'user_id': random.choice(user_ids),\n                'subreddit': random.choice(self.subreddits),\n                'title': self.fake.sentence(nb_words=8),\n                'content': self.fake.text(max_nb_chars=2000),\n                'created_at': self.fake.date_time_between(start_date='-1y', end_date='now'),\n                'score': random.randint(-100, 1000),\n                'upvote_ratio': random.uniform(0.1, 1.0),\n                'num_comments': random.randint(0, 500),\n                'awards': random.randint(0, 10),\n                'flair': random.choice(['Discussion', 'Question', 'News', 'Meta']) if random.random() &lt; 0.3 else None,\n                'nsfw': random.choice([True, False]),\n                'stickied': random.choice([True, False])\n            }\n            posts.append(post)\n        return posts\n\n    def generate_youtube_channels(self, count: int) -&gt; List[Dict[str, Any]]:\n        channels = []\n        for _ in range(count):\n            channel = {\n                'id': self.fake.uuid4(),\n                'channel_name': self.fake.company() + ' Tech',\n                'description': self.fake.text(max_nb_chars=500),\n                'created_at': self.fake.date_time_between(start_date='-3y', end_date='now'),\n                'subscriber_count': random.randint(100, 1000000),\n                'video_count': random.randint(10, 500),\n                'total_views': random.randint(10000, 10000000),\n                'category': random.choice(self.video_categories),\n                'country': self.fake.country(),\n                'verified': random.choice([True, False]),\n                'monetization': random.choice([True, False])\n            }\n            channels.append(channel)\n        return channels\n\n    def generate_youtube_videos(self, channel_ids: List[str], count: int) -&gt; List[Dict[str, Any]]:\n        videos = []\n        for _ in range(count):\n            video = {\n                'id': self.fake.uuid4(),\n                'channel_id': random.choice(channel_ids),\n                'title': self.fake.sentence(nb_words=6),\n                'description': self.fake.text(max_nb_chars=1000),\n                'published_at': self.fake.date_time_between(start_date='-1y', end_date='now'),\n                'duration': random.randint(60, 3600),  # seconds\n                'views': random.randint(100, 1000000),\n                'likes': random.randint(0, 50000),\n                'dislikes': random.randint(0, 1000),\n                'comments': random.randint(0, 10000),\n                'category': random.choice(self.video_categories),\n                'tags': [self.fake.word() for _ in range(random.randint(3, 10))],\n                'thumbnail_url': self.fake.image_url(),\n                'privacy': random.choice(['public', 'unlisted', 'private'])\n            }\n            videos.append(video)\n        return videos\n</code></pre>"},{"location":"08_fake_data_generation/#data-models","title":"Data Models","text":""},{"location":"08_fake_data_generation/#pydantic-models","title":"Pydantic Models","text":"<pre><code># src/models/customer.py\nfrom pydantic import BaseModel, EmailStr, Field\nfrom typing import Optional, Dict, Any\nfrom datetime import datetime\nfrom enum import Enum\n\nclass CompanySize(str, Enum):\n    STARTUP = \"startup\"\n    SMALL = \"small\"\n    MEDIUM = \"medium\"\n    LARGE = \"large\"\n    ENTERPRISE = \"enterprise\"\n\nclass CustomerStatus(str, Enum):\n    ACTIVE = \"active\"\n    INACTIVE = \"inactive\"\n    PROSPECT = \"prospect\"\n    CHURNED = \"churned\"\n\nclass Location(BaseModel):\n    city: str\n    state: str\n    country: str\n    postal_code: str\n\nclass Customer(BaseModel):\n    id: str\n    first_name: str\n    last_name: str\n    email: EmailStr\n    phone: str\n    company: str\n    job_title: str\n    industry: str\n    company_size: CompanySize\n    location: Location\n    created_at: datetime\n    last_activity: datetime\n    status: CustomerStatus\n    lifetime_value: float = Field(ge=0)\n    lead_source: str\n\nclass Purchase(BaseModel):\n    id: str\n    customer_id: str\n    product: str\n    amount: float = Field(ge=0)\n    purchase_date: datetime\n    status: str\n    payment_method: str\n</code></pre>"},{"location":"08_fake_data_generation/#data-validation","title":"Data Validation","text":""},{"location":"08_fake_data_generation/#quality-assurance","title":"Quality Assurance","text":"<pre><code># src/utils/data_validation.py\nfrom typing import List, Dict, Any\nimport pandas as pd\nfrom datetime import datetime\n\nclass DataValidator:\n    def __init__(self):\n        self.errors = []\n        self.warnings = []\n\n    def validate_customers(self, customers: List[Dict[str, Any]]) -&gt; bool:\n        \"\"\"Validate customer data for quality and consistency\"\"\"\n        df = pd.DataFrame(customers)\n\n        # Check for required fields\n        required_fields = ['id', 'email', 'first_name', 'last_name', 'company']\n        for field in required_fields:\n            if field not in df.columns:\n                self.errors.append(f\"Missing required field: {field}\")\n\n        # Check for duplicate emails\n        duplicate_emails = df[df.duplicated(subset=['email'], keep=False)]\n        if not duplicate_emails.empty:\n            self.warnings.append(f\"Found {len(duplicate_emails)} duplicate emails\")\n\n        # Check email format\n        invalid_emails = df[~df['email'].str.contains('@', na=False)]\n        if not invalid_emails.empty:\n            self.errors.append(f\"Found {len(invalid_emails)} invalid email addresses\")\n\n        # Check date consistency\n        if 'created_at' in df.columns and 'last_activity' in df.columns:\n            invalid_dates = df[df['created_at'] &gt; df['last_activity']]\n            if not invalid_dates.empty:\n                self.errors.append(f\"Found {len(invalid_dates)} records with invalid date ranges\")\n\n        return len(self.errors) == 0\n\n    def validate_relationships(self, customers: List[Dict[str, Any]], \n                            purchases: List[Dict[str, Any]]) -&gt; bool:\n        \"\"\"Validate referential integrity between related data\"\"\"\n        customer_ids = {c['id'] for c in customers}\n        purchase_customer_ids = {p['customer_id'] for p in purchases}\n\n        orphaned_purchases = purchase_customer_ids - customer_ids\n        if orphaned_purchases:\n            self.errors.append(f\"Found {len(orphaned_purchases)} orphaned purchases\")\n\n        return len(self.errors) == 0\n\n    def get_validation_report(self) -&gt; Dict[str, Any]:\n        \"\"\"Generate a comprehensive validation report\"\"\"\n        return {\n            'valid': len(self.errors) == 0,\n            'error_count': len(self.errors),\n            'warning_count': len(self.warnings),\n            'errors': self.errors,\n            'warnings': self.warnings\n        }\n</code></pre>"},{"location":"08_fake_data_generation/#export-functions","title":"Export Functions","text":""},{"location":"08_fake_data_generation/#multiple-output-formats","title":"Multiple Output Formats","text":"<pre><code># src/utils/export.py\nimport json\nimport csv\nimport sqlite3\nfrom typing import List, Dict, Any\nimport pandas as pd\n\nclass DataExporter:\n    def __init__(self, output_dir: str = \"output\"):\n        self.output_dir = output_dir\n        os.makedirs(output_dir, exist_ok=True)\n\n    def export_to_json(self, data: List[Dict[str, Any]], filename: str) -&gt; str:\n        \"\"\"Export data to JSON format\"\"\"\n        filepath = os.path.join(self.output_dir, f\"{filename}.json\")\n        with open(filepath, 'w') as f:\n            json.dump(data, f, indent=2, default=str)\n        return filepath\n\n    def export_to_csv(self, data: List[Dict[str, Any]], filename: str) -&gt; str:\n        \"\"\"Export data to CSV format\"\"\"\n        filepath = os.path.join(self.output_dir, f\"{filename}.csv\")\n        df = pd.DataFrame(data)\n        df.to_csv(filepath, index=False)\n        return filepath\n\n    def export_to_sqlite(self, tables: Dict[str, List[Dict[str, Any]]], \n                        filename: str) -&gt; str:\n        \"\"\"Export data to SQLite database\"\"\"\n        filepath = os.path.join(self.output_dir, f\"{filename}.db\")\n        conn = sqlite3.connect(filepath)\n\n        for table_name, records in tables.items():\n            df = pd.DataFrame(records)\n            df.to_sql(table_name, conn, if_exists='replace', index=False)\n\n        conn.close()\n        return filepath\n\n    def export_to_postgresql(self, tables: Dict[str, List[Dict[str, Any]]], \n                           connection_string: str) -&gt; bool:\n        \"\"\"Export data to PostgreSQL database\"\"\"\n        try:\n            import psycopg2\n            from sqlalchemy import create_engine\n\n            engine = create_engine(connection_string)\n\n            for table_name, records in tables.items():\n                df = pd.DataFrame(records)\n                df.to_sql(table_name, engine, if_exists='replace', index=False)\n\n            return True\n        except ImportError:\n            print(\"psycopg2 not installed. Install with: pip install psycopg2-binary\")\n            return False\n</code></pre>"},{"location":"08_fake_data_generation/#cli-interface","title":"CLI Interface","text":""},{"location":"08_fake_data_generation/#command-line-tool","title":"Command Line Tool","text":"<pre><code># src/cli.py\nimport click\nfrom typing import Optional\nfrom .generators.customers import CustomerGenerator\nfrom .generators.leads import LeadGenerator\nfrom .generators.social_media import SocialMediaGenerator\nfrom .utils.export import DataExporter\nfrom .utils.data_validation import DataValidator\n\n@click.group()\ndef cli():\n    \"\"\"Fake Data Generator CLI\"\"\"\n    pass\n\n@cli.command()\n@click.option('--count', default=1000, help='Number of records to generate')\n@click.option('--output-format', type=click.Choice(['json', 'csv', 'sqlite']), \n              default='json', help='Output format')\n@click.option('--seed', type=int, help='Random seed for reproducibility')\n@click.option('--locale', default='en_US', help='Locale for fake data')\ndef generate_customers(count: int, output_format: str, seed: Optional[int], locale: str):\n    \"\"\"Generate fake customer data\"\"\"\n    generator = CustomerGenerator(locale=locale, seed=seed)\n    exporter = DataExporter()\n    validator = DataValidator()\n\n    click.echo(f\"Generating {count} customer records...\")\n    customers = generator.generate(count)\n\n    # Validate data\n    if validator.validate_customers(customers):\n        click.echo(\"\u2705 Data validation passed\")\n    else:\n        click.echo(\"\u274c Data validation failed\")\n        for error in validator.errors:\n            click.echo(f\"  - {error}\")\n        return\n\n    # Export data\n    if output_format == 'json':\n        filepath = exporter.export_to_json(customers, 'customers')\n    elif output_format == 'csv':\n        filepath = exporter.export_to_csv(customers, 'customers')\n    elif output_format == 'sqlite':\n        filepath = exporter.export_to_sqlite({'customers': customers}, 'customers')\n\n    click.echo(f\"\u2705 Data exported to {filepath}\")\n\n@cli.command()\n@click.option('--count', default=500, help='Number of records to generate')\n@click.option('--output-format', type=click.Choice(['json', 'csv', 'sqlite']), \n              default='json', help='Output format')\n@click.option('--seed', type=int, help='Random seed for reproducibility')\ndef generate_social_media(count: int, output_format: str, seed: Optional[int]):\n    \"\"\"Generate fake social media data\"\"\"\n    generator = SocialMediaGenerator(seed=seed)\n    exporter = DataExporter()\n\n    click.echo(f\"Generating {count} social media records...\")\n\n    # Generate users and posts\n    users = generator.generate_reddit_users(count // 2)\n    posts = generator.generate_reddit_posts([u['id'] for u in users], count)\n\n    # Export data\n    if output_format == 'sqlite':\n        filepath = exporter.export_to_sqlite({\n            'reddit_users': users,\n            'reddit_posts': posts\n        }, 'social_media')\n    else:\n        users_file = exporter.export_to_json(users, 'reddit_users')\n        posts_file = exporter.export_to_json(posts, 'reddit_posts')\n        click.echo(f\"\u2705 Users exported to {users_file}\")\n        click.echo(f\"\u2705 Posts exported to {posts_file}\")\n        return\n\n    click.echo(f\"\u2705 Data exported to {filepath}\")\n\nif __name__ == '__main__':\n    cli()\n</code></pre>"},{"location":"08_fake_data_generation/#testing","title":"Testing","text":""},{"location":"08_fake_data_generation/#comprehensive-test-suite","title":"Comprehensive Test Suite","text":"<pre><code># tests/test_generators.py\nimport pytest\nfrom src.generators.customers import CustomerGenerator\nfrom src.generators.leads import LeadGenerator\nfrom src.generators.social_media import SocialMediaGenerator\n\nclass TestCustomerGenerator:\n    def test_generate_customers(self):\n        generator = CustomerGenerator(seed=42)\n        customers = generator.generate(10)\n\n        assert len(customers) == 10\n        assert all('email' in customer for customer in customers)\n        assert all('@' in customer['email'] for customer in customers)\n        assert all(customer['lifetime_value'] &gt;= 0 for customer in customers)\n\n    def test_generate_purchase_history(self):\n        generator = CustomerGenerator(seed=42)\n        customer_ids = ['customer1', 'customer2']\n        purchases = generator.generate_purchase_history(customer_ids, 3)\n\n        assert len(purchases) == 6  # 2 customers * 3 purchases each\n        assert all(purchase['customer_id'] in customer_ids for purchase in purchases)\n        assert all(purchase['amount'] &gt; 0 for purchase in purchases)\n\nclass TestLeadGenerator:\n    def test_generate_leads(self):\n        generator = LeadGenerator(seed=42)\n        leads = generator.generate(10)\n\n        assert len(leads) == 10\n        assert all('email' in lead for lead in leads)\n        assert all(lead['score'] &gt;= 0 and lead['score'] &lt;= 100 for lead in leads)\n        assert all(lead['status'] in ['new', 'contacted', 'qualified', 'unqualified', 'converted'] \n                  for lead in leads)\n\nclass TestSocialMediaGenerator:\n    def test_generate_reddit_users(self):\n        generator = SocialMediaGenerator(seed=42)\n        users = generator.generate_reddit_users(10)\n\n        assert len(users) == 10\n        assert all('username' in user for user in users)\n        assert all(user['karma'] &gt;= 0 for user in users)\n        assert all(len(user['interests']) &gt; 0 for user in users)\n\n    def test_generate_reddit_posts(self):\n        generator = SocialMediaGenerator(seed=42)\n        user_ids = ['user1', 'user2']\n        posts = generator.generate_reddit_posts(user_ids, 10)\n\n        assert len(posts) == 10\n        assert all(post['user_id'] in user_ids for post in posts)\n        assert all(post['score'] &gt;= -100 for post in posts)\n        assert all(post['upvote_ratio'] &gt;= 0 and post['upvote_ratio'] &lt;= 1 for post in posts)\n</code></pre>"},{"location":"08_fake_data_generation/#success-criteria","title":"Success Criteria","text":""},{"location":"08_fake_data_generation/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Realistic Data - Generate statistically accurate fake data</li> <li> Multiple Data Types - Customers, leads, social media, content</li> <li> Data Relationships - Maintain referential integrity</li> <li> Configurable Scale - Generate datasets of any size</li> <li> Multiple Output Formats - JSON, CSV, SQLite, PostgreSQL</li> <li> Data Validation - Quality assurance and error checking</li> <li> CLI Interface - Easy-to-use command line tool</li> <li> Comprehensive Testing - Unit tests and integration tests</li> </ul>"},{"location":"08_fake_data_generation/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"08_fake_data_generation/#advanced-features","title":"Advanced Features","text":"<ul> <li> Temporal Consistency - Generate realistic time-based data</li> <li> Data Anonymization - Remove PII while maintaining relationships</li> <li> Custom Schemas - Allow users to define custom data structures</li> <li> Performance Optimization - Generate large datasets efficiently</li> <li> Data Visualization - Generate charts and graphs of the data</li> <li> API Integration - Generate data based on real API responses</li> <li> Machine Learning - Use ML to generate more realistic data</li> <li> Data Lineage - Track data generation and transformations</li> </ul>"},{"location":"08_fake_data_generation/#getting-started","title":"Getting Started","text":""},{"location":"08_fake_data_generation/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Create project structure - Set up the recommended architecture</li> <li>Install dependencies - Add Faker, Pandas, and other required packages</li> <li>Implement base generator - Create the abstract base class</li> <li>Build specific generators - Start with customers, then leads, then social media</li> <li>Add data validation - Implement quality assurance checks</li> <li>Create export functions - Support multiple output formats</li> <li>Build CLI interface - Make it easy to use from command line</li> <li>Write tests - Ensure data quality and generator reliability</li> </ol>"},{"location":"08_fake_data_generation/#dependencies","title":"Dependencies","text":""},{"location":"08_fake_data_generation/#requirementstxt","title":"requirements.txt","text":"<pre><code>faker&gt;=19.0.0\npandas&gt;=1.5.0\nnumpy&gt;=1.24.0\npydantic&gt;=2.0.0\nclick&gt;=8.0.0\ntqdm&gt;=4.65.0\nsqlalchemy&gt;=2.0.0\npsycopg2-binary&gt;=2.9.0\npytest&gt;=7.0.0\npytest-cov&gt;=4.0.0\n</code></pre>"},{"location":"08_fake_data_generation/#resources","title":"Resources","text":""},{"location":"08_fake_data_generation/#helpful-links","title":"Helpful Links","text":"<ul> <li>Faker Documentation - https://faker.readthedocs.io/</li> <li>Pandas - https://pandas.pydata.org/</li> <li>Pydantic - https://pydantic-docs.helpmanual.io/</li> <li>Click - https://click.palletsprojects.com/</li> <li>SQLAlchemy - https://www.sqlalchemy.org/</li> <li>Data Generation Best Practices - https://www.oreilly.com/library/view/data-generation/9781492048775/</li> </ul>"},{"location":"08_fake_data_generation/#lets-generate-data","title":"Let's Generate Data!","text":""},{"location":"08_fake_data_generation/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Data generation techniques and best practices - Statistical modeling for realistic fake data - Data validation and quality assurance - Multiple output formats and database integration - Command-line tool development - Testing strategies for data generation</p> <p>Start with basic customer data and build up to complex social media datasets!</p>"},{"location":"08_fake_data_generation/#next-steps","title":"Next Steps","text":""},{"location":"08_fake_data_generation/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Share your datasets - Make them available for others to use</li> <li>Document your approach - Write about your data generation strategies</li> <li>Contribute to open source - Share your generators with the community</li> <li>Move to the next track - Try social media API integration or advanced search algorithms next!</li> </ol> <p>Happy data generating! \ud83d\ude80</p>"},{"location":"09_social_media_integration/","title":"Social Media Integration","text":""},{"location":"09_social_media_integration/#social-media-integration-assignment","title":"Social Media Integration Assignment","text":""},{"location":"09_social_media_integration/#real-time-api-data-collection","title":"Real-Time API Data Collection","text":"<p>Connect to Reddit, YouTube, Twitter, and other social platforms</p>"},{"location":"09_social_media_integration/#assignment-overview","title":"Assignment Overview","text":""},{"location":"09_social_media_integration/#what-youll-build","title":"What You'll Build","text":"<p>A comprehensive social media integration system that: - Connects to multiple APIs - Reddit, YouTube, Twitter, LinkedIn, GitHub - Collects real-time data - Posts, comments, videos, user profiles - Processes and normalizes data - Standardize different data formats - Implements rate limiting - Respect API limits and terms of service - Stores data efficiently - Optimize for search and analysis - Provides real-time updates - Live data streaming and processing</p>"},{"location":"09_social_media_integration/#problem-statement","title":"Problem Statement","text":""},{"location":"09_social_media_integration/#social-media-data-challenges","title":"Social Media Data Challenges","text":"<p>Real-world applications need social media data for: - Market research - Understand customer sentiment and trends - Content discovery - Find relevant discussions and influencers - Competitive analysis - Monitor competitor mentions and activities - Lead generation - Identify potential customers and partners - Brand monitoring - Track mentions and reputation - Trend analysis - Identify emerging topics and patterns</p>"},{"location":"09_social_media_integration/#your-solution","title":"Your Solution","text":""},{"location":"09_social_media_integration/#multi-platform-integration","title":"Multi-Platform Integration","text":"<p>Create a social media integration system that addresses these challenges:</p> <ol> <li>Unified API Interface - Consistent interface across platforms</li> <li>Real-time Data Collection - Live streaming and batch processing</li> <li>Data Normalization - Standardize different data formats</li> <li>Rate Limiting &amp; Caching - Efficient API usage and data storage</li> <li>Error Handling &amp; Recovery - Robust error handling and retry logic</li> <li>Data Quality Assurance - Validate and clean collected data</li> </ol>"},{"location":"09_social_media_integration/#technical-requirements","title":"Technical Requirements","text":""},{"location":"09_social_media_integration/#tech-stack","title":"Tech Stack","text":"<ul> <li>Python 3.8+ with asyncio support</li> <li>PRAW - Reddit API wrapper</li> <li>Google API Client - YouTube Data API</li> <li>Tweepy - Twitter API wrapper</li> <li>LinkedIn API - Professional network data</li> <li>GitHub API - Developer community data</li> <li>Redis - Caching and rate limiting</li> <li>Celery - Background task processing</li> <li>FastAPI - API endpoints for data access</li> </ul>"},{"location":"09_social_media_integration/#project-structure","title":"Project Structure","text":""},{"location":"09_social_media_integration/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>social_media_integration/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 connectors/\n\u2502   \u2502   \u251c\u2500\u2500 base.py\n\u2502   \u2502   \u251c\u2500\u2500 reddit.py\n\u2502   \u2502   \u251c\u2500\u2500 youtube.py\n\u2502   \u2502   \u251c\u2500\u2500 twitter.py\n\u2502   \u2502   \u2514\u2500\u2500 linkedin.py\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 post.py\n\u2502   \u2502   \u251c\u2500\u2500 user.py\n\u2502   \u2502   \u251c\u2500\u2500 comment.py\n\u2502   \u2502   \u2514\u2500\u2500 video.py\n\u2502   \u251c\u2500\u2500 services/\n\u2502   \u2502   \u251c\u2500\u2500 rate_limiter.py\n\u2502   \u2502   \u251c\u2500\u2500 data_processor.py\n\u2502   \u2502   \u251c\u2500\u2500 cache_manager.py\n\u2502   \u2502   \u2514\u2500\u2500 error_handler.py\n\u2502   \u251c\u2500\u2500 workers/\n\u2502   \u2502   \u251c\u2500\u2500 collector.py\n\u2502   \u2502   \u251c\u2500\u2500 processor.py\n\u2502   \u2502   \u2514\u2500\u2500 scheduler.py\n\u2502   \u2514\u2500\u2500 api/\n\u2502       \u251c\u2500\u2500 endpoints.py\n\u2502       \u2514\u2500\u2500 middleware.py\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 api_keys.yaml\n\u2502   \u2514\u2500\u2500 settings.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_connectors.py\n\u2502   \u2514\u2500\u2500 test_services.py\n\u2514\u2500\u2500 requirements.txt\n</code></pre>"},{"location":"09_social_media_integration/#core-components","title":"Core Components","text":""},{"location":"09_social_media_integration/#1-base-connector-class","title":"1. Base Connector Class","text":"<pre><code># src/connectors/base.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, List, Optional, AsyncGenerator\nimport asyncio\nimport aiohttp\nfrom datetime import datetime, timedelta\nimport logging\n\nclass BaseConnector(ABC):\n    def __init__(self, api_key: str, rate_limit: int = 100):\n        self.api_key = api_key\n        self.rate_limit = rate_limit\n        self.requests_made = 0\n        self.rate_limit_reset = datetime.now()\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    @abstractmethod\n    async def authenticate(self) -&gt; bool:\n        \"\"\"Authenticate with the API\"\"\"\n        pass\n\n    @abstractmethod\n    async def search_posts(self, query: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"Search for posts matching the query\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_user_profile(self, user_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Get user profile information\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_comments(self, post_id: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get comments for a specific post\"\"\"\n        pass\n\n    async def rate_limit_check(self):\n        \"\"\"Check and enforce rate limits\"\"\"\n        if datetime.now() &lt; self.rate_limit_reset:\n            await asyncio.sleep(1)\n            return\n\n        if self.requests_made &gt;= self.rate_limit:\n            sleep_time = (self.rate_limit_reset - datetime.now()).total_seconds()\n            if sleep_time &gt; 0:\n                await asyncio.sleep(sleep_time)\n            self.requests_made = 0\n            self.rate_limit_reset = datetime.now() + timedelta(hours=1)\n\n    async def make_request(self, url: str, params: Dict[str, Any] = None) -&gt; Dict[str, Any]:\n        \"\"\"Make an authenticated API request\"\"\"\n        await self.rate_limit_check()\n\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(url, params=params) as response:\n                    self.requests_made += 1\n                    if response.status == 200:\n                        return await response.json()\n                    else:\n                        self.logger.error(f\"API request failed: {response.status}\")\n                        return {}\n        except Exception as e:\n            self.logger.error(f\"Request error: {str(e)}\")\n            return {}\n</code></pre>"},{"location":"09_social_media_integration/#core-components_1","title":"Core Components","text":""},{"location":"09_social_media_integration/#2-reddit-connector","title":"2. Reddit Connector","text":"<pre><code># src/connectors/reddit.py\nimport praw\nfrom typing import Dict, Any, List\nfrom .base import BaseConnector\n\nclass RedditConnector(BaseConnector):\n    def __init__(self, client_id: str, client_secret: str, user_agent: str):\n        super().__init__(client_id, rate_limit=100)\n        self.client_secret = client_secret\n        self.user_agent = user_agent\n        self.reddit = None\n\n    async def authenticate(self) -&gt; bool:\n        \"\"\"Authenticate with Reddit API\"\"\"\n        try:\n            self.reddit = praw.Reddit(\n                client_id=self.api_key,\n                client_secret=self.client_secret,\n                user_agent=self.user_agent\n            )\n            # Test authentication\n            self.reddit.user.me()\n            return True\n        except Exception as e:\n            self.logger.error(f\"Reddit authentication failed: {str(e)}\")\n            return False\n\n    async def search_posts(self, query: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"Search for Reddit posts\"\"\"\n        if not self.reddit:\n            await self.authenticate()\n\n        posts = []\n        try:\n            subreddit = self.reddit.subreddit(\"all\")\n            for post in subreddit.search(query, limit=limit):\n                post_data = {\n                    'id': post.id,\n                    'title': post.title,\n                    'content': post.selftext,\n                    'author': str(post.author) if post.author else 'deleted',\n                    'subreddit': str(post.subreddit),\n                    'score': post.score,\n                    'upvote_ratio': post.upvote_ratio,\n                    'num_comments': post.num_comments,\n                    'created_utc': post.created_utc,\n                    'url': post.url,\n                    'permalink': post.permalink,\n                    'is_self': post.is_self,\n                    'over_18': post.over_18,\n                    'stickied': post.stickied,\n                    'awards': post.total_awards_received,\n                    'flair': post.link_flair_text,\n                    'platform': 'reddit'\n                }\n                posts.append(post_data)\n        except Exception as e:\n            self.logger.error(f\"Reddit search failed: {str(e)}\")\n\n        return posts\n\n    async def get_user_profile(self, username: str) -&gt; Dict[str, Any]:\n        \"\"\"Get Reddit user profile\"\"\"\n        if not self.reddit:\n            await self.authenticate()\n\n        try:\n            user = self.reddit.redditor(username)\n            return {\n                'id': str(user),\n                'username': str(user),\n                'created_utc': user.created_utc,\n                'karma': user.comment_karma + user.link_karma,\n                'comment_karma': user.comment_karma,\n                'link_karma': user.link_karma,\n                'is_employee': user.is_employee,\n                'is_mod': user.is_mod,\n                'is_gold': user.is_gold,\n                'is_verified': user.verified,\n                'platform': 'reddit'\n            }\n        except Exception as e:\n            self.logger.error(f\"Failed to get Reddit user profile: {str(e)}\")\n            return {}\n\n    async def get_comments(self, post_id: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get Reddit post comments\"\"\"\n        if not self.reddit:\n            await self.authenticate()\n\n        comments = []\n        try:\n            post = self.reddit.submission(id=post_id)\n            post.comments.replace_more(limit=0)\n            for comment in post.comments.list()[:limit]:\n                comment_data = {\n                    'id': comment.id,\n                    'post_id': post_id,\n                    'author': str(comment.author) if comment.author else 'deleted',\n                    'body': comment.body,\n                    'score': comment.score,\n                    'created_utc': comment.created_utc,\n                    'is_submitter': comment.is_submitter,\n                    'stickied': comment.stickied,\n                    'awards': comment.total_awards_received,\n                    'platform': 'reddit'\n                }\n                comments.append(comment_data)\n        except Exception as e:\n            self.logger.error(f\"Failed to get Reddit comments: {str(e)}\")\n\n        return comments\n</code></pre>"},{"location":"09_social_media_integration/#core-components_2","title":"Core Components","text":""},{"location":"09_social_media_integration/#3-youtube-connector","title":"3. YouTube Connector","text":"<pre><code># src/connectors/youtube.py\nfrom googleapiclient.discovery import build\nfrom typing import Dict, Any, List\nfrom .base import BaseConnector\n\nclass YouTubeConnector(BaseConnector):\n    def __init__(self, api_key: str):\n        super().__init__(api_key, rate_limit=10000)\n        self.youtube = None\n\n    async def authenticate(self) -&gt; bool:\n        \"\"\"Authenticate with YouTube API\"\"\"\n        try:\n            self.youtube = build('youtube', 'v3', developerKey=self.api_key)\n            # Test authentication with a simple request\n            request = self.youtube.channels().list(part='snippet', mine=True)\n            request.execute()\n            return True\n        except Exception as e:\n            self.logger.error(f\"YouTube authentication failed: {str(e)}\")\n            return False\n\n    async def search_videos(self, query: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"Search for YouTube videos\"\"\"\n        if not self.youtube:\n            await self.authenticate()\n\n        videos = []\n        try:\n            search_response = self.youtube.search().list(\n                q=query,\n                part='id,snippet',\n                maxResults=min(limit, 50),  # YouTube API limit\n                type='video',\n                order='relevance'\n            ).execute()\n\n            video_ids = [item['id']['videoId'] for item in search_response['items']]\n\n            # Get detailed video information\n            video_response = self.youtube.videos().list(\n                part='snippet,statistics,contentDetails',\n                id=','.join(video_ids)\n            ).execute()\n\n            for video in video_response['items']:\n                video_data = {\n                    'id': video['id'],\n                    'title': video['snippet']['title'],\n                    'description': video['snippet']['description'],\n                    'channel_id': video['snippet']['channelId'],\n                    'channel_title': video['snippet']['channelTitle'],\n                    'published_at': video['snippet']['publishedAt'],\n                    'duration': video['contentDetails']['duration'],\n                    'views': int(video['statistics'].get('viewCount', 0)),\n                    'likes': int(video['statistics'].get('likeCount', 0)),\n                    'dislikes': int(video['statistics'].get('dislikeCount', 0)),\n                    'comments': int(video['statistics'].get('commentCount', 0)),\n                    'tags': video['snippet'].get('tags', []),\n                    'category_id': video['snippet']['categoryId'],\n                    'thumbnail_url': video['snippet']['thumbnails']['high']['url'],\n                    'platform': 'youtube'\n                }\n                videos.append(video_data)\n        except Exception as e:\n            self.logger.error(f\"YouTube search failed: {str(e)}\")\n\n        return videos\n\n    async def get_channel_info(self, channel_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Get YouTube channel information\"\"\"\n        if not self.youtube:\n            await self.authenticate()\n\n        try:\n            channel_response = self.youtube.channels().list(\n                part='snippet,statistics,contentDetails',\n                id=channel_id\n            ).execute()\n\n            if channel_response['items']:\n                channel = channel_response['items'][0]\n                return {\n                    'id': channel['id'],\n                    'title': channel['snippet']['title'],\n                    'description': channel['snippet']['description'],\n                    'subscriber_count': int(channel['statistics'].get('subscriberCount', 0)),\n                    'video_count': int(channel['statistics'].get('videoCount', 0)),\n                    'view_count': int(channel['statistics'].get('viewCount', 0)),\n                    'created_at': channel['snippet']['publishedAt'],\n                    'country': channel['snippet'].get('country'),\n                    'thumbnail_url': channel['snippet']['thumbnails']['high']['url'],\n                    'platform': 'youtube'\n                }\n        except Exception as e:\n            self.logger.error(f\"Failed to get YouTube channel info: {str(e)}\")\n\n        return {}\n\n    async def get_video_comments(self, video_id: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get YouTube video comments\"\"\"\n        if not self.youtube:\n            await self.authenticate()\n\n        comments = []\n        try:\n            comments_response = self.youtube.commentThreads().list(\n                part='snippet',\n                videoId=video_id,\n                maxResults=min(limit, 100),  # YouTube API limit\n                order='relevance'\n            ).execute()\n\n            for comment_thread in comments_response['items']:\n                comment = comment_thread['snippet']['topLevelComment']['snippet']\n                comment_data = {\n                    'id': comment_thread['id'],\n                    'video_id': video_id,\n                    'author': comment['authorDisplayName'],\n                    'author_channel_id': comment.get('authorChannelId', {}).get('value'),\n                    'text': comment['textDisplay'],\n                    'like_count': comment['likeCount'],\n                    'published_at': comment['publishedAt'],\n                    'updated_at': comment['updatedAt'],\n                    'platform': 'youtube'\n                }\n                comments.append(comment_data)\n        except Exception as e:\n            self.logger.error(f\"Failed to get YouTube comments: {str(e)}\")\n\n        return comments\n</code></pre>"},{"location":"09_social_media_integration/#core-components_3","title":"Core Components","text":""},{"location":"09_social_media_integration/#4-twitter-connector","title":"4. Twitter Connector","text":"<pre><code># src/connectors/twitter.py\nimport tweepy\nfrom typing import Dict, Any, List\nfrom .base import BaseConnector\n\nclass TwitterConnector(BaseConnector):\n    def __init__(self, bearer_token: str, consumer_key: str = None, \n                 consumer_secret: str = None, access_token: str = None, \n                 access_token_secret: str = None):\n        super().__init__(bearer_token, rate_limit=300)\n        self.consumer_key = consumer_key\n        self.consumer_secret = consumer_secret\n        self.access_token = access_token\n        self.access_token_secret = access_token_secret\n        self.client = None\n        self.api = None\n\n    async def authenticate(self) -&gt; bool:\n        \"\"\"Authenticate with Twitter API\"\"\"\n        try:\n            # For read-only operations, bearer token is sufficient\n            self.client = tweepy.Client(bearer_token=self.api_key)\n\n            # For write operations, use OAuth 1.0a\n            if self.consumer_key and self.consumer_secret:\n                auth = tweepy.OAuth1UserHandler(\n                    self.consumer_key,\n                    self.consumer_secret,\n                    self.access_token,\n                    self.access_token_secret\n                )\n                self.api = tweepy.API(auth)\n\n            return True\n        except Exception as e:\n            self.logger.error(f\"Twitter authentication failed: {str(e)}\")\n            return False\n\n    async def search_tweets(self, query: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"Search for tweets\"\"\"\n        if not self.client:\n            await self.authenticate()\n\n        tweets = []\n        try:\n            response = self.client.search_recent_tweets(\n                query=query,\n                max_results=min(limit, 100),  # Twitter API limit\n                tweet_fields=['created_at', 'public_metrics', 'author_id', 'context_annotations']\n            )\n\n            if response.data:\n                for tweet in response.data:\n                    tweet_data = {\n                        'id': tweet.id,\n                        'text': tweet.text,\n                        'author_id': tweet.author_id,\n                        'created_at': tweet.created_at.isoformat(),\n                        'retweet_count': tweet.public_metrics['retweet_count'],\n                        'like_count': tweet.public_metrics['like_count'],\n                        'reply_count': tweet.public_metrics['reply_count'],\n                        'quote_count': tweet.public_metrics['quote_count'],\n                        'platform': 'twitter'\n                    }\n                    tweets.append(tweet_data)\n        except Exception as e:\n            self.logger.error(f\"Twitter search failed: {str(e)}\")\n\n        return tweets\n\n    async def get_user_profile(self, username: str) -&gt; Dict[str, Any]:\n        \"\"\"Get Twitter user profile\"\"\"\n        if not self.client:\n            await self.authenticate()\n\n        try:\n            user = self.client.get_user(\n                username=username,\n                user_fields=['created_at', 'public_metrics', 'description', 'verified']\n            )\n\n            if user.data:\n                return {\n                    'id': user.data.id,\n                    'username': user.data.username,\n                    'name': user.data.name,\n                    'description': user.data.description,\n                    'created_at': user.data.created_at.isoformat(),\n                    'followers_count': user.data.public_metrics['followers_count'],\n                    'following_count': user.data.public_metrics['following_count'],\n                    'tweet_count': user.data.public_metrics['tweet_count'],\n                    'verified': user.data.verified,\n                    'platform': 'twitter'\n                }\n        except Exception as e:\n            self.logger.error(f\"Failed to get Twitter user profile: {str(e)}\")\n\n        return {}\n\n    async def get_tweet_replies(self, tweet_id: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get replies to a specific tweet\"\"\"\n        if not self.client:\n            await self.authenticate()\n\n        replies = []\n        try:\n            response = self.client.search_recent_tweets(\n                query=f\"conversation_id:{tweet_id}\",\n                max_results=min(limit, 100),\n                tweet_fields=['created_at', 'public_metrics', 'author_id']\n            )\n\n            if response.data:\n                for tweet in response.data:\n                    if tweet.id != tweet_id:  # Exclude the original tweet\n                        reply_data = {\n                            'id': tweet.id,\n                            'text': tweet.text,\n                            'author_id': tweet.author_id,\n                            'created_at': tweet.created_at.isoformat(),\n                            'retweet_count': tweet.public_metrics['retweet_count'],\n                            'like_count': tweet.public_metrics['like_count'],\n                            'reply_count': tweet.public_metrics['reply_count'],\n                            'platform': 'twitter'\n                        }\n                        replies.append(reply_data)\n        except Exception as e:\n            self.logger.error(f\"Failed to get Twitter replies: {str(e)}\")\n\n        return replies\n</code></pre>"},{"location":"09_social_media_integration/#data-processing","title":"Data Processing","text":""},{"location":"09_social_media_integration/#data-normalization","title":"Data Normalization","text":"<pre><code># src/services/data_processor.py\nfrom typing import Dict, Any, List\nfrom datetime import datetime\nimport re\n\nclass DataProcessor:\n    def __init__(self):\n        self.platform_processors = {\n            'reddit': self._process_reddit_data,\n            'youtube': self._process_youtube_data,\n            'twitter': self._process_twitter_data\n        }\n\n    def normalize_post(self, raw_data: Dict[str, Any], platform: str) -&gt; Dict[str, Any]:\n        \"\"\"Normalize post data from different platforms\"\"\"\n        processor = self.platform_processors.get(platform)\n        if processor:\n            return processor(raw_data)\n        return raw_data\n\n    def _process_reddit_data(self, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Process Reddit-specific data\"\"\"\n        return {\n            'id': data['id'],\n            'platform': 'reddit',\n            'title': data.get('title', ''),\n            'content': data.get('content', ''),\n            'author': data.get('author', ''),\n            'community': data.get('subreddit', ''),\n            'score': data.get('score', 0),\n            'engagement': {\n                'upvotes': data.get('score', 0),\n                'comments': data.get('num_comments', 0),\n                'awards': data.get('awards', 0)\n            },\n            'created_at': datetime.fromtimestamp(data.get('created_utc', 0)),\n            'url': data.get('url', ''),\n            'metadata': {\n                'subreddit': data.get('subreddit', ''),\n                'flair': data.get('flair'),\n                'nsfw': data.get('over_18', False),\n                'stickied': data.get('stickied', False)\n            }\n        }\n\n    def _process_youtube_data(self, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Process YouTube-specific data\"\"\"\n        return {\n            'id': data['id'],\n            'platform': 'youtube',\n            'title': data.get('title', ''),\n            'content': data.get('description', ''),\n            'author': data.get('channel_title', ''),\n            'community': data.get('channel_id', ''),\n            'score': data.get('likes', 0),\n            'engagement': {\n                'views': data.get('views', 0),\n                'likes': data.get('likes', 0),\n                'dislikes': data.get('dislikes', 0),\n                'comments': data.get('comments', 0)\n            },\n            'created_at': datetime.fromisoformat(data.get('published_at', '').replace('Z', '+00:00')),\n            'url': f\"https://www.youtube.com/watch?v={data['id']}\",\n            'metadata': {\n                'channel_id': data.get('channel_id', ''),\n                'duration': data.get('duration', ''),\n                'category_id': data.get('category_id', ''),\n                'tags': data.get('tags', []),\n                'thumbnail_url': data.get('thumbnail_url', '')\n            }\n        }\n\n    def _process_twitter_data(self, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Process Twitter-specific data\"\"\"\n        return {\n            'id': data['id'],\n            'platform': 'twitter',\n            'title': '',  # Twitter doesn't have titles\n            'content': data.get('text', ''),\n            'author': data.get('author_id', ''),\n            'community': 'twitter',\n            'score': data.get('like_count', 0),\n            'engagement': {\n                'retweets': data.get('retweet_count', 0),\n                'likes': data.get('like_count', 0),\n                'replies': data.get('reply_count', 0),\n                'quotes': data.get('quote_count', 0)\n            },\n            'created_at': datetime.fromisoformat(data.get('created_at', '').replace('Z', '+00:00')),\n            'url': f\"https://twitter.com/i/status/{data['id']}\",\n            'metadata': {\n                'author_id': data.get('author_id', ''),\n                'context_annotations': data.get('context_annotations', [])\n            }\n        }\n\n    def extract_hashtags(self, text: str) -&gt; List[str]:\n        \"\"\"Extract hashtags from text\"\"\"\n        hashtag_pattern = r'#\\w+'\n        return re.findall(hashtag_pattern, text)\n\n    def extract_mentions(self, text: str) -&gt; List[str]:\n        \"\"\"Extract mentions from text\"\"\"\n        mention_pattern = r'@\\w+'\n        return re.findall(mention_pattern, text)\n\n    def extract_urls(self, text: str) -&gt; List[str]:\n        \"\"\"Extract URLs from text\"\"\"\n        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n        return re.findall(url_pattern, text)\n\n    def clean_text(self, text: str) -&gt; str:\n        \"\"\"Clean and normalize text content\"\"\"\n        # Remove extra whitespace\n        text = re.sub(r'\\s+', ' ', text)\n        # Remove special characters but keep basic punctuation\n        text = re.sub(r'[^\\w\\s.,!?;:]', '', text)\n        return text.strip()\n</code></pre>"},{"location":"09_social_media_integration/#rate-limiting","title":"Rate Limiting","text":""},{"location":"09_social_media_integration/#api-rate-management","title":"API Rate Management","text":"<pre><code># src/services/rate_limiter.py\nimport asyncio\nimport time\nfrom typing import Dict, Any\nfrom datetime import datetime, timedelta\nimport redis\n\nclass RateLimiter:\n    def __init__(self, redis_url: str = \"redis://localhost:6379\"):\n        self.redis_client = redis.from_url(redis_url)\n        self.rate_limits = {\n            'reddit': {'requests': 100, 'window': 3600},  # 100 requests per hour\n            'youtube': {'requests': 10000, 'window': 3600},  # 10000 requests per hour\n            'twitter': {'requests': 300, 'window': 900},  # 300 requests per 15 minutes\n            'linkedin': {'requests': 100, 'window': 3600},  # 100 requests per hour\n        }\n\n    async def check_rate_limit(self, platform: str) -&gt; bool:\n        \"\"\"Check if we can make a request to the platform\"\"\"\n        key = f\"rate_limit:{platform}\"\n        limits = self.rate_limits.get(platform, {'requests': 100, 'window': 3600})\n\n        current_time = int(time.time())\n        window_start = current_time - limits['window']\n\n        # Remove old entries\n        self.redis_client.zremrangebyscore(key, 0, window_start)\n\n        # Count current requests\n        current_requests = self.redis_client.zcard(key)\n\n        if current_requests &gt;= limits['requests']:\n            return False\n\n        # Add current request\n        self.redis_client.zadd(key, {str(current_time): current_time})\n        self.redis_client.expire(key, limits['window'])\n\n        return True\n\n    async def wait_for_rate_limit(self, platform: str) -&gt; None:\n        \"\"\"Wait until rate limit allows a request\"\"\"\n        while not await self.check_rate_limit(platform):\n            await asyncio.sleep(1)\n\n    def get_rate_limit_status(self, platform: str) -&gt; Dict[str, Any]:\n        \"\"\"Get current rate limit status for a platform\"\"\"\n        key = f\"rate_limit:{platform}\"\n        limits = self.rate_limits.get(platform, {'requests': 100, 'window': 3600})\n\n        current_requests = self.redis_client.zcard(key)\n        remaining = max(0, limits['requests'] - current_requests)\n\n        return {\n            'platform': platform,\n            'current_requests': current_requests,\n            'limit': limits['requests'],\n            'remaining': remaining,\n            'window_seconds': limits['window']\n        }\n</code></pre>"},{"location":"09_social_media_integration/#background-processing","title":"Background Processing","text":""},{"location":"09_social_media_integration/#celery-workers","title":"Celery Workers","text":"<pre><code># src/workers/collector.py\nfrom celery import Celery\nfrom typing import Dict, Any, List\nimport asyncio\nfrom src.connectors.reddit import RedditConnector\nfrom src.connectors.youtube import YouTubeConnector\nfrom src.connectors.twitter import TwitterConnector\nfrom src.services.data_processor import DataProcessor\nfrom src.services.rate_limiter import RateLimiter\n\napp = Celery('social_media_collector')\n\n@app.task\ndef collect_reddit_data(query: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n    \"\"\"Collect Reddit data for a query\"\"\"\n    async def _collect():\n        connector = RedditConnector(\n            client_id=\"your_client_id\",\n            client_secret=\"your_client_secret\",\n            user_agent=\"FastOpp Data Collector\"\n        )\n\n        rate_limiter = RateLimiter()\n        await rate_limiter.wait_for_rate_limit('reddit')\n\n        posts = await connector.search_posts(query, limit)\n        processor = DataProcessor()\n\n        normalized_posts = []\n        for post in posts:\n            normalized = processor.normalize_post(post, 'reddit')\n            normalized_posts.append(normalized)\n\n        return normalized_posts\n\n    return asyncio.run(_collect())\n\n@app.task\ndef collect_youtube_data(query: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n    \"\"\"Collect YouTube data for a query\"\"\"\n    async def _collect():\n        connector = YouTubeConnector(api_key=\"your_api_key\")\n\n        rate_limiter = RateLimiter()\n        await rate_limiter.wait_for_rate_limit('youtube')\n\n        videos = await connector.search_videos(query, limit)\n        processor = DataProcessor()\n\n        normalized_videos = []\n        for video in videos:\n            normalized = processor.normalize_post(video, 'youtube')\n            normalized_videos.append(normalized)\n\n        return normalized_videos\n\n    return asyncio.run(_collect())\n\n@app.task\ndef collect_twitter_data(query: str, limit: int = 100) -&gt; List[Dict[str, Any]]:\n    \"\"\"Collect Twitter data for a query\"\"\"\n    async def _collect():\n        connector = TwitterConnector(bearer_token=\"your_bearer_token\")\n\n        rate_limiter = RateLimiter()\n        await rate_limiter.wait_for_rate_limit('twitter')\n\n        tweets = await connector.search_tweets(query, limit)\n        processor = DataProcessor()\n\n        normalized_tweets = []\n        for tweet in tweets:\n            normalized = processor.normalize_post(tweet, 'twitter')\n            normalized_tweets.append(normalized)\n\n        return normalized_tweets\n\n    return asyncio.run(_collect())\n\n@app.task\ndef collect_all_platforms(query: str, limit: int = 100) -&gt; Dict[str, List[Dict[str, Any]]]:\n    \"\"\"Collect data from all platforms\"\"\"\n    results = {}\n\n    # Collect from all platforms in parallel\n    reddit_task = collect_reddit_data.delay(query, limit)\n    youtube_task = collect_youtube_data.delay(query, limit)\n    twitter_task = collect_twitter_data.delay(query, limit)\n\n    results['reddit'] = reddit_task.get()\n    results['youtube'] = youtube_task.get()\n    results['twitter'] = twitter_task.get()\n\n    return results\n</code></pre>"},{"location":"09_social_media_integration/#api-endpoints","title":"API Endpoints","text":""},{"location":"09_social_media_integration/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code># src/api/endpoints.py\nfrom fastapi import APIRouter, HTTPException, BackgroundTasks\nfrom typing import Dict, Any, List, Optional\nfrom pydantic import BaseModel\nfrom src.workers.collector import collect_all_platforms, collect_reddit_data\nfrom src.services.rate_limiter import RateLimiter\n\nrouter = APIRouter()\nrate_limiter = RateLimiter()\n\nclass SearchRequest(BaseModel):\n    query: str\n    limit: int = 100\n    platforms: Optional[List[str]] = None\n\nclass SearchResponse(BaseModel):\n    query: str\n    total_results: int\n    platforms: Dict[str, int]\n    data: Dict[str, List[Dict[str, Any]]]\n\n@router.post(\"/search\", response_model=SearchResponse)\nasync def search_social_media(request: SearchRequest, background_tasks: BackgroundTasks):\n    \"\"\"Search across multiple social media platforms\"\"\"\n    try:\n        # Check rate limits for all platforms\n        for platform in request.platforms or ['reddit', 'youtube', 'twitter']:\n            if not await rate_limiter.check_rate_limit(platform):\n                raise HTTPException(\n                    status_code=429, \n                    detail=f\"Rate limit exceeded for {platform}\"\n                )\n\n        # Collect data from all platforms\n        results = collect_all_platforms.delay(request.query, request.limit).get()\n\n        # Calculate totals\n        total_results = sum(len(platform_data) for platform_data in results.values())\n        platform_counts = {platform: len(data) for platform, data in results.items()}\n\n        return SearchResponse(\n            query=request.query,\n            total_results=total_results,\n            platforms=platform_counts,\n            data=results\n        )\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@router.get(\"/rate-limits\")\nasync def get_rate_limits():\n    \"\"\"Get current rate limit status for all platforms\"\"\"\n    status = {}\n    for platform in ['reddit', 'youtube', 'twitter', 'linkedin']:\n        status[platform] = rate_limiter.get_rate_limit_status(platform)\n\n    return status\n\n@router.get(\"/platforms/{platform}/search\")\nasync def search_single_platform(platform: str, query: str, limit: int = 100):\n    \"\"\"Search a single platform\"\"\"\n    if platform not in ['reddit', 'youtube', 'twitter']:\n        raise HTTPException(status_code=400, detail=\"Unsupported platform\")\n\n    if not await rate_limiter.check_rate_limit(platform):\n        raise HTTPException(status_code=429, detail=\"Rate limit exceeded\")\n\n    try:\n        if platform == 'reddit':\n            results = collect_reddit_data.delay(query, limit).get()\n        elif platform == 'youtube':\n            results = collect_youtube_data.delay(query, limit).get()\n        elif platform == 'twitter':\n            results = collect_twitter_data.delay(query, limit).get()\n\n        return {\n            'platform': platform,\n            'query': query,\n            'results': results,\n            'count': len(results)\n        }\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n</code></pre>"},{"location":"09_social_media_integration/#testing","title":"Testing","text":""},{"location":"09_social_media_integration/#comprehensive-test-suite","title":"Comprehensive Test Suite","text":"<pre><code># tests/test_connectors.py\nimport pytest\nfrom unittest.mock import Mock, patch\nfrom src.connectors.reddit import RedditConnector\nfrom src.connectors.youtube import YouTubeConnector\nfrom src.connectors.twitter import TwitterConnector\n\nclass TestRedditConnector:\n    @pytest.fixture\n    def reddit_connector(self):\n        return RedditConnector(\n            client_id=\"test_client_id\",\n            client_secret=\"test_client_secret\",\n            user_agent=\"test_user_agent\"\n        )\n\n    @patch('praw.Reddit')\n    async def test_authenticate_success(self, mock_reddit, reddit_connector):\n        mock_reddit_instance = Mock()\n        mock_reddit_instance.user.me.return_value = Mock()\n        mock_reddit.return_value = mock_reddit_instance\n\n        result = await reddit_connector.authenticate()\n        assert result is True\n\n    @patch('praw.Reddit')\n    async def test_authenticate_failure(self, mock_reddit, reddit_connector):\n        mock_reddit.side_effect = Exception(\"Authentication failed\")\n\n        result = await reddit_connector.authenticate()\n        assert result is False\n\n    @patch('praw.Reddit')\n    async def test_search_posts(self, mock_reddit, reddit_connector):\n        # Mock Reddit instance\n        mock_reddit_instance = Mock()\n        mock_subreddit = Mock()\n        mock_post = Mock()\n        mock_post.id = \"test_id\"\n        mock_post.title = \"Test Post\"\n        mock_post.selftext = \"Test content\"\n        mock_post.author = \"test_author\"\n        mock_post.subreddit = \"test_subreddit\"\n        mock_post.score = 100\n        mock_post.upvote_ratio = 0.95\n        mock_post.num_comments = 50\n        mock_post.created_utc = 1640995200\n        mock_post.url = \"https://reddit.com/test\"\n        mock_post.permalink = \"/r/test/comments/test_id/\"\n        mock_post.is_self = True\n        mock_post.over_18 = False\n        mock_post.stickied = False\n        mock_post.total_awards_received = 5\n        mock_post.link_flair_text = \"Discussion\"\n\n        mock_subreddit.search.return_value = [mock_post]\n        mock_reddit_instance.subreddit.return_value = mock_subreddit\n        mock_reddit.return_value = mock_reddit_instance\n\n        reddit_connector.reddit = mock_reddit_instance\n\n        results = await reddit_connector.search_posts(\"test query\", 10)\n\n        assert len(results) == 1\n        assert results[0]['id'] == \"test_id\"\n        assert results[0]['title'] == \"Test Post\"\n        assert results[0]['platform'] == 'reddit'\n\nclass TestYouTubeConnector:\n    @pytest.fixture\n    def youtube_connector(self):\n        return YouTubeConnector(api_key=\"test_api_key\")\n\n    @patch('googleapiclient.discovery.build')\n    async def test_authenticate_success(self, mock_build, youtube_connector):\n        mock_youtube = Mock()\n        mock_request = Mock()\n        mock_request.execute.return_value = {}\n        mock_youtube.channels.return_value.list.return_value = mock_request\n        mock_build.return_value = mock_youtube\n\n        result = await youtube_connector.authenticate()\n        assert result is True\n\n    @patch('googleapiclient.discovery.build')\n    async def test_search_videos(self, mock_build, youtube_connector):\n        mock_youtube = Mock()\n        mock_search_response = {\n            'items': [{'id': {'videoId': 'test_video_id'}}]\n        }\n        mock_video_response = {\n            'items': [{\n                'id': 'test_video_id',\n                'snippet': {\n                    'title': 'Test Video',\n                    'description': 'Test description',\n                    'channelId': 'test_channel_id',\n                    'channelTitle': 'Test Channel',\n                    'publishedAt': '2024-01-01T00:00:00Z',\n                    'categoryId': '22',\n                    'tags': ['test', 'video'],\n                    'thumbnails': {'high': {'url': 'https://example.com/thumb.jpg'}}\n                },\n                'statistics': {\n                    'viewCount': '1000',\n                    'likeCount': '100',\n                    'dislikeCount': '10',\n                    'commentCount': '50'\n                },\n                'contentDetails': {'duration': 'PT5M30S'}\n            }]\n        }\n\n        mock_youtube.search.return_value.list.return_value.execute.return_value = mock_search_response\n        mock_youtube.videos.return_value.list.return_value.execute.return_value = mock_video_response\n        mock_build.return_value = mock_youtube\n\n        youtube_connector.youtube = mock_youtube\n\n        results = await youtube_connector.search_videos(\"test query\", 10)\n\n        assert len(results) == 1\n        assert results[0]['id'] == 'test_video_id'\n        assert results[0]['title'] == 'Test Video'\n        assert results[0]['platform'] == 'youtube'\n</code></pre>"},{"location":"09_social_media_integration/#success-criteria","title":"Success Criteria","text":""},{"location":"09_social_media_integration/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Multi-Platform Integration - Connect to Reddit, YouTube, and Twitter</li> <li> Rate Limiting - Respect API limits and implement proper throttling</li> <li> Data Normalization - Standardize data from different platforms</li> <li> Error Handling - Robust error handling and retry logic</li> <li> Background Processing - Use Celery for async data collection</li> <li> API Endpoints - RESTful API for data access</li> <li> Data Validation - Ensure data quality and consistency</li> <li> Comprehensive Testing - Unit tests and integration tests</li> </ul>"},{"location":"09_social_media_integration/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"09_social_media_integration/#advanced-features","title":"Advanced Features","text":"<ul> <li> Real-time Streaming - WebSocket connections for live data</li> <li> Data Caching - Redis caching for improved performance</li> <li> Sentiment Analysis - Analyze sentiment of collected content</li> <li> Trend Detection - Identify trending topics and hashtags</li> <li> User Profiling - Build comprehensive user profiles</li> <li> Content Recommendation - Recommend relevant content to users</li> <li> Data Visualization - Create dashboards for data insights</li> <li> Machine Learning - Use ML for content classification and analysis</li> </ul>"},{"location":"09_social_media_integration/#getting-started","title":"Getting Started","text":""},{"location":"09_social_media_integration/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Get API Keys - Register for Reddit, YouTube, and Twitter APIs</li> <li>Set up environment - Install required packages and dependencies</li> <li>Configure Redis - Set up Redis for rate limiting and caching</li> <li>Set up Celery - Configure background task processing</li> <li>Implement connectors - Start with one platform, then expand</li> <li>Add data processing - Normalize and clean collected data</li> <li>Build API endpoints - Create RESTful API for data access</li> <li>Add testing - Write comprehensive tests for all components</li> </ol>"},{"location":"09_social_media_integration/#dependencies","title":"Dependencies","text":""},{"location":"09_social_media_integration/#requirementstxt","title":"requirements.txt","text":"<pre><code>praw&gt;=7.7.0\ngoogle-api-python-client&gt;=2.100.0\ntweepy&gt;=4.14.0\nfastapi&gt;=0.100.0\ncelery&gt;=5.3.0\nredis&gt;=4.6.0\naiohttp&gt;=3.8.0\npandas&gt;=2.0.0\npydantic&gt;=2.0.0\npytest&gt;=7.0.0\npytest-asyncio&gt;=0.21.0\n</code></pre>"},{"location":"09_social_media_integration/#resources","title":"Resources","text":""},{"location":"09_social_media_integration/#helpful-links","title":"Helpful Links","text":"<ul> <li>PRAW Documentation - https://praw.readthedocs.io/</li> <li>YouTube Data API - https://developers.google.com/youtube/v3</li> <li>Twitter API v2 - https://developer.twitter.com/en/docs/twitter-api</li> <li>Celery - https://docs.celeryproject.org/</li> <li>Redis - https://redis.io/docs/</li> <li>FastAPI - https://fastapi.tiangolo.com/</li> </ul>"},{"location":"09_social_media_integration/#lets-connect-to-social-media","title":"Let's Connect to Social Media!","text":""},{"location":"09_social_media_integration/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - API integration and authentication - Rate limiting and error handling - Data normalization and processing - Background task processing - Real-time data collection - Social media data analysis</p> <p>Start with one platform and build up to a comprehensive social media integration system!</p>"},{"location":"09_social_media_integration/#next-steps","title":"Next Steps","text":""},{"location":"09_social_media_integration/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Deploy your system - Set up production infrastructure</li> <li>Monitor performance - Track API usage and system performance</li> <li>Share your insights - Document your findings and learnings</li> <li>Contribute to open source - Share your connectors with the community</li> <li>Move to the next track - Try advanced search algorithms or machine learning next!</li> </ol> <p>Happy social media integration! \ud83d\ude80</p>"},{"location":"10_advanced_search_algorithms/","title":"Search Algorithms","text":""},{"location":"10_advanced_search_algorithms/#advanced-search-algorithms-assignment","title":"Advanced Search Algorithms Assignment","text":""},{"location":"10_advanced_search_algorithms/#beyond-cosine-similarity","title":"Beyond Cosine Similarity","text":"<p>Implement and compare multiple similarity algorithms for better search results</p>"},{"location":"10_advanced_search_algorithms/#assignment-overview","title":"Assignment Overview","text":""},{"location":"10_advanced_search_algorithms/#what-youll-build","title":"What You'll Build","text":"<p>A comprehensive search algorithm system that implements: - Multiple similarity measures - Cosine, Jaccard, Euclidean, and more - Semantic search - BERT, RoBERTa, and transformer-based embeddings - Hybrid search - Combine multiple algorithms for better results - Learning-to-rank - ML-based ranking optimization - Graph-based search - Network analysis and recommendations - Performance comparison - Benchmark different algorithms</p>"},{"location":"10_advanced_search_algorithms/#problem-statement","title":"Problem Statement","text":""},{"location":"10_advanced_search_algorithms/#limitations-of-basic-search","title":"Limitations of Basic Search","text":"<p>The current FastOpp system uses basic cosine similarity, which has limitations: - Semantic understanding - Can't understand meaning and context - Language variations - Struggles with synonyms and paraphrasing - Multi-modal search - Can't handle different content types effectively - Personalization - No user-specific ranking or preferences - Scalability - Performance degrades with large datasets - Relevance tuning - Hard to optimize for specific use cases</p>"},{"location":"10_advanced_search_algorithms/#your-solution","title":"Your Solution","text":""},{"location":"10_advanced_search_algorithms/#advanced-search-system","title":"Advanced Search System","text":"<p>Create a comprehensive search system that addresses these limitations:</p> <ol> <li>Multiple Algorithms - Implement various similarity measures</li> <li>Semantic Understanding - Use transformer models for better context</li> <li>Hybrid Approaches - Combine multiple algorithms for optimal results</li> <li>Machine Learning - Use ML for ranking and personalization</li> <li>Graph Analysis - Leverage network relationships for recommendations</li> <li>Performance Optimization - Efficient algorithms for large datasets</li> </ol>"},{"location":"10_advanced_search_algorithms/#technical-requirements","title":"Technical Requirements","text":""},{"location":"10_advanced_search_algorithms/#tech-stack","title":"Tech Stack","text":"<ul> <li>Python 3.8+ with type hints</li> <li>NumPy &amp; SciPy - Numerical computations</li> <li>Scikit-learn - Machine learning algorithms</li> <li>Transformers - Hugging Face transformer models</li> <li>FAISS - Efficient similarity search</li> <li>NetworkX - Graph analysis</li> <li>Pandas - Data manipulation</li> <li>Matplotlib/Seaborn - Visualization</li> </ul>"},{"location":"10_advanced_search_algorithms/#project-structure","title":"Project Structure","text":""},{"location":"10_advanced_search_algorithms/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>advanced_search/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 algorithms/\n\u2502   \u2502   \u251c\u2500\u2500 similarity.py\n\u2502   \u2502   \u251c\u2500\u2500 semantic.py\n\u2502   \u2502   \u251c\u2500\u2500 hybrid.py\n\u2502   \u2502   \u2514\u2500\u2500 learning_to_rank.py\n\u2502   \u251c\u2500\u2500 embeddings/\n\u2502   \u2502   \u251c\u2500\u2500 text_embeddings.py\n\u2502   \u2502   \u251c\u2500\u2500 image_embeddings.py\n\u2502   \u2502   \u2514\u2500\u2500 multimodal.py\n\u2502   \u251c\u2500\u2500 ranking/\n\u2502   \u2502   \u251c\u2500\u2500 rankers.py\n\u2502   \u2502   \u251c\u2500\u2500 personalization.py\n\u2502   \u2502   \u2514\u2500\u2500 optimization.py\n\u2502   \u251c\u2500\u2500 evaluation/\n\u2502   \u2502   \u251c\u2500\u2500 metrics.py\n\u2502   \u2502   \u251c\u2500\u2500 benchmarks.py\n\u2502   \u2502   \u2514\u2500\u2500 visualization.py\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u251c\u2500\u2500 preprocessing.py\n\u2502       \u2514\u2500\u2500 performance.py\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 test_datasets/\n\u2502   \u2514\u2500\u2500 embeddings/\n\u251c\u2500\u2500 experiments/\n\u2502   \u251c\u2500\u2500 algorithm_comparison.py\n\u2502   \u2514\u2500\u2500 hyperparameter_tuning.py\n\u2514\u2500\u2500 tests/\n    \u251c\u2500\u2500 test_algorithms.py\n    \u2514\u2500\u2500 test_evaluation.py\n</code></pre>"},{"location":"10_advanced_search_algorithms/#core-components","title":"Core Components","text":""},{"location":"10_advanced_search_algorithms/#1-similarity-algorithms","title":"1. Similarity Algorithms","text":"<pre><code># src/algorithms/similarity.py\nimport numpy as np\nfrom scipy.spatial.distance import cosine, euclidean, jaccard\nfrom scipy.stats import pearsonr\nfrom sklearn.metrics.pairwise import cosine_similarity, manhattan_distances\nfrom typing import List, Tuple, Dict, Any\nimport math\n\nclass SimilarityAlgorithms:\n    def __init__(self):\n        self.algorithms = {\n            'cosine': self.cosine_similarity,\n            'euclidean': self.euclidean_similarity,\n            'manhattan': self.manhattan_similarity,\n            'jaccard': self.jaccard_similarity,\n            'pearson': self.pearson_similarity,\n            'jensen_shannon': self.jensen_shannon_similarity,\n            'bray_curtis': self.bray_curtis_similarity,\n            'canberra': self.canberra_similarity\n        }\n\n    def cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -&gt; float:\n        \"\"\"Calculate cosine similarity between two vectors\"\"\"\n        if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n            return 0.0\n        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n\n    def euclidean_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -&gt; float:\n        \"\"\"Calculate Euclidean distance similarity (1 - normalized distance)\"\"\"\n        distance = euclidean(vec1, vec2)\n        max_distance = math.sqrt(len(vec1))  # Maximum possible distance\n        return 1 - (distance / max_distance)\n\n    def manhattan_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -&gt; float:\n        \"\"\"Calculate Manhattan distance similarity\"\"\"\n        distance = manhattan_distances([vec1], [vec2])[0][0]\n        max_distance = np.sum(np.abs(vec1)) + np.sum(np.abs(vec2))\n        return 1 - (distance / max_distance) if max_distance &gt; 0 else 0\n\n    def jaccard_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -&gt; float:\n        \"\"\"Calculate Jaccard similarity for binary vectors\"\"\"\n        # Convert to binary if needed\n        vec1_binary = (vec1 &gt; 0).astype(int)\n        vec2_binary = (vec2 &gt; 0).astype(int)\n\n        intersection = np.sum(vec1_binary &amp; vec2_binary)\n        union = np.sum(vec1_binary | vec2_binary)\n\n        return intersection / union if union &gt; 0 else 0\n\n    def pearson_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -&gt; float:\n        \"\"\"Calculate Pearson correlation coefficient\"\"\"\n        if len(vec1) != len(vec2) or len(vec1) &lt; 2:\n            return 0.0\n\n        correlation, _ = pearsonr(vec1, vec2)\n        return correlation if not np.isnan(correlation) else 0.0\n\n    def jensen_shannon_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -&gt; float:\n        \"\"\"Calculate Jensen-Shannon divergence similarity\"\"\"\n        # Normalize vectors to probability distributions\n        p = vec1 / np.sum(vec1) if np.sum(vec1) &gt; 0 else vec1\n        q = vec2 / np.sum(vec2) if np.sum(vec2) &gt; 0 else vec2\n\n        # Calculate KL divergence\n        def kl_divergence(p, q):\n            return np.sum(p * np.log(p / q + 1e-10))\n\n        # Jensen-Shannon divergence\n        m = 0.5 * (p + q)\n        js_div = 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n\n        # Convert to similarity (1 - JS divergence)\n        return 1 - js_div\n\n    def bray_curtis_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -&gt; float:\n        \"\"\"Calculate Bray-Curtis similarity\"\"\"\n        numerator = np.sum(np.abs(vec1 - vec2))\n        denominator = np.sum(vec1 + vec2)\n        return 1 - (numerator / denominator) if denominator &gt; 0 else 0\n\n    def canberra_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -&gt; float:\n        \"\"\"Calculate Canberra similarity\"\"\"\n        numerator = np.sum(np.abs(vec1 - vec2))\n        denominator = np.sum(np.abs(vec1) + np.abs(vec2))\n        return 1 - (numerator / denominator) if denominator &gt; 0 else 0\n\n    def calculate_similarity(self, vec1: np.ndarray, vec2: np.ndarray, \n                           algorithm: str = 'cosine') -&gt; float:\n        \"\"\"Calculate similarity using specified algorithm\"\"\"\n        if algorithm not in self.algorithms:\n            raise ValueError(f\"Unknown algorithm: {algorithm}\")\n\n        return self.algorithms[algorithm](vec1, vec2)\n\n    def batch_similarity(self, query_vec: np.ndarray, \n                        candidate_vecs: np.ndarray, \n                        algorithm: str = 'cosine') -&gt; np.ndarray:\n        \"\"\"Calculate similarity between query and multiple candidates\"\"\"\n        similarities = []\n        for candidate_vec in candidate_vecs:\n            sim = self.calculate_similarity(query_vec, candidate_vec, algorithm)\n            similarities.append(sim)\n        return np.array(similarities)\n</code></pre>"},{"location":"10_advanced_search_algorithms/#core-components_1","title":"Core Components","text":""},{"location":"10_advanced_search_algorithms/#2-semantic-search","title":"2. Semantic Search","text":"<pre><code># src/algorithms/semantic.py\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\nfrom typing import List, Dict, Any, Optional\nimport faiss\nfrom sentence_transformers import SentenceTransformer\n\nclass SemanticSearch:\n    def __init__(self, model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'):\n        self.model_name = model_name\n        self.model = SentenceTransformer(model_name)\n        self.index = None\n        self.documents = []\n        self.embeddings = None\n\n    def encode_text(self, texts: List[str]) -&gt; np.ndarray:\n        \"\"\"Encode texts to embeddings\"\"\"\n        embeddings = self.model.encode(texts, convert_to_tensor=False)\n        return embeddings\n\n    def build_index(self, documents: List[Dict[str, Any]], \n                   index_type: str = 'flat') -&gt; None:\n        \"\"\"Build FAISS index for efficient similarity search\"\"\"\n        self.documents = documents\n        texts = [doc.get('content', '') for doc in documents]\n\n        # Encode documents\n        self.embeddings = self.encode_text(texts)\n\n        # Create FAISS index\n        dimension = self.embeddings.shape[1]\n\n        if index_type == 'flat':\n            self.index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n        elif index_type == 'ivf':\n            quantizer = faiss.IndexFlatIP(dimension)\n            self.index = faiss.IndexIVFFlat(quantizer, dimension, 100)\n        elif index_type == 'hnsw':\n            self.index = faiss.IndexHNSWFlat(dimension, 32)\n\n        # Normalize embeddings for cosine similarity\n        faiss.normalize_L2(self.embeddings)\n        self.index.add(self.embeddings.astype('float32'))\n\n    def search(self, query: str, top_k: int = 10, \n              threshold: float = 0.0) -&gt; List[Dict[str, Any]]:\n        \"\"\"Search for similar documents\"\"\"\n        if self.index is None:\n            raise ValueError(\"Index not built. Call build_index() first.\")\n\n        # Encode query\n        query_embedding = self.encode_text([query])\n        faiss.normalize_L2(query_embedding)\n\n        # Search\n        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)\n\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx == -1:  # Invalid index\n                continue\n\n            if score &gt;= threshold:\n                result = {\n                    'document': self.documents[idx],\n                    'score': float(score),\n                    'index': int(idx)\n                }\n                results.append(result)\n\n        return results\n\n    def search_with_filters(self, query: str, filters: Dict[str, Any], \n                           top_k: int = 10) -&gt; List[Dict[str, Any]]:\n        \"\"\"Search with additional filters\"\"\"\n        # Get all results first\n        all_results = self.search(query, top_k * 2)  # Get more results for filtering\n\n        # Apply filters\n        filtered_results = []\n        for result in all_results:\n            doc = result['document']\n            matches_filter = True\n\n            for key, value in filters.items():\n                if key in doc:\n                    if isinstance(value, list):\n                        if doc[key] not in value:\n                            matches_filter = False\n                            break\n                    else:\n                        if doc[key] != value:\n                            matches_filter = False\n                            break\n                else:\n                    matches_filter = False\n                    break\n\n            if matches_filter:\n                filtered_results.append(result)\n                if len(filtered_results) &gt;= top_k:\n                    break\n\n        return filtered_results[:top_k]\n\nclass MultiModelSemanticSearch:\n    def __init__(self, models: List[str] = None):\n        self.models = models or [\n            'sentence-transformers/all-MiniLM-L6-v2',\n            'sentence-transformers/all-mpnet-base-v2',\n            'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n        ]\n        self.searchers = {}\n\n        for model_name in self.models:\n            self.searchers[model_name] = SemanticSearch(model_name)\n\n    def build_indexes(self, documents: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Build indexes for all models\"\"\"\n        for searcher in self.searchers.values():\n            searcher.build_index(documents)\n\n    def ensemble_search(self, query: str, top_k: int = 10, \n                       weights: Dict[str, float] = None) -&gt; List[Dict[str, Any]]:\n        \"\"\"Perform ensemble search across multiple models\"\"\"\n        if weights is None:\n            weights = {model: 1.0 for model in self.models}\n\n        all_results = {}\n\n        # Get results from each model\n        for model_name, searcher in self.searchers.items():\n            results = searcher.search(query, top_k * 2)\n            for result in results:\n                doc_id = result['index']\n                if doc_id not in all_results:\n                    all_results[doc_id] = {\n                        'document': result['document'],\n                        'scores': {},\n                        'index': doc_id\n                    }\n                all_results[doc_id]['scores'][model_name] = result['score']\n\n        # Calculate ensemble scores\n        ensemble_results = []\n        for doc_id, result in all_results.items():\n            ensemble_score = 0\n            total_weight = 0\n\n            for model_name, score in result['scores'].items():\n                weight = weights.get(model_name, 1.0)\n                ensemble_score += score * weight\n                total_weight += weight\n\n            if total_weight &gt; 0:\n                ensemble_score /= total_weight\n                result['ensemble_score'] = ensemble_score\n                ensemble_results.append(result)\n\n        # Sort by ensemble score\n        ensemble_results.sort(key=lambda x: x['ensemble_score'], reverse=True)\n\n        return ensemble_results[:top_k]\n</code></pre>"},{"location":"10_advanced_search_algorithms/#core-components_2","title":"Core Components","text":""},{"location":"10_advanced_search_algorithms/#3-hybrid-search","title":"3. Hybrid Search","text":"<pre><code># src/algorithms/hybrid.py\nimport numpy as np\nfrom typing import List, Dict, Any, Tuple\nfrom .similarity import SimilarityAlgorithms\nfrom .semantic import SemanticSearch\nimport pandas as pd\n\nclass HybridSearch:\n    def __init__(self, semantic_model: str = 'sentence-transformers/all-MiniLM-L6-v2'):\n        self.similarity_algorithms = SimilarityAlgorithms()\n        self.semantic_search = SemanticSearch(semantic_model)\n        self.documents = []\n        self.tfidf_vectors = None\n        self.bm25_vectors = None\n\n    def build_index(self, documents: List[Dict[str, Any]], \n                   use_tfidf: bool = True, use_bm25: bool = True) -&gt; None:\n        \"\"\"Build multiple indexes for hybrid search\"\"\"\n        self.documents = documents\n\n        # Build semantic index\n        self.semantic_search.build_index(documents)\n\n        # Build TF-IDF index\n        if use_tfidf:\n            self._build_tfidf_index(documents)\n\n        # Build BM25 index\n        if use_bm25:\n            self._build_bm25_index(documents)\n\n    def _build_tfidf_index(self, documents: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Build TF-IDF index\"\"\"\n        from sklearn.feature_extraction.text import TfidfVectorizer\n\n        texts = [doc.get('content', '') for doc in documents]\n        vectorizer = TfidfVectorizer(\n            max_features=10000,\n            stop_words='english',\n            ngram_range=(1, 2)\n        )\n\n        self.tfidf_vectors = vectorizer.fit_transform(texts)\n        self.tfidf_vectorizer = vectorizer\n\n    def _build_bm25_index(self, documents: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Build BM25 index\"\"\"\n        from rank_bm25 import BM25Okapi\n\n        texts = [doc.get('content', '').split() for doc in documents]\n        self.bm25 = BM25Okapi(texts)\n\n    def search(self, query: str, top_k: int = 10, \n              weights: Dict[str, float] = None) -&gt; List[Dict[str, Any]]:\n        \"\"\"Perform hybrid search combining multiple algorithms\"\"\"\n        if weights is None:\n            weights = {\n                'semantic': 0.4,\n                'tfidf': 0.3,\n                'bm25': 0.3\n            }\n\n        results = {}\n\n        # Semantic search\n        if 'semantic' in weights and weights['semantic'] &gt; 0:\n            semantic_results = self.semantic_search.search(query, top_k * 2)\n            for result in semantic_results:\n                doc_id = result['index']\n                if doc_id not in results:\n                    results[doc_id] = {\n                        'document': result['document'],\n                        'scores': {},\n                        'index': doc_id\n                    }\n                results[doc_id]['scores']['semantic'] = result['score']\n\n        # TF-IDF search\n        if 'tfidf' in weights and weights['tfidf'] &gt; 0 and self.tfidf_vectors is not None:\n            query_vector = self.tfidf_vectorizer.transform([query])\n            tfidf_scores = cosine_similarity(query_vector, self.tfidf_vectors).flatten()\n\n            top_indices = np.argsort(tfidf_scores)[::-1][:top_k * 2]\n            for idx in top_indices:\n                if idx not in results:\n                    results[idx] = {\n                        'document': self.documents[idx],\n                        'scores': {},\n                        'index': idx\n                    }\n                results[idx]['scores']['tfidf'] = float(tfidf_scores[idx])\n\n        # BM25 search\n        if 'bm25' in weights and weights['bm25'] &gt; 0 and self.bm25 is not None:\n            bm25_scores = self.bm25.get_scores(query.split())\n            top_indices = np.argsort(bm25_scores)[::-1][:top_k * 2]\n\n            for idx in top_indices:\n                if idx not in results:\n                    results[idx] = {\n                        'document': self.documents[idx],\n                        'scores': {},\n                        'index': idx\n                    }\n                results[idx]['scores']['bm25'] = float(bm25_scores[idx])\n\n        # Calculate hybrid scores\n        hybrid_results = []\n        for doc_id, result in results.items():\n            hybrid_score = 0\n            total_weight = 0\n\n            for algorithm, score in result['scores'].items():\n                weight = weights.get(algorithm, 0)\n                hybrid_score += score * weight\n                total_weight += weight\n\n            if total_weight &gt; 0:\n                hybrid_score /= total_weight\n                result['hybrid_score'] = hybrid_score\n                hybrid_results.append(result)\n\n        # Sort by hybrid score\n        hybrid_results.sort(key=lambda x: x['hybrid_score'], reverse=True)\n\n        return hybrid_results[:top_k]\n\nclass AdaptiveHybridSearch:\n    def __init__(self, semantic_model: str = 'sentence-transformers/all-MiniLM-L6-v2'):\n        self.hybrid_search = HybridSearch(semantic_model)\n        self.query_classifier = None\n        self.performance_history = []\n\n    def build_index(self, documents: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Build indexes and train query classifier\"\"\"\n        self.hybrid_search.build_index(documents)\n        self._train_query_classifier(documents)\n\n    def _train_query_classifier(self, documents: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Train a classifier to determine optimal weights for different query types\"\"\"\n        from sklearn.feature_extraction.text import TfidfVectorizer\n        from sklearn.ensemble import RandomForestClassifier\n\n        # Generate training data with different query types\n        training_queries = []\n        training_labels = []\n\n        # Short queries (favor BM25)\n        short_queries = [\"python\", \"machine learning\", \"data science\"]\n        for query in short_queries:\n            training_queries.append(query)\n            training_labels.append('short')\n\n        # Long queries (favor semantic)\n        long_queries = [\n            \"How to implement machine learning algorithms in Python\",\n            \"Best practices for data preprocessing and feature engineering\",\n            \"Understanding deep learning architectures and their applications\"\n        ]\n        for query in long_queries:\n            training_queries.append(query)\n            training_labels.append('long')\n\n        # Technical queries (favor TF-IDF)\n        tech_queries = [\"API documentation\", \"error handling\", \"performance optimization\"]\n        for query in tech_queries:\n            training_queries.append(query)\n            training_labels.append('technical')\n\n        # Train classifier\n        vectorizer = TfidfVectorizer(max_features=1000)\n        X = vectorizer.fit_transform(training_queries)\n\n        self.query_classifier = RandomForestClassifier(n_estimators=100)\n        self.query_classifier.fit(X, vectorizer)\n        self.query_vectorizer = vectorizer\n\n    def classify_query(self, query: str) -&gt; str:\n        \"\"\"Classify query type to determine optimal weights\"\"\"\n        if self.query_classifier is None:\n            return 'default'\n\n        query_vector = self.query_vectorizer.transform([query])\n        prediction = self.query_classifier.predict(query_vector)[0]\n        return prediction\n\n    def get_adaptive_weights(self, query: str) -&gt; Dict[str, float]:\n        \"\"\"Get adaptive weights based on query classification\"\"\"\n        query_type = self.classify_query(query)\n\n        weight_configs = {\n            'short': {'semantic': 0.2, 'tfidf': 0.3, 'bm25': 0.5},\n            'long': {'semantic': 0.6, 'tfidf': 0.2, 'bm25': 0.2},\n            'technical': {'semantic': 0.3, 'tfidf': 0.5, 'bm25': 0.2},\n            'default': {'semantic': 0.4, 'tfidf': 0.3, 'bm25': 0.3}\n        }\n\n        return weight_configs.get(query_type, weight_configs['default'])\n\n    def search(self, query: str, top_k: int = 10) -&gt; List[Dict[str, Any]]:\n        \"\"\"Perform adaptive hybrid search\"\"\"\n        weights = self.get_adaptive_weights(query)\n        return self.hybrid_search.search(query, top_k, weights)\n\n    def update_performance(self, query: str, results: List[Dict[str, Any]], \n                          user_feedback: Dict[int, float]) -&gt; None:\n        \"\"\"Update performance based on user feedback\"\"\"\n        # Store performance data for future optimization\n        performance_data = {\n            'query': query,\n            'weights': self.get_adaptive_weights(query),\n            'results': results,\n            'feedback': user_feedback,\n            'timestamp': pd.Timestamp.now()\n        }\n        self.performance_history.append(performance_data)\n\n        # Retrain classifier if we have enough data\n        if len(self.performance_history) &gt; 100:\n            self._retrain_classifier()\n\n    def _retrain_classifier(self) -&gt; None:\n        \"\"\"Retrain query classifier based on performance history\"\"\"\n        # Implementation would analyze performance history\n        # and retrain the classifier for better weight prediction\n        pass\n</code></pre>"},{"location":"10_advanced_search_algorithms/#core-components_3","title":"Core Components","text":""},{"location":"10_advanced_search_algorithms/#4-learning-to-rank","title":"4. Learning to Rank","text":"<pre><code># src/algorithms/learning_to_rank.py\nimport numpy as np\nimport pandas as pd\nfrom typing import List, Dict, Any, Tuple\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import ndcg_score\nimport xgboost as xgb\n\nclass LearningToRank:\n    def __init__(self, model_type: str = 'xgboost'):\n        self.model_type = model_type\n        self.model = None\n        self.feature_names = []\n        self.training_data = []\n\n    def extract_features(self, query: str, documents: List[Dict[str, Any]], \n                        algorithm_scores: Dict[str, List[float]]) -&gt; np.ndarray:\n        \"\"\"Extract features for learning to rank\"\"\"\n        features = []\n\n        for i, doc in enumerate(documents):\n            doc_features = []\n\n            # Query features\n            query_length = len(query.split())\n            doc_features.append(query_length)\n\n            # Document features\n            content_length = len(doc.get('content', '').split())\n            doc_features.append(content_length)\n\n            # Title features\n            title_length = len(doc.get('title', '').split())\n            doc_features.append(title_length)\n\n            # Algorithm scores\n            for algorithm, scores in algorithm_scores.items():\n                if i &lt; len(scores):\n                    doc_features.append(scores[i])\n                else:\n                    doc_features.append(0.0)\n\n            # Text similarity features\n            query_words = set(query.lower().split())\n            content_words = set(doc.get('content', '').lower().split())\n            title_words = set(doc.get('title', '').lower().split())\n\n            # Word overlap\n            content_overlap = len(query_words.intersection(content_words)) / len(query_words) if query_words else 0\n            title_overlap = len(query_words.intersection(title_words)) / len(query_words) if query_words else 0\n\n            doc_features.extend([content_overlap, title_overlap])\n\n            # Position features\n            doc_features.append(i)  # Original position\n\n            # Recency features\n            if 'created_at' in doc:\n                days_old = (pd.Timestamp.now() - pd.to_datetime(doc['created_at'])).days\n                doc_features.append(days_old)\n            else:\n                doc_features.append(0)\n\n            # Engagement features\n            if 'engagement' in doc:\n                engagement = doc['engagement']\n                total_engagement = sum(engagement.values()) if isinstance(engagement, dict) else engagement\n                doc_features.append(total_engagement)\n            else:\n                doc_features.append(0)\n\n            features.append(doc_features)\n\n        return np.array(features)\n\n    def train(self, training_queries: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Train the learning to rank model\"\"\"\n        X = []\n        y = []\n\n        for query_data in training_queries:\n            query = query_data['query']\n            documents = query_data['documents']\n            relevance_scores = query_data['relevance_scores']\n            algorithm_scores = query_data['algorithm_scores']\n\n            # Extract features\n            features = self.extract_features(query, documents, algorithm_scores)\n            X.append(features)\n            y.append(relevance_scores)\n\n        # Combine all features\n        X = np.vstack(X)\n        y = np.concatenate(y)\n\n        # Train model\n        if self.model_type == 'xgboost':\n            self.model = xgb.XGBRanker(\n                objective='rank:pairwise',\n                n_estimators=100,\n                max_depth=6,\n                learning_rate=0.1\n            )\n            # XGBoost requires group information\n            groups = [len(query_data['documents']) for query_data in training_queries]\n            self.model.fit(X, y, group=groups)\n\n        elif self.model_type == 'random_forest':\n            self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n            self.model.fit(X, y)\n\n        elif self.model_type == 'gradient_boosting':\n            self.model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n            self.model.fit(X, y)\n\n        elif self.model_type == 'linear':\n            self.model = LinearRegression()\n            self.model.fit(X, y)\n\n    def predict_ranking(self, query: str, documents: List[Dict[str, Any]], \n                       algorithm_scores: Dict[str, List[float]]) -&gt; List[float]:\n        \"\"\"Predict ranking scores for documents\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not trained. Call train() first.\")\n\n        features = self.extract_features(query, documents, algorithm_scores)\n        scores = self.model.predict(features)\n        return scores.tolist()\n\n    def rank_documents(self, query: str, documents: List[Dict[str, Any]], \n                      algorithm_scores: Dict[str, List[float]]) -&gt; List[Dict[str, Any]]:\n        \"\"\"Rank documents using the trained model\"\"\"\n        scores = self.predict_ranking(query, documents, algorithm_scores)\n\n        # Create results with ranking scores\n        ranked_docs = []\n        for i, (doc, score) in enumerate(zip(documents, scores)):\n            ranked_doc = doc.copy()\n            ranked_doc['ranking_score'] = score\n            ranked_doc['original_position'] = i\n            ranked_docs.append(ranked_doc)\n\n        # Sort by ranking score\n        ranked_docs.sort(key=lambda x: x['ranking_score'], reverse=True)\n\n        return ranked_docs\n\n    def evaluate(self, test_queries: List[Dict[str, Any]]) -&gt; Dict[str, float]:\n        \"\"\"Evaluate the model on test data\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not trained. Call train() first.\")\n\n        ndcg_scores = []\n        mrr_scores = []\n\n        for query_data in test_queries:\n            query = query_data['query']\n            documents = query_data['documents']\n            relevance_scores = query_data['relevance_scores']\n            algorithm_scores = query_data['algorithm_scores']\n\n            # Get predicted scores\n            predicted_scores = self.predict_ranking(query, documents, algorithm_scores)\n\n            # Calculate NDCG\n            ndcg = ndcg_score([relevance_scores], [predicted_scores])\n            ndcg_scores.append(ndcg)\n\n            # Calculate MRR\n            sorted_indices = np.argsort(predicted_scores)[::-1]\n            mrr = 0\n            for i, idx in enumerate(sorted_indices):\n                if relevance_scores[idx] &gt; 0:\n                    mrr = 1.0 / (i + 1)\n                    break\n            mrr_scores.append(mrr)\n\n        return {\n            'ndcg_mean': np.mean(ndcg_scores),\n            'ndcg_std': np.std(ndcg_scores),\n            'mrr_mean': np.mean(mrr_scores),\n            'mrr_std': np.std(mrr_scores)\n        }\n\nclass PersonalizedLearningToRank(LearningToRank):\n    def __init__(self, model_type: str = 'xgboost'):\n        super().__init__(model_type)\n        self.user_models = {}\n        self.global_model = None\n\n    def train_user_model(self, user_id: str, training_queries: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Train a personalized model for a specific user\"\"\"\n        user_ltor = LearningToRank(self.model_type)\n        user_ltor.train(training_queries)\n        self.user_models[user_id] = user_ltor\n\n    def train_global_model(self, training_queries: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Train a global model using all user data\"\"\"\n        super().train(training_queries)\n        self.global_model = self.model\n\n    def rank_documents_personalized(self, user_id: str, query: str, \n                                   documents: List[Dict[str, Any]], \n                                   algorithm_scores: Dict[str, List[float]]) -&gt; List[Dict[str, Any]]:\n        \"\"\"Rank documents using personalized model if available, otherwise global model\"\"\"\n        if user_id in self.user_models:\n            return self.user_models[user_id].rank_documents(query, documents, algorithm_scores)\n        elif self.global_model is not None:\n            return self.rank_documents(query, documents, algorithm_scores)\n        else:\n            raise ValueError(\"No model available for ranking\")\n</code></pre>"},{"location":"10_advanced_search_algorithms/#evaluation","title":"Evaluation","text":""},{"location":"10_advanced_search_algorithms/#performance-metrics","title":"Performance Metrics","text":"<pre><code># src/evaluation/metrics.py\nimport numpy as np\nfrom typing import List, Dict, Any\nfrom sklearn.metrics import ndcg_score, precision_score, recall_score\nimport pandas as pd\n\nclass SearchEvaluator:\n    def __init__(self):\n        self.metrics = {}\n\n    def calculate_ndcg(self, relevance_scores: List[float], \n                      predicted_scores: List[float], k: int = 10) -&gt; float:\n        \"\"\"Calculate Normalized Discounted Cumulative Gain\"\"\"\n        if len(relevance_scores) != len(predicted_scores):\n            raise ValueError(\"Relevance and predicted scores must have same length\")\n\n        # Sort by predicted scores\n        sorted_indices = np.argsort(predicted_scores)[::-1]\n        sorted_relevance = [relevance_scores[i] for i in sorted_indices[:k]]\n\n        # Calculate DCG\n        dcg = 0\n        for i, rel in enumerate(sorted_relevance):\n            dcg += rel / np.log2(i + 2)\n\n        # Calculate IDCG (ideal DCG)\n        ideal_relevance = sorted(relevance_scores, reverse=True)[:k]\n        idcg = 0\n        for i, rel in enumerate(ideal_relevance):\n            idcg += rel / np.log2(i + 2)\n\n        return dcg / idcg if idcg &gt; 0 else 0\n\n    def calculate_mrr(self, relevance_scores: List[float], \n                     predicted_scores: List[float]) -&gt; float:\n        \"\"\"Calculate Mean Reciprocal Rank\"\"\"\n        sorted_indices = np.argsort(predicted_scores)[::-1]\n\n        for i, idx in enumerate(sorted_indices):\n            if relevance_scores[idx] &gt; 0:\n                return 1.0 / (i + 1)\n\n        return 0\n\n    def calculate_precision_at_k(self, relevance_scores: List[float], \n                                predicted_scores: List[float], k: int = 10) -&gt; float:\n        \"\"\"Calculate Precision@K\"\"\"\n        sorted_indices = np.argsort(predicted_scores)[::-1]\n        top_k_indices = sorted_indices[:k]\n\n        relevant_count = sum(1 for idx in top_k_indices if relevance_scores[idx] &gt; 0)\n        return relevant_count / k\n\n    def calculate_recall_at_k(self, relevance_scores: List[float], \n                             predicted_scores: List[float], k: int = 10) -&gt; float:\n        \"\"\"Calculate Recall@K\"\"\"\n        total_relevant = sum(1 for score in relevance_scores if score &gt; 0)\n        if total_relevant == 0:\n            return 0\n\n        sorted_indices = np.argsort(predicted_scores)[::-1]\n        top_k_indices = sorted_indices[:k]\n\n        relevant_retrieved = sum(1 for idx in top_k_indices if relevance_scores[idx] &gt; 0)\n        return relevant_retrieved / total_relevant\n\n    def calculate_map(self, relevance_scores: List[float], \n                     predicted_scores: List[float]) -&gt; float:\n        \"\"\"Calculate Mean Average Precision\"\"\"\n        sorted_indices = np.argsort(predicted_scores)[::-1]\n\n        precision_sum = 0\n        relevant_count = 0\n\n        for i, idx in enumerate(sorted_indices):\n            if relevance_scores[idx] &gt; 0:\n                relevant_count += 1\n                precision_at_i = relevant_count / (i + 1)\n                precision_sum += precision_at_i\n\n        return precision_sum / relevant_count if relevant_count &gt; 0 else 0\n\n    def evaluate_algorithm(self, algorithm_name: str, \n                          test_queries: List[Dict[str, Any]]) -&gt; Dict[str, float]:\n        \"\"\"Evaluate a specific algorithm on test queries\"\"\"\n        ndcg_scores = []\n        mrr_scores = []\n        precision_scores = []\n        recall_scores = []\n        map_scores = []\n\n        for query_data in test_queries:\n            relevance_scores = query_data['relevance_scores']\n            predicted_scores = query_data['algorithm_scores'][algorithm_name]\n\n            ndcg_scores.append(self.calculate_ndcg(relevance_scores, predicted_scores))\n            mrr_scores.append(self.calculate_mrr(relevance_scores, predicted_scores))\n            precision_scores.append(self.calculate_precision_at_k(relevance_scores, predicted_scores))\n            recall_scores.append(self.calculate_recall_at_k(relevance_scores, predicted_scores))\n            map_scores.append(self.calculate_map(relevance_scores, predicted_scores))\n\n        return {\n            'ndcg_mean': np.mean(ndcg_scores),\n            'ndcg_std': np.std(ndcg_scores),\n            'mrr_mean': np.mean(mrr_scores),\n            'mrr_std': np.std(mrr_scores),\n            'precision_mean': np.mean(precision_scores),\n            'precision_std': np.std(precision_scores),\n            'recall_mean': np.mean(recall_scores),\n            'recall_std': np.std(recall_scores),\n            'map_mean': np.mean(map_scores),\n            'map_std': np.std(map_scores)\n        }\n\n    def compare_algorithms(self, algorithm_results: Dict[str, List[Dict[str, Any]]]) -&gt; pd.DataFrame:\n        \"\"\"Compare multiple algorithms\"\"\"\n        comparison_data = []\n\n        for algorithm_name, test_queries in algorithm_results.items():\n            metrics = self.evaluate_algorithm(algorithm_name, test_queries)\n            metrics['algorithm'] = algorithm_name\n            comparison_data.append(metrics)\n\n        return pd.DataFrame(comparison_data)\n\n    def generate_report(self, comparison_df: pd.DataFrame) -&gt; str:\n        \"\"\"Generate a comprehensive evaluation report\"\"\"\n        report = \"# Algorithm Comparison Report\\n\\n\"\n\n        # Summary table\n        report += \"## Summary\\n\\n\"\n        report += comparison_df.to_string(index=False)\n        report += \"\\n\\n\"\n\n        # Best performing algorithm\n        best_ndcg = comparison_df.loc[comparison_df['ndcg_mean'].idxmax()]\n        report += f\"## Best Performing Algorithm (NDCG)\\n\\n\"\n        report += f\"**{best_ndcg['algorithm']}** with NDCG: {best_ndcg['ndcg_mean']:.4f}\\n\\n\"\n\n        # Detailed analysis\n        report += \"## Detailed Analysis\\n\\n\"\n        for metric in ['ndcg_mean', 'mrr_mean', 'precision_mean', 'recall_mean', 'map_mean']:\n            best_algorithm = comparison_df.loc[comparison_df[metric].idxmax()]\n            report += f\"- **{metric.replace('_', ' ').title()}**: {best_algorithm['algorithm']} ({best_algorithm[metric]:.4f})\\n\"\n\n        return report\n</code></pre>"},{"location":"10_advanced_search_algorithms/#success-criteria","title":"Success Criteria","text":""},{"location":"10_advanced_search_algorithms/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Multiple Similarity Algorithms - Implement at least 5 different similarity measures</li> <li> Semantic Search - Use transformer models for semantic understanding</li> <li> Hybrid Search - Combine multiple algorithms for better results</li> <li> Learning to Rank - Implement ML-based ranking optimization</li> <li> Performance Evaluation - Comprehensive metrics and benchmarking</li> <li> Algorithm Comparison - Compare different approaches objectively</li> <li> Documentation - Clear documentation of algorithms and results</li> <li> Testing - Unit tests and integration tests</li> </ul>"},{"location":"10_advanced_search_algorithms/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"10_advanced_search_algorithms/#advanced-features","title":"Advanced Features","text":"<ul> <li> Graph-based Search - Use network analysis for recommendations</li> <li> Multi-modal Search - Handle text, images, and other content types</li> <li> Real-time Learning - Update models based on user feedback</li> <li> A/B Testing - Compare different algorithms in production</li> <li> Personalization - User-specific ranking and recommendations</li> <li> Federated Search - Search across multiple data sources</li> <li> Query Expansion - Improve search with related terms</li> <li> Result Diversification - Ensure diverse and relevant results</li> </ul>"},{"location":"10_advanced_search_algorithms/#getting-started","title":"Getting Started","text":""},{"location":"10_advanced_search_algorithms/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Set up environment - Install required packages and dependencies</li> <li>Prepare test data - Create or obtain test datasets for evaluation</li> <li>Implement basic algorithms - Start with simple similarity measures</li> <li>Add semantic search - Integrate transformer models</li> <li>Build hybrid system - Combine multiple approaches</li> <li>Implement learning to rank - Add ML-based ranking</li> <li>Create evaluation framework - Build comprehensive testing system</li> <li>Compare and optimize - Benchmark different approaches</li> </ol>"},{"location":"10_advanced_search_algorithms/#dependencies","title":"Dependencies","text":""},{"location":"10_advanced_search_algorithms/#requirementstxt","title":"requirements.txt","text":"<pre><code>numpy&gt;=1.24.0\nscipy&gt;=1.10.0\nscikit-learn&gt;=1.3.0\ntransformers&gt;=4.30.0\nsentence-transformers&gt;=2.2.0\nfaiss-cpu&gt;=1.7.4\npandas&gt;=2.0.0\nmatplotlib&gt;=3.7.0\nseaborn&gt;=0.12.0\nxgboost&gt;=1.7.0\nrank-bm25&gt;=0.2.2\nnetworkx&gt;=3.1.0\npytest&gt;=7.0.0\n</code></pre>"},{"location":"10_advanced_search_algorithms/#resources","title":"Resources","text":""},{"location":"10_advanced_search_algorithms/#helpful-links","title":"Helpful Links","text":"<ul> <li>Scikit-learn - https://scikit-learn.org/</li> <li>Transformers - https://huggingface.co/transformers/</li> <li>FAISS - https://github.com/facebookresearch/faiss</li> <li>Learning to Rank - https://en.wikipedia.org/wiki/Learning_to_rank</li> <li>NDCG - https://en.wikipedia.org/wiki/Discounted_cumulative_gain</li> <li>BM25 - https://en.wikipedia.org/wiki/Okapi_BM25</li> </ul>"},{"location":"10_advanced_search_algorithms/#lets-build-advanced-search","title":"Let's Build Advanced Search!","text":""},{"location":"10_advanced_search_algorithms/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Advanced similarity algorithms and their applications - Semantic search and transformer models - Hybrid search and ensemble methods - Machine learning for ranking optimization - Performance evaluation and benchmarking - Algorithm comparison and optimization</p> <p>Start with basic similarity algorithms and build up to a comprehensive search system!</p>"},{"location":"10_advanced_search_algorithms/#next-steps","title":"Next Steps","text":""},{"location":"10_advanced_search_algorithms/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Benchmark your results - Compare with existing search systems</li> <li>Optimize performance - Improve speed and accuracy</li> <li>Share your findings - Document your results and insights</li> <li>Contribute to open source - Share your implementations</li> <li>Move to the next track - Try database exploration or machine learning pipelines next!</li> </ol> <p>Happy algorithm development! \ud83d\ude80</p>"},{"location":"11_database_exploration/","title":"Database Exploration","text":""},{"location":"11_database_exploration/#database-exploration-assignment","title":"Database Exploration Assignment","text":""},{"location":"11_database_exploration/#beyond-sqlite-and-faiss","title":"Beyond SQLite and FAISS","text":"<p>Explore different databases for different use cases</p>"},{"location":"11_database_exploration/#assignment-overview","title":"Assignment Overview","text":""},{"location":"11_database_exploration/#what-youll-build","title":"What You'll Build","text":"<p>A comprehensive database exploration system that: - Compares different databases - SQLite, PostgreSQL, MongoDB, Elasticsearch - Optimizes for different use cases - OLTP, OLAP, search, analytics - Implements data pipelines - ETL processes and data synchronization - Benchmarks performance - Speed, scalability, and resource usage - Handles different data types - Structured, semi-structured, and unstructured - Provides data insights - Analytics and reporting capabilities</p>"},{"location":"11_database_exploration/#problem-statement","title":"Problem Statement","text":""},{"location":"11_database_exploration/#database-limitations","title":"Database Limitations","text":"<p>The current FastOpp system uses SQLite and FAISS, which have limitations: - Scalability - SQLite doesn't scale well for large datasets - Concurrency - Limited concurrent read/write operations - Search capabilities - Basic text search and vector similarity - Data types - Limited support for complex data structures - Performance - Not optimized for specific use cases - Analytics - Limited analytical and reporting capabilities</p>"},{"location":"11_database_exploration/#your-solution","title":"Your Solution","text":""},{"location":"11_database_exploration/#multi-database-architecture","title":"Multi-Database Architecture","text":"<p>Create a comprehensive database system that addresses these limitations:</p> <ol> <li>Database Selection - Choose the right database for each use case</li> <li>Data Modeling - Design optimal schemas for different databases</li> <li>Performance Optimization - Indexing, query optimization, and caching</li> <li>Data Synchronization - Keep multiple databases in sync</li> <li>Analytics Pipeline - Extract insights from your data</li> <li>Monitoring - Track performance and usage patterns</li> </ol>"},{"location":"11_database_exploration/#technical-requirements","title":"Technical Requirements","text":""},{"location":"11_database_exploration/#tech-stack","title":"Tech Stack","text":"<ul> <li>PostgreSQL - Advanced relational database</li> <li>MongoDB - Document-based NoSQL database</li> <li>Elasticsearch - Full-text search and analytics</li> <li>Redis - In-memory caching and session storage</li> <li>ClickHouse - Columnar database for analytics</li> <li>Neo4j - Graph database for relationships</li> <li>Apache Kafka - Stream processing and data pipelines</li> </ul>"},{"location":"11_database_exploration/#database-comparison","title":"Database Comparison","text":""},{"location":"11_database_exploration/#use-case-matrix","title":"Use Case Matrix","text":"Database Best For Strengths Weaknesses SQLite Development, small apps Simple, embedded, no setup Limited concurrency, no network PostgreSQL Complex queries, ACID Advanced SQL, JSON support Memory usage, complexity MongoDB Document storage, flexibility Schema flexibility, scaling No joins, eventual consistency Elasticsearch Search, analytics Full-text search, aggregations Not ACID, resource intensive Redis Caching, sessions Speed, data structures Memory only, no persistence ClickHouse Analytics, OLAP Columnar storage, speed Not OLTP, limited updates Neo4j Graph relationships Graph queries, relationships Not for tabular data"},{"location":"11_database_exploration/#core-components","title":"Core Components","text":""},{"location":"11_database_exploration/#1-database-connectors","title":"1. Database Connectors","text":"<pre><code># src/databases/connectors.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, List, Optional\nimport asyncio\nimport asyncpg\nimport motor.motor_asyncio\nfrom elasticsearch import AsyncElasticsearch\nimport redis.asyncio as redis\nimport clickhouse_connect\nfrom neo4j import AsyncGraphDatabase\n\nclass BaseDatabase(ABC):\n    def __init__(self, connection_string: str):\n        self.connection_string = connection_string\n        self.client = None\n\n    @abstractmethod\n    async def connect(self) -&gt; bool:\n        \"\"\"Connect to the database\"\"\"\n        pass\n\n    @abstractmethod\n    async def disconnect(self) -&gt; None:\n        \"\"\"Disconnect from the database\"\"\"\n        pass\n\n    @abstractmethod\n    async def query(self, query: str, params: Dict[str, Any] = None) -&gt; List[Dict[str, Any]]:\n        \"\"\"Execute a query and return results\"\"\"\n        pass\n\nclass PostgreSQLConnector(BaseDatabase):\n    async def connect(self) -&gt; bool:\n        try:\n            self.client = await asyncpg.connect(self.connection_string)\n            return True\n        except Exception as e:\n            print(f\"PostgreSQL connection failed: {e}\")\n            return False\n\n    async def disconnect(self) -&gt; None:\n        if self.client:\n            await self.client.close()\n\n    async def query(self, query: str, params: Dict[str, Any] = None) -&gt; List[Dict[str, Any]]:\n        if not self.client:\n            raise ValueError(\"Not connected to database\")\n\n        rows = await self.client.fetch(query, *(params or {}).values())\n        return [dict(row) for row in rows]\n\nclass MongoDBConnector(BaseDatabase):\n    async def connect(self) -&gt; bool:\n        try:\n            self.client = motor.motor_asyncio.AsyncIOMotorClient(self.connection_string)\n            await self.client.admin.command('ping')\n            return True\n        except Exception as e:\n            print(f\"MongoDB connection failed: {e}\")\n            return False\n\n    async def disconnect(self) -&gt; None:\n        if self.client:\n            self.client.close()\n\n    async def query(self, collection: str, filter: Dict[str, Any] = None, \n                   projection: Dict[str, Any] = None) -&gt; List[Dict[str, Any]]:\n        if not self.client:\n            raise ValueError(\"Not connected to database\")\n\n        db = self.client.get_default_database()\n        cursor = db[collection].find(filter or {}, projection)\n        return await cursor.to_list(length=None)\n\nclass ElasticsearchConnector(BaseDatabase):\n    async def connect(self) -&gt; bool:\n        try:\n            self.client = AsyncElasticsearch([self.connection_string])\n            await self.client.ping()\n            return True\n        except Exception as e:\n            print(f\"Elasticsearch connection failed: {e}\")\n            return False\n\n    async def disconnect(self) -&gt; None:\n        if self.client:\n            await self.client.close()\n\n    async def query(self, index: str, body: Dict[str, Any]) -&gt; List[Dict[str, Any]]:\n        if not self.client:\n            raise ValueError(\"Not connected to database\")\n\n        response = await self.client.search(index=index, body=body)\n        return [hit['_source'] for hit in response['hits']['hits']]\n\nclass RedisConnector(BaseDatabase):\n    async def connect(self) -&gt; bool:\n        try:\n            self.client = redis.from_url(self.connection_string)\n            await self.client.ping()\n            return True\n        except Exception as e:\n            print(f\"Redis connection failed: {e}\")\n            return False\n\n    async def disconnect(self) -&gt; None:\n        if self.client:\n            await self.client.close()\n\n    async def query(self, command: str, *args) -&gt; Any:\n        if not self.client:\n            raise ValueError(\"Not connected to database\")\n\n        return await self.client.execute_command(command, *args)\n</code></pre>"},{"location":"11_database_exploration/#core-components_1","title":"Core Components","text":""},{"location":"11_database_exploration/#2-data-synchronization","title":"2. Data Synchronization","text":"<pre><code># src/databases/sync.py\nimport asyncio\nfrom typing import Dict, Any, List\nfrom datetime import datetime\nimport json\n\nclass DatabaseSynchronizer:\n    def __init__(self, source_db: BaseDatabase, target_dbs: List[BaseDatabase]):\n        self.source_db = source_db\n        self.target_dbs = target_dbs\n        self.sync_log = []\n\n    async def sync_table(self, table_name: str, \n                        sync_strategy: str = 'full') -&gt; Dict[str, Any]:\n        \"\"\"Synchronize a table from source to target databases\"\"\"\n        sync_start = datetime.now()\n\n        try:\n            # Get data from source\n            if sync_strategy == 'full':\n                data = await self._full_sync(table_name)\n            elif sync_strategy == 'incremental':\n                data = await self._incremental_sync(table_name)\n            else:\n                raise ValueError(f\"Unknown sync strategy: {sync_strategy}\")\n\n            # Sync to target databases\n            sync_results = {}\n            for target_db in self.target_dbs:\n                result = await self._sync_to_target(target_db, table_name, data)\n                sync_results[target_db.__class__.__name__] = result\n\n            sync_end = datetime.now()\n            sync_duration = (sync_end - sync_start).total_seconds()\n\n            sync_info = {\n                'table': table_name,\n                'strategy': sync_strategy,\n                'records_synced': len(data),\n                'duration_seconds': sync_duration,\n                'target_results': sync_results,\n                'timestamp': sync_start.isoformat()\n            }\n\n            self.sync_log.append(sync_info)\n            return sync_info\n\n        except Exception as e:\n            error_info = {\n                'table': table_name,\n                'strategy': sync_strategy,\n                'error': str(e),\n                'timestamp': sync_start.isoformat()\n            }\n            self.sync_log.append(error_info)\n            raise\n\n    async def _full_sync(self, table_name: str) -&gt; List[Dict[str, Any]]:\n        \"\"\"Perform full table synchronization\"\"\"\n        query = f\"SELECT * FROM {table_name}\"\n        return await self.source_db.query(query)\n\n    async def _incremental_sync(self, table_name: str) -&gt; List[Dict[str, Any]]:\n        \"\"\"Perform incremental synchronization\"\"\"\n        # Get last sync timestamp\n        last_sync = await self._get_last_sync_timestamp(table_name)\n\n        # Query for records modified since last sync\n        query = f\"\"\"\n        SELECT * FROM {table_name} \n        WHERE updated_at &gt; %s\n        ORDER BY updated_at\n        \"\"\"\n        return await self.source_db.query(query, {'last_sync': last_sync})\n\n    async def _sync_to_target(self, target_db: BaseDatabase, \n                            table_name: str, data: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Sync data to a specific target database\"\"\"\n        start_time = datetime.now()\n\n        try:\n            if isinstance(target_db, MongoDBConnector):\n                result = await self._sync_to_mongodb(target_db, table_name, data)\n            elif isinstance(target_db, ElasticsearchConnector):\n                result = await self._sync_to_elasticsearch(target_db, table_name, data)\n            elif isinstance(target_db, RedisConnector):\n                result = await self._sync_to_redis(target_db, table_name, data)\n            else:\n                result = await self._sync_to_sql(target_db, table_name, data)\n\n            end_time = datetime.now()\n            duration = (end_time - start_time).total_seconds()\n\n            return {\n                'success': True,\n                'records_processed': len(data),\n                'duration_seconds': duration,\n                'result': result\n            }\n\n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'records_processed': 0\n            }\n\n    async def _sync_to_mongodb(self, target_db: MongoDBConnector, \n                              table_name: str, data: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Sync data to MongoDB\"\"\"\n        db = target_db.client.get_default_database()\n        collection = db[table_name]\n\n        # Clear existing data\n        await collection.delete_many({})\n\n        # Insert new data\n        if data:\n            await collection.insert_many(data)\n\n        return {'operation': 'insert_many', 'count': len(data)}\n\n    async def _sync_to_elasticsearch(self, target_db: ElasticsearchConnector, \n                                   table_name: str, data: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Sync data to Elasticsearch\"\"\"\n        index_name = table_name.lower()\n\n        # Create index if it doesn't exist\n        if not await target_db.client.indices.exists(index=index_name):\n            await target_db.client.indices.create(index=index_name)\n\n        # Bulk insert data\n        if data:\n            bulk_body = []\n            for doc in data:\n                bulk_body.append({\n                    'index': {\n                        '_index': index_name,\n                        '_id': doc.get('id', doc.get('_id'))\n                    }\n                })\n                bulk_body.append(doc)\n\n            response = await target_db.client.bulk(body=bulk_body)\n            return {'operation': 'bulk_insert', 'count': len(data)}\n\n        return {'operation': 'bulk_insert', 'count': 0}\n\n    async def _sync_to_redis(self, target_db: RedisConnector, \n                           table_name: str, data: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Sync data to Redis\"\"\"\n        key_prefix = f\"{table_name}:\"\n\n        # Clear existing keys\n        pattern = f\"{key_prefix}*\"\n        keys = await target_db.client.keys(pattern)\n        if keys:\n            await target_db.client.delete(*keys)\n\n        # Set new data\n        for doc in data:\n            key = f\"{key_prefix}{doc.get('id', doc.get('_id'))}\"\n            await target_db.client.set(key, json.dumps(doc))\n\n        return {'operation': 'set', 'count': len(data)}\n\n    async def _sync_to_sql(self, target_db: BaseDatabase, \n                          table_name: str, data: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Sync data to SQL database\"\"\"\n        if not data:\n            return {'operation': 'insert', 'count': 0}\n\n        # Get column names from first record\n        columns = list(data[0].keys())\n        placeholders = ', '.join([f'${i+1}' for i in range(len(columns))])\n\n        # Create table if it doesn't exist\n        create_table_query = f\"\"\"\n        CREATE TABLE IF NOT EXISTS {table_name} (\n            {', '.join([f'{col} TEXT' for col in columns])}\n        )\n        \"\"\"\n        await target_db.query(create_table_query)\n\n        # Insert data\n        insert_query = f\"\"\"\n        INSERT INTO {table_name} ({', '.join(columns)})\n        VALUES ({placeholders})\n        \"\"\"\n\n        for doc in data:\n            values = [doc.get(col) for col in columns]\n            await target_db.query(insert_query, values)\n\n        return {'operation': 'insert', 'count': len(data)}\n</code></pre>"},{"location":"11_database_exploration/#core-components_2","title":"Core Components","text":""},{"location":"11_database_exploration/#3-performance-benchmarking","title":"3. Performance Benchmarking","text":"<pre><code># src/databases/benchmark.py\nimport asyncio\nimport time\nfrom typing import Dict, Any, List\nimport statistics\nfrom dataclasses import dataclass\n\n@dataclass\nclass BenchmarkResult:\n    operation: str\n    database: str\n    records: int\n    duration_seconds: float\n    records_per_second: float\n    memory_usage_mb: float\n    cpu_usage_percent: float\n\nclass DatabaseBenchmark:\n    def __init__(self, databases: Dict[str, BaseDatabase]):\n        self.databases = databases\n        self.results = []\n\n    async def benchmark_read_operations(self, table_name: str, \n                                      record_counts: List[int] = [100, 1000, 10000]) -&gt; List[BenchmarkResult]:\n        \"\"\"Benchmark read operations across different databases\"\"\"\n        results = []\n\n        for db_name, db in self.databases.items():\n            for record_count in record_counts:\n                # Generate test data\n                test_data = await self._generate_test_data(record_count)\n\n                # Benchmark read operations\n                result = await self._benchmark_read(db, table_name, test_data)\n                result.database = db_name\n                result.records = record_count\n                results.append(result)\n\n        return results\n\n    async def benchmark_write_operations(self, table_name: str, \n                                       record_counts: List[int] = [100, 1000, 10000]) -&gt; List[BenchmarkResult]:\n        \"\"\"Benchmark write operations across different databases\"\"\"\n        results = []\n\n        for db_name, db in self.databases.items():\n            for record_count in record_counts:\n                # Generate test data\n                test_data = await self._generate_test_data(record_count)\n\n                # Benchmark write operations\n                result = await self._benchmark_write(db, table_name, test_data)\n                result.database = db_name\n                result.records = record_count\n                results.append(result)\n\n        return results\n\n    async def benchmark_search_operations(self, table_name: str, \n                                        search_queries: List[str]) -&gt; List[BenchmarkResult]:\n        \"\"\"Benchmark search operations across different databases\"\"\"\n        results = []\n\n        for db_name, db in self.databases.items():\n            for query in search_queries:\n                result = await self._benchmark_search(db, table_name, query)\n                result.database = db_name\n                result.records = 0  # Search results vary\n                results.append(result)\n\n        return results\n\n    async def _benchmark_read(self, db: BaseDatabase, table_name: str, \n                            test_data: List[Dict[str, Any]]) -&gt; BenchmarkResult:\n        \"\"\"Benchmark read operations for a specific database\"\"\"\n        start_time = time.time()\n        start_memory = self._get_memory_usage()\n        start_cpu = self._get_cpu_usage()\n\n        # Perform read operations\n        if isinstance(db, MongoDBConnector):\n            await db.query(table_name, {})\n        elif isinstance(db, ElasticsearchConnector):\n            await db.query(table_name, {'query': {'match_all': {}}})\n        else:\n            await db.query(f\"SELECT * FROM {table_name}\")\n\n        end_time = time.time()\n        end_memory = self._get_memory_usage()\n        end_cpu = self._get_cpu_usage()\n\n        duration = end_time - start_time\n        memory_usage = end_memory - start_memory\n        cpu_usage = end_cpu - start_cpu\n\n        return BenchmarkResult(\n            operation='read',\n            database='',\n            records=len(test_data),\n            duration_seconds=duration,\n            records_per_second=len(test_data) / duration if duration &gt; 0 else 0,\n            memory_usage_mb=memory_usage,\n            cpu_usage_percent=cpu_usage\n        )\n\n    async def _benchmark_write(self, db: BaseDatabase, table_name: str, \n                             test_data: List[Dict[str, Any]]) -&gt; BenchmarkResult:\n        \"\"\"Benchmark write operations for a specific database\"\"\"\n        start_time = time.time()\n        start_memory = self._get_memory_usage()\n        start_cpu = self._get_cpu_usage()\n\n        # Perform write operations\n        if isinstance(db, MongoDBConnector):\n            db_client = db.client.get_default_database()\n            collection = db_client[table_name]\n            await collection.insert_many(test_data)\n        elif isinstance(db, ElasticsearchConnector):\n            # Bulk insert to Elasticsearch\n            bulk_body = []\n            for doc in test_data:\n                bulk_body.append({'index': {'_index': table_name}})\n                bulk_body.append(doc)\n            await db.client.bulk(body=bulk_body)\n        else:\n            # SQL insert\n            if test_data:\n                columns = list(test_data[0].keys())\n                placeholders = ', '.join([f'${i+1}' for i in range(len(columns))])\n                insert_query = f\"\"\"\n                INSERT INTO {table_name} ({', '.join(columns)})\n                VALUES ({placeholders})\n                \"\"\"\n                for doc in test_data:\n                    values = [doc.get(col) for col in columns]\n                    await db.query(insert_query, values)\n\n        end_time = time.time()\n        end_memory = self._get_memory_usage()\n        end_cpu = self._get_cpu_usage()\n\n        duration = end_time - start_time\n        memory_usage = end_memory - start_memory\n        cpu_usage = end_cpu - start_cpu\n\n        return BenchmarkResult(\n            operation='write',\n            database='',\n            records=len(test_data),\n            duration_seconds=duration,\n            records_per_second=len(test_data) / duration if duration &gt; 0 else 0,\n            memory_usage_mb=memory_usage,\n            cpu_usage_percent=cpu_usage\n        )\n\n    async def _benchmark_search(self, db: BaseDatabase, table_name: str, \n                              query: str) -&gt; BenchmarkResult:\n        \"\"\"Benchmark search operations for a specific database\"\"\"\n        start_time = time.time()\n        start_memory = self._get_memory_usage()\n        start_cpu = self._get_cpu_usage()\n\n        # Perform search operations\n        if isinstance(db, MongoDBConnector):\n            await db.query(table_name, {'$text': {'$search': query}})\n        elif isinstance(db, ElasticsearchConnector):\n            search_body = {\n                'query': {\n                    'multi_match': {\n                        'query': query,\n                        'fields': ['*']\n                    }\n                }\n            }\n            await db.query(table_name, search_body)\n        else:\n            await db.query(f\"\"\"\n                SELECT * FROM {table_name} \n                WHERE content ILIKE %s\n            \"\"\", {'query': f'%{query}%'})\n\n        end_time = time.time()\n        end_memory = self._get_memory_usage()\n        end_cpu = self._get_cpu_usage()\n\n        duration = end_time - start_time\n        memory_usage = end_memory - start_memory\n        cpu_usage = end_cpu - start_cpu\n\n        return BenchmarkResult(\n            operation='search',\n            database='',\n            records=0,  # Search results vary\n            duration_seconds=duration,\n            records_per_second=0,\n            memory_usage_mb=memory_usage,\n            cpu_usage_percent=cpu_usage\n        )\n\n    def generate_report(self, results: List[BenchmarkResult]) -&gt; str:\n        \"\"\"Generate a comprehensive benchmark report\"\"\"\n        report = \"# Database Performance Benchmark Report\\n\\n\"\n\n        # Group results by operation\n        operations = {}\n        for result in results:\n            if result.operation not in operations:\n                operations[result.operation] = []\n            operations[result.operation].append(result)\n\n        for operation, op_results in operations.items():\n            report += f\"## {operation.title()} Operations\\n\\n\"\n\n            # Group by database\n            databases = {}\n            for result in op_results:\n                if result.database not in databases:\n                    databases[result.database] = []\n                databases[result.database].append(result)\n\n            for db_name, db_results in databases.items():\n                report += f\"### {db_name}\\n\\n\"\n\n                # Calculate statistics\n                durations = [r.duration_seconds for r in db_results]\n                throughputs = [r.records_per_second for r in db_results]\n                memory_usage = [r.memory_usage_mb for r in db_results]\n                cpu_usage = [r.cpu_usage_percent for r in db_results]\n\n                report += f\"- **Average Duration**: {statistics.mean(durations):.4f}s\\n\"\n                report += f\"- **Average Throughput**: {statistics.mean(throughputs):.2f} records/s\\n\"\n                report += f\"- **Average Memory Usage**: {statistics.mean(memory_usage):.2f} MB\\n\"\n                report += f\"- **Average CPU Usage**: {statistics.mean(cpu_usage):.2f}%\\n\\n\"\n\n        return report\n</code></pre>"},{"location":"11_database_exploration/#success-criteria","title":"Success Criteria","text":""},{"location":"11_database_exploration/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Multiple Database Support - Connect to at least 3 different databases</li> <li> Data Synchronization - Keep multiple databases in sync</li> <li> Performance Benchmarking - Compare database performance</li> <li> Data Modeling - Design optimal schemas for each database</li> <li> Query Optimization - Optimize queries for each database type</li> <li> Monitoring - Track database performance and usage</li> <li> Documentation - Comprehensive documentation of findings</li> <li> Testing - Unit tests and integration tests</li> </ul>"},{"location":"11_database_exploration/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"11_database_exploration/#advanced-features","title":"Advanced Features","text":"<ul> <li> Data Pipeline - Implement ETL processes</li> <li> Real-time Sync - Stream data between databases</li> <li> Data Quality - Implement data validation and cleaning</li> <li> Backup Strategy - Implement backup and recovery</li> <li> Security - Implement proper authentication and authorization</li> <li> Scalability - Test with large datasets</li> <li> Analytics - Extract insights from your data</li> <li> Visualization - Create dashboards for monitoring</li> </ul>"},{"location":"11_database_exploration/#getting-started","title":"Getting Started","text":""},{"location":"11_database_exploration/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Set up databases - Install and configure different databases</li> <li>Implement connectors - Create database connection classes</li> <li>Design schemas - Create optimal schemas for each database</li> <li>Build sync system - Implement data synchronization</li> <li>Create benchmarks - Build performance testing framework</li> <li>Run experiments - Test different scenarios and configurations</li> <li>Analyze results - Compare performance and identify best practices</li> <li>Document findings - Create comprehensive documentation</li> </ol>"},{"location":"11_database_exploration/#dependencies","title":"Dependencies","text":""},{"location":"11_database_exploration/#requirementstxt","title":"requirements.txt","text":"<pre><code>asyncpg&gt;=0.28.0\nmotor&gt;=3.3.0\nelasticsearch&gt;=8.8.0\nredis&gt;=4.6.0\nclickhouse-connect&gt;=0.6.0\nneo4j&gt;=5.12.0\nkafka-python&gt;=2.0.2\npandas&gt;=2.0.0\nmatplotlib&gt;=3.7.0\nseaborn&gt;=0.12.0\npsutil&gt;=5.9.0\npytest&gt;=7.0.0\n</code></pre>"},{"location":"11_database_exploration/#resources","title":"Resources","text":""},{"location":"11_database_exploration/#helpful-links","title":"Helpful Links","text":"<ul> <li>PostgreSQL - https://www.postgresql.org/</li> <li>MongoDB - https://www.mongodb.com/</li> <li>Elasticsearch - https://www.elastic.co/elasticsearch/</li> <li>Redis - https://redis.io/</li> <li>ClickHouse - https://clickhouse.com/</li> <li>Neo4j - https://neo4j.com/</li> <li>Apache Kafka - https://kafka.apache.org/</li> </ul>"},{"location":"11_database_exploration/#lets-explore-databases","title":"Let's Explore Databases!","text":""},{"location":"11_database_exploration/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - Different database types and their use cases - Data modeling and schema design - Performance optimization and benchmarking - Data synchronization and ETL processes - Database monitoring and maintenance - Best practices for database selection</p> <p>Start with one database and build up to a comprehensive multi-database system!</p>"},{"location":"11_database_exploration/#next-steps","title":"Next Steps","text":""},{"location":"11_database_exploration/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Deploy your system - Set up production databases</li> <li>Monitor performance - Track database performance in production</li> <li>Share your findings - Document your database comparison results</li> <li>Contribute to open source - Share your database connectors</li> <li>Move to the next track - Try machine learning pipelines or data visualization next!</li> </ol> <p>Happy database exploring! \ud83d\ude80</p>"},{"location":"12_ml_pipeline/","title":"ML Pipeline","text":""},{"location":"12_ml_pipeline/#machine-learning-pipeline-assignment","title":"Machine Learning Pipeline Assignment","text":""},{"location":"12_ml_pipeline/#end-to-end-ml-for-data-processing","title":"End-to-End ML for Data Processing","text":"<p>Build comprehensive ML pipelines for data analysis and insights</p>"},{"location":"12_ml_pipeline/#assignment-overview","title":"Assignment Overview","text":""},{"location":"12_ml_pipeline/#what-youll-build","title":"What You'll Build","text":"<p>A comprehensive machine learning pipeline system that: - Data preprocessing - Clean, transform, and prepare data for ML - Feature engineering - Create meaningful features from raw data - Model training - Train multiple ML models for different tasks - Model evaluation - Comprehensive evaluation and validation - Model deployment - Serve models via API endpoints - Monitoring - Track model performance and data drift</p>"},{"location":"12_ml_pipeline/#problem-statement","title":"Problem Statement","text":""},{"location":"12_ml_pipeline/#ml-pipeline-challenges","title":"ML Pipeline Challenges","text":"<p>Real-world ML applications face several challenges: - Data quality - Raw data is often messy and incomplete - Feature engineering - Creating meaningful features from raw data - Model selection - Choosing the right algorithm for the task - Evaluation - Properly evaluating model performance - Deployment - Serving models in production environments - Monitoring - Tracking model performance over time</p>"},{"location":"12_ml_pipeline/#your-solution","title":"Your Solution","text":""},{"location":"12_ml_pipeline/#end-to-end-ml-pipeline","title":"End-to-End ML Pipeline","text":"<p>Create a comprehensive ML pipeline that addresses these challenges:</p> <ol> <li>Data Pipeline - Automated data processing and validation</li> <li>Feature Engineering - Automated feature creation and selection</li> <li>Model Training - Automated model training and hyperparameter tuning</li> <li>Model Evaluation - Comprehensive evaluation and validation</li> <li>Model Deployment - API endpoints for model serving</li> <li>Monitoring - Real-time monitoring and alerting</li> </ol>"},{"location":"12_ml_pipeline/#technical-requirements","title":"Technical Requirements","text":""},{"location":"12_ml_pipeline/#tech-stack","title":"Tech Stack","text":"<ul> <li>Python 3.8+ with type hints</li> <li>Pandas &amp; NumPy - Data manipulation</li> <li>Scikit-learn - Machine learning algorithms</li> <li>XGBoost - Gradient boosting</li> <li>TensorFlow/PyTorch - Deep learning</li> <li>MLflow - Model management and tracking</li> <li>FastAPI - Model serving API</li> <li>Docker - Containerization</li> </ul>"},{"location":"12_ml_pipeline/#project-structure","title":"Project Structure","text":""},{"location":"12_ml_pipeline/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>ml_pipeline/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u251c\u2500\u2500 ingestion.py\n\u2502   \u2502   \u251c\u2500\u2500 preprocessing.py\n\u2502   \u2502   \u2514\u2500\u2500 validation.py\n\u2502   \u251c\u2500\u2500 features/\n\u2502   \u2502   \u251c\u2500\u2500 engineering.py\n\u2502   \u2502   \u251c\u2500\u2500 selection.py\n\u2502   \u2502   \u2514\u2500\u2500 transformation.py\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u251c\u2500\u2500 training.py\n\u2502   \u2502   \u251c\u2500\u2500 evaluation.py\n\u2502   \u2502   \u2514\u2500\u2500 deployment.py\n\u2502   \u251c\u2500\u2500 pipelines/\n\u2502   \u2502   \u251c\u2500\u2500 training_pipeline.py\n\u2502   \u2502   \u251c\u2500\u2500 inference_pipeline.py\n\u2502   \u2502   \u2514\u2500\u2500 monitoring_pipeline.py\n\u2502   \u2514\u2500\u2500 api/\n\u2502       \u251c\u2500\u2500 endpoints.py\n\u2502       \u2514\u2500\u2500 middleware.py\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 model_config.yaml\n\u2502   \u2514\u2500\u2500 pipeline_config.yaml\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 trained_models/\n\u2502   \u2514\u2500\u2500 model_artifacts/\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/\n\u2502   \u251c\u2500\u2500 processed/\n\u2502   \u2514\u2500\u2500 features/\n\u2514\u2500\u2500 tests/\n    \u251c\u2500\u2500 test_data.py\n    \u2514\u2500\u2500 test_models.py\n</code></pre>"},{"location":"12_ml_pipeline/#core-components","title":"Core Components","text":""},{"location":"12_ml_pipeline/#1-data-preprocessing","title":"1. Data Preprocessing","text":"<pre><code># src/data/preprocessing.py\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, List, Optional\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport logging\n\nclass DataPreprocessor:\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.scalers = {}\n        self.encoders = {}\n        self.imputers = {}\n        self.logger = logging.getLogger(__name__)\n\n    def preprocess(self, data: pd.DataFrame, \n                  target_column: Optional[str] = None) -&gt; pd.DataFrame:\n        \"\"\"Main preprocessing pipeline\"\"\"\n        self.logger.info(\"Starting data preprocessing\")\n\n        # Create a copy to avoid modifying original data\n        processed_data = data.copy()\n\n        # Handle missing values\n        processed_data = self._handle_missing_values(processed_data)\n\n        # Handle outliers\n        processed_data = self._handle_outliers(processed_data)\n\n        # Encode categorical variables\n        processed_data = self._encode_categorical(processed_data)\n\n        # Scale numerical variables\n        processed_data = self._scale_numerical(processed_data)\n\n        # Feature selection\n        if target_column and target_column in processed_data.columns:\n            processed_data = self._select_features(processed_data, target_column)\n\n        self.logger.info(\"Data preprocessing completed\")\n        return processed_data\n\n    def _handle_missing_values(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Handle missing values in the dataset\"\"\"\n        self.logger.info(\"Handling missing values\")\n\n        for column in data.columns:\n            if data[column].isnull().any():\n                missing_count = data[column].isnull().sum()\n                missing_percent = (missing_count / len(data)) * 100\n\n                self.logger.info(f\"Column {column}: {missing_count} missing values ({missing_percent:.2f}%)\")\n\n                if missing_percent &gt; 50:\n                    # Drop columns with more than 50% missing values\n                    data = data.drop(columns=[column])\n                    self.logger.info(f\"Dropped column {column} due to high missing value percentage\")\n                elif data[column].dtype in ['object', 'category']:\n                    # Use mode for categorical variables\n                    mode_value = data[column].mode()[0] if not data[column].mode().empty else 'Unknown'\n                    data[column] = data[column].fillna(mode_value)\n                else:\n                    # Use KNN imputation for numerical variables\n                    if column not in self.imputers:\n                        self.imputers[column] = KNNImputer(n_neighbors=5)\n                        data[column] = self.imputers[column].fit_transform(data[[column]]).flatten()\n                    else:\n                        data[column] = self.imputers[column].transform(data[[column]]).flatten()\n\n        return data\n\n    def _handle_outliers(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Handle outliers using IQR method\"\"\"\n        self.logger.info(\"Handling outliers\")\n\n        for column in data.select_dtypes(include=[np.number]).columns:\n            Q1 = data[column].quantile(0.25)\n            Q3 = data[column].quantile(0.75)\n            IQR = Q3 - Q1\n\n            lower_bound = Q1 - 1.5 * IQR\n            upper_bound = Q3 + 1.5 * IQR\n\n            outliers = (data[column] &lt; lower_bound) | (data[column] &gt; upper_bound)\n            outlier_count = outliers.sum()\n\n            if outlier_count &gt; 0:\n                self.logger.info(f\"Column {column}: {outlier_count} outliers detected\")\n\n                # Cap outliers instead of removing them\n                data[column] = np.where(data[column] &lt; lower_bound, lower_bound, data[column])\n                data[column] = np.where(data[column] &gt; upper_bound, upper_bound, data[column])\n\n        return data\n\n    def _encode_categorical(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Encode categorical variables\"\"\"\n        self.logger.info(\"Encoding categorical variables\")\n\n        for column in data.select_dtypes(include=['object', 'category']).columns:\n            unique_values = data[column].nunique()\n\n            if unique_values &lt;= 10:\n                # Use label encoding for low cardinality\n                if column not in self.encoders:\n                    self.encoders[column] = LabelEncoder()\n                    data[column] = self.encoders[column].fit_transform(data[column])\n                else:\n                    data[column] = self.encoders[column].transform(data[column])\n            else:\n                # Use one-hot encoding for high cardinality\n                if column not in self.encoders:\n                    self.encoders[column] = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n                    encoded_data = self.encoders[column].fit_transform(data[[column]])\n                    encoded_df = pd.DataFrame(encoded_data, columns=[f\"{column}_{i}\" for i in range(encoded_data.shape[1])])\n                    data = pd.concat([data.drop(columns=[column]), encoded_df], axis=1)\n                else:\n                    encoded_data = self.encoders[column].transform(data[[column]])\n                    encoded_df = pd.DataFrame(encoded_data, columns=[f\"{column}_{i}\" for i in range(encoded_data.shape[1])])\n                    data = pd.concat([data.drop(columns=[column]), encoded_df], axis=1)\n\n        return data\n\n    def _scale_numerical(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Scale numerical variables\"\"\"\n        self.logger.info(\"Scaling numerical variables\")\n\n        numerical_columns = data.select_dtypes(include=[np.number]).columns\n\n        for column in numerical_columns:\n            if column not in self.scalers:\n                self.scalers[column] = StandardScaler()\n                data[column] = self.scalers[column].fit_transform(data[[column]]).flatten()\n            else:\n                data[column] = self.scalers[column].transform(data[[column]]).flatten()\n\n        return data\n\n    def _select_features(self, data: pd.DataFrame, target_column: str) -&gt; pd.DataFrame:\n        \"\"\"Select the most important features\"\"\"\n        self.logger.info(\"Selecting features\")\n\n        X = data.drop(columns=[target_column])\n        y = data[target_column]\n\n        # Select top k features\n        k = min(50, X.shape[1])  # Select top 50 features or all if less than 50\n        selector = SelectKBest(score_func=f_classif, k=k)\n        X_selected = selector.fit_transform(X, y)\n\n        # Get selected feature names\n        selected_features = X.columns[selector.get_support()].tolist()\n\n        # Create new dataframe with selected features\n        selected_data = pd.DataFrame(X_selected, columns=selected_features)\n        selected_data[target_column] = y\n\n        self.logger.info(f\"Selected {len(selected_features)} features out of {X.shape[1]}\")\n\n        return selected_data\n</code></pre>"},{"location":"12_ml_pipeline/#core-components_1","title":"Core Components","text":""},{"location":"12_ml_pipeline/#2-feature-engineering","title":"2. Feature Engineering","text":"<pre><code># src/features/engineering.py\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, List, Optional\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport re\nfrom datetime import datetime\n\nclass FeatureEngineer:\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.vectorizers = {}\n        self.pca_models = {}\n        self.cluster_models = {}\n\n    def engineer_features(self, data: pd.DataFrame, \n                         target_column: Optional[str] = None) -&gt; pd.DataFrame:\n        \"\"\"Main feature engineering pipeline\"\"\"\n        print(\"Starting feature engineering\")\n\n        # Create a copy to avoid modifying original data\n        engineered_data = data.copy()\n\n        # Text features\n        engineered_data = self._create_text_features(engineered_data)\n\n        # Temporal features\n        engineered_data = self._create_temporal_features(engineered_data)\n\n        # Numerical features\n        engineered_data = self._create_numerical_features(engineered_data)\n\n        # Categorical features\n        engineered_data = self._create_categorical_features(engineered_data)\n\n        # Interaction features\n        engineered_data = self._create_interaction_features(engineered_data)\n\n        # Dimensionality reduction\n        if target_column and target_column in engineered_data.columns:\n            engineered_data = self._apply_dimensionality_reduction(engineered_data, target_column)\n\n        print(\"Feature engineering completed\")\n        return engineered_data\n\n    def _create_text_features(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Create features from text columns\"\"\"\n        text_columns = data.select_dtypes(include=['object']).columns\n\n        for column in text_columns:\n            if data[column].dtype == 'object':\n                # Basic text features\n                data[f'{column}_length'] = data[column].astype(str).str.len()\n                data[f'{column}_word_count'] = data[column].astype(str).str.split().str.len()\n                data[f'{column}_char_count'] = data[column].astype(str).str.replace(' ', '').str.len()\n\n                # TF-IDF features\n                if column not in self.vectorizers:\n                    self.vectorizers[column] = TfidfVectorizer(max_features=100, stop_words='english')\n                    tfidf_matrix = self.vectorizers[column].fit_transform(data[column].astype(str))\n                else:\n                    tfidf_matrix = self.vectorizers[column].transform(data[column].astype(str])\n\n                # Add TF-IDF features\n                tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), \n                                      columns=[f'{column}_tfidf_{i}' for i in range(tfidf_matrix.shape[1])])\n                data = pd.concat([data, tfidf_df], axis=1)\n\n        return data\n\n    def _create_temporal_features(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Create features from temporal columns\"\"\"\n        temporal_columns = data.select_dtypes(include=['datetime64']).columns\n\n        for column in temporal_columns:\n            if data[column].dtype == 'datetime64[ns]':\n                # Extract temporal components\n                data[f'{column}_year'] = data[column].dt.year\n                data[f'{column}_month'] = data[column].dt.month\n                data[f'{column}_day'] = data[column].dt.day\n                data[f'{column}_weekday'] = data[column].dt.weekday\n                data[f'{column}_hour'] = data[column].dt.hour\n\n                # Calculate time differences\n                if len(data) &gt; 1:\n                    data[f'{column}_days_since_first'] = (data[column] - data[column].min()).dt.days\n                    data[f'{column}_days_since_last'] = (data[column].max() - data[column]).dt.days\n\n                # Cyclical encoding\n                data[f'{column}_month_sin'] = np.sin(2 * np.pi * data[column].dt.month / 12)\n                data[f'{column}_month_cos'] = np.cos(2 * np.pi * data[column].dt.month / 12)\n                data[f'{column}_day_sin'] = np.sin(2 * np.pi * data[column].dt.day / 31)\n                data[f'{column}_day_cos'] = np.cos(2 * np.pi * data[column].dt.day / 31)\n\n        return data\n\n    def _create_numerical_features(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Create features from numerical columns\"\"\"\n        numerical_columns = data.select_dtypes(include=[np.number]).columns\n\n        for column in numerical_columns:\n            # Statistical features\n            data[f'{column}_log'] = np.log1p(data[column])\n            data[f'{column}_sqrt'] = np.sqrt(data[column])\n            data[f'{column}_square'] = data[column] ** 2\n\n            # Rolling statistics\n            if len(data) &gt; 10:\n                data[f'{column}_rolling_mean_5'] = data[column].rolling(window=5).mean()\n                data[f'{column}_rolling_std_5'] = data[column].rolling(window=5).std()\n                data[f'{column}_rolling_mean_10'] = data[column].rolling(window=10).mean()\n                data[f'{column}_rolling_std_10'] = data[column].rolling(window=10).std()\n\n            # Percentile features\n            data[f'{column}_percentile_25'] = data[column].quantile(0.25)\n            data[f'{column}_percentile_75'] = data[column].quantile(0.75)\n            data[f'{column}_iqr'] = data[f'{column}_percentile_75'] - data[f'{column}_percentile_25']\n\n        return data\n\n    def _create_categorical_features(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Create features from categorical columns\"\"\"\n        categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n\n        for column in categorical_columns:\n            # Frequency encoding\n            freq_map = data[column].value_counts().to_dict()\n            data[f'{column}_freq'] = data[column].map(freq_map)\n\n            # Target encoding (if target column is available)\n            if 'target' in data.columns:\n                target_mean = data.groupby(column)['target'].mean()\n                data[f'{column}_target_mean'] = data[column].map(target_mean)\n\n        return data\n\n    def _create_interaction_features(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Create interaction features between columns\"\"\"\n        numerical_columns = data.select_dtypes(include=[np.number]).columns\n\n        # Create pairwise interactions for top numerical columns\n        top_columns = numerical_columns[:5]  # Limit to top 5 columns to avoid explosion\n\n        for i, col1 in enumerate(top_columns):\n            for col2 in top_columns[i+1:]:\n                # Multiplication\n                data[f'{col1}_x_{col2}'] = data[col1] * data[col2]\n\n                # Division (avoid division by zero)\n                data[f'{col1}_div_{col2}'] = np.where(data[col2] != 0, data[col1] / data[col2], 0)\n\n                # Addition\n                data[f'{col1}_plus_{col2}'] = data[col1] + data[col2]\n\n                # Subtraction\n                data[f'{col1}_minus_{col2}'] = data[col1] - data[col2]\n\n        return data\n\n    def _apply_dimensionality_reduction(self, data: pd.DataFrame, target_column: str) -&gt; pd.DataFrame:\n        \"\"\"Apply dimensionality reduction techniques\"\"\"\n        X = data.drop(columns=[target_column])\n        y = data[target_column]\n\n        # PCA\n        if X.shape[1] &gt; 50:\n            n_components = min(50, X.shape[1])\n            pca = PCA(n_components=n_components)\n            X_pca = pca.fit_transform(X)\n\n            # Create PCA features\n            pca_df = pd.DataFrame(X_pca, columns=[f'pca_{i}' for i in range(n_components)])\n            data = pd.concat([data, pca_df], axis=1)\n\n        # Clustering\n        if X.shape[1] &gt; 10:\n            n_clusters = min(10, X.shape[0] // 10)\n            if n_clusters &gt; 1:\n                kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n                clusters = kmeans.fit_predict(X)\n                data['cluster'] = clusters\n\n        return data\n</code></pre>"},{"location":"12_ml_pipeline/#core-components_2","title":"Core Components","text":""},{"location":"12_ml_pipeline/#3-model-training","title":"3. Model Training","text":"<pre><code># src/models/training.py\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, List, Optional, Tuple\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nimport xgboost as xgb\nimport joblib\nimport mlflow\nimport mlflow.sklearn\nfrom datetime import datetime\n\nclass ModelTrainer:\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.models = {}\n        self.best_model = None\n        self.best_score = 0\n        self.training_history = []\n\n    def train_models(self, X: pd.DataFrame, y: pd.Series, \n                    test_size: float = 0.2) -&gt; Dict[str, Any]:\n        \"\"\"Train multiple models and select the best one\"\"\"\n        print(\"Starting model training\")\n\n        # Split data\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, test_size=test_size, random_state=42, stratify=y\n        )\n\n        # Define models to train\n        models = {\n            'logistic_regression': LogisticRegression(random_state=42),\n            'random_forest': RandomForestClassifier(random_state=42),\n            'gradient_boosting': GradientBoostingClassifier(random_state=42),\n            'svm': SVC(random_state=42, probability=True),\n            'xgboost': xgb.XGBClassifier(random_state=42)\n        }\n\n        # Train and evaluate each model\n        results = {}\n        for name, model in models.items():\n            print(f\"Training {name}...\")\n\n            # Train model\n            model.fit(X_train, y_train)\n\n            # Evaluate model\n            train_score = model.score(X_train, y_train)\n            test_score = model.score(X_test, y_test)\n\n            # Cross-validation score\n            cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n\n            # Predictions\n            y_pred = model.predict(X_test)\n            y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n\n            # Calculate metrics\n            auc_score = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 0\n\n            # Store results\n            results[name] = {\n                'model': model,\n                'train_score': train_score,\n                'test_score': test_score,\n                'cv_mean': cv_scores.mean(),\n                'cv_std': cv_scores.std(),\n                'auc_score': auc_score,\n                'predictions': y_pred,\n                'probabilities': y_pred_proba\n            }\n\n            # Update best model\n            if test_score &gt; self.best_score:\n                self.best_score = test_score\n                self.best_model = model\n                self.best_model_name = name\n\n            print(f\"{name} - Test Score: {test_score:.4f}, CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n\n        # Hyperparameter tuning for best model\n        if self.best_model_name in ['random_forest', 'gradient_boosting', 'xgboost']:\n            print(f\"Performing hyperparameter tuning for {self.best_model_name}...\")\n            tuned_model = self._hyperparameter_tuning(\n                self.best_model_name, X_train, y_train, X_test, y_test\n            )\n            if tuned_model is not None:\n                results[f'{self.best_model_name}_tuned'] = tuned_model\n                self.best_model = tuned_model['model']\n                self.best_model_name = f'{self.best_model_name}_tuned'\n\n        # Log to MLflow\n        self._log_to_mlflow(results, X_test, y_test)\n\n        print(f\"Best model: {self.best_model_name} with score: {self.best_score:.4f}\")\n        return results\n\n    def _hyperparameter_tuning(self, model_name: str, X_train: pd.DataFrame, \n                              y_train: pd.Series, X_test: pd.DataFrame, \n                              y_test: pd.Series) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Perform hyperparameter tuning for the best model\"\"\"\n        param_grids = {\n            'random_forest': {\n                'n_estimators': [100, 200, 300],\n                'max_depth': [10, 20, None],\n                'min_samples_split': [2, 5, 10],\n                'min_samples_leaf': [1, 2, 4]\n            },\n            'gradient_boosting': {\n                'n_estimators': [100, 200, 300],\n                'learning_rate': [0.01, 0.1, 0.2],\n                'max_depth': [3, 5, 7],\n                'subsample': [0.8, 0.9, 1.0]\n            },\n            'xgboost': {\n                'n_estimators': [100, 200, 300],\n                'learning_rate': [0.01, 0.1, 0.2],\n                'max_depth': [3, 5, 7],\n                'subsample': [0.8, 0.9, 1.0]\n            }\n        }\n\n        if model_name not in param_grids:\n            return None\n\n        # Get base model\n        base_models = {\n            'random_forest': RandomForestClassifier(random_state=42),\n            'gradient_boosting': GradientBoostingClassifier(random_state=42),\n            'xgboost': xgb.XGBClassifier(random_state=42)\n        }\n\n        base_model = base_models[model_name]\n        param_grid = param_grids[model_name]\n\n        # Grid search\n        grid_search = GridSearchCV(\n            base_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1\n        )\n        grid_search.fit(X_train, y_train)\n\n        # Get best model\n        best_model = grid_search.best_estimator_\n        best_params = grid_search.best_params_\n        best_score = grid_search.best_score_\n\n        # Evaluate on test set\n        test_score = best_model.score(X_test, y_test)\n        y_pred = best_model.predict(X_test)\n        y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n        auc_score = roc_auc_score(y_test, y_pred_proba)\n\n        return {\n            'model': best_model,\n            'best_params': best_params,\n            'best_score': best_score,\n            'test_score': test_score,\n            'auc_score': auc_score,\n            'predictions': y_pred,\n            'probabilities': y_pred_proba\n        }\n\n    def _log_to_mlflow(self, results: Dict[str, Any], X_test: pd.DataFrame, \n                      y_test: pd.Series) -&gt; None:\n        \"\"\"Log training results to MLflow\"\"\"\n        with mlflow.start_run():\n            # Log parameters\n            mlflow.log_param(\"test_size\", 0.2)\n            mlflow.log_param(\"random_state\", 42)\n\n            # Log metrics for each model\n            for name, result in results.items():\n                mlflow.log_metric(f\"{name}_test_score\", result['test_score'])\n                mlflow.log_metric(f\"{name}_auc_score\", result['auc_score'])\n\n            # Log best model\n            if self.best_model is not None:\n                mlflow.sklearn.log_model(self.best_model, \"model\")\n\n                # Log model performance\n                y_pred = self.best_model.predict(X_test)\n                y_pred_proba = self.best_model.predict_proba(X_test)[:, 1]\n\n                # Classification report\n                report = classification_report(y_test, y_pred, output_dict=True)\n                for metric, value in report.items():\n                    if isinstance(value, dict):\n                        for sub_metric, sub_value in value.items():\n                            mlflow.log_metric(f\"{metric}_{sub_metric}\", sub_value)\n                    else:\n                        mlflow.log_metric(metric, value)\n\n    def save_model(self, filepath: str) -&gt; None:\n        \"\"\"Save the best model to disk\"\"\"\n        if self.best_model is not None:\n            joblib.dump(self.best_model, filepath)\n            print(f\"Model saved to {filepath}\")\n        else:\n            print(\"No model to save\")\n\n    def load_model(self, filepath: str) -&gt; None:\n        \"\"\"Load a model from disk\"\"\"\n        self.best_model = joblib.load(filepath)\n        print(f\"Model loaded from {filepath}\")\n</code></pre>"},{"location":"12_ml_pipeline/#core-components_3","title":"Core Components","text":""},{"location":"12_ml_pipeline/#4-model-deployment","title":"4. Model Deployment","text":"<pre><code># src/api/endpoints.py\nfrom fastapi import FastAPI, HTTPException, Depends\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List, Optional\nimport pandas as pd\nimport numpy as np\nimport joblib\nimport logging\n\n# Initialize FastAPI app\napp = FastAPI(title=\"ML Pipeline API\", version=\"1.0.0\")\n\n# Global model storage\nmodels = {}\nmodel_metadata = {}\n\nclass PredictionRequest(BaseModel):\n    features: Dict[str, Any]\n    model_name: Optional[str] = None\n\nclass PredictionResponse(BaseModel):\n    prediction: Any\n    probability: Optional[float] = None\n    model_name: str\n    confidence: Optional[float] = None\n\nclass ModelInfo(BaseModel):\n    name: str\n    accuracy: float\n    auc_score: float\n    features: List[str]\n    created_at: str\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    \"\"\"Load models on startup\"\"\"\n    # Load pre-trained models\n    # This would typically load from a model registry or file system\n    pass\n\n@app.post(\"/predict\", response_model=PredictionResponse)\nasync def predict(request: PredictionRequest):\n    \"\"\"Make a prediction using the specified model\"\"\"\n    try:\n        # Get model name\n        model_name = request.model_name or \"best_model\"\n\n        if model_name not in models:\n            raise HTTPException(status_code=404, detail=f\"Model {model_name} not found\")\n\n        model = models[model_name]\n\n        # Convert features to DataFrame\n        features_df = pd.DataFrame([request.features])\n\n        # Make prediction\n        prediction = model.predict(features_df)[0]\n\n        # Get probability if available\n        probability = None\n        if hasattr(model, 'predict_proba'):\n            proba = model.predict_proba(features_df)[0]\n            probability = float(max(proba))\n\n        # Calculate confidence\n        confidence = probability if probability else 0.5\n\n        return PredictionResponse(\n            prediction=prediction,\n            probability=probability,\n            model_name=model_name,\n            confidence=confidence\n        )\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/predict_batch\", response_model=List[PredictionResponse])\nasync def predict_batch(requests: List[PredictionRequest]):\n    \"\"\"Make predictions for multiple samples\"\"\"\n    try:\n        results = []\n\n        for request in requests:\n            # Get model name\n            model_name = request.model_name or \"best_model\"\n\n            if model_name not in models:\n                raise HTTPException(status_code=404, detail=f\"Model {model_name} not found\")\n\n            model = models[model_name]\n\n            # Convert features to DataFrame\n            features_df = pd.DataFrame([request.features])\n\n            # Make prediction\n            prediction = model.predict(features_df)[0]\n\n            # Get probability if available\n            probability = None\n            if hasattr(model, 'predict_proba'):\n                proba = model.predict_proba(features_df)[0]\n                probability = float(max(proba))\n\n            # Calculate confidence\n            confidence = probability if probability else 0.5\n\n            results.append(PredictionResponse(\n                prediction=prediction,\n                probability=probability,\n                model_name=model_name,\n                confidence=confidence\n            ))\n\n        return results\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/models\", response_model=List[ModelInfo])\nasync def list_models():\n    \"\"\"List all available models\"\"\"\n    model_list = []\n\n    for name, model in models.items():\n        if name in model_metadata:\n            metadata = model_metadata[name]\n            model_list.append(ModelInfo(\n                name=name,\n                accuracy=metadata.get('accuracy', 0.0),\n                auc_score=metadata.get('auc_score', 0.0),\n                features=metadata.get('features', []),\n                created_at=metadata.get('created_at', '')\n            ))\n\n    return model_list\n\n@app.get(\"/models/{model_name}\", response_model=ModelInfo)\nasync def get_model_info(model_name: str):\n    \"\"\"Get information about a specific model\"\"\"\n    if model_name not in models:\n        raise HTTPException(status_code=404, detail=f\"Model {model_name} not found\")\n\n    if model_name not in model_metadata:\n        raise HTTPException(status_code=404, detail=f\"Metadata for model {model_name} not found\")\n\n    metadata = model_metadata[model_name]\n    return ModelInfo(\n        name=model_name,\n        accuracy=metadata.get('accuracy', 0.0),\n        auc_score=metadata.get('auc_score', 0.0),\n        features=metadata.get('features', []),\n        created_at=metadata.get('created_at', '')\n    )\n\n@app.post(\"/models/{model_name}/load\")\nasync def load_model(model_name: str, filepath: str):\n    \"\"\"Load a model from disk\"\"\"\n    try:\n        model = joblib.load(filepath)\n        models[model_name] = model\n\n        # Load metadata if available\n        metadata_file = filepath.replace('.pkl', '_metadata.json')\n        if os.path.exists(metadata_file):\n            import json\n            with open(metadata_file, 'r') as f:\n                model_metadata[model_name] = json.load(f)\n\n        return {\"message\": f\"Model {model_name} loaded successfully\"}\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint\"\"\"\n    return {\"status\": \"healthy\", \"models_loaded\": len(models)}\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"12_ml_pipeline/#success-criteria","title":"Success Criteria","text":""},{"location":"12_ml_pipeline/#must-have-features","title":"Must-Have Features","text":"<ul> <li> Data Preprocessing - Automated data cleaning and transformation</li> <li> Feature Engineering - Automated feature creation and selection</li> <li> Model Training - Multiple ML algorithms with hyperparameter tuning</li> <li> Model Evaluation - Comprehensive evaluation and validation</li> <li> Model Deployment - API endpoints for model serving</li> <li> Model Management - Model versioning and tracking</li> <li> Monitoring - Model performance monitoring</li> <li> Documentation - Comprehensive documentation and examples</li> </ul>"},{"location":"12_ml_pipeline/#bonus-challenges","title":"Bonus Challenges","text":""},{"location":"12_ml_pipeline/#advanced-features","title":"Advanced Features","text":"<ul> <li> AutoML - Automated model selection and hyperparameter tuning</li> <li> Model Ensembling - Combine multiple models for better performance</li> <li> Online Learning - Update models with new data</li> <li> A/B Testing - Compare different models in production</li> <li> Model Explainability - Explain model predictions</li> <li> Data Drift Detection - Detect when data distribution changes</li> <li> Model Retraining - Automated model retraining pipeline</li> <li> Real-time Monitoring - Real-time model performance monitoring</li> </ul>"},{"location":"12_ml_pipeline/#getting-started","title":"Getting Started","text":""},{"location":"12_ml_pipeline/#setup-instructions","title":"Setup Instructions","text":"<ol> <li>Set up environment - Install required packages and dependencies</li> <li>Prepare data - Clean and prepare your dataset</li> <li>Implement preprocessing - Build data preprocessing pipeline</li> <li>Create features - Implement feature engineering</li> <li>Train models - Train multiple ML models</li> <li>Evaluate performance - Compare model performance</li> <li>Deploy models - Create API endpoints for model serving</li> <li>Monitor performance - Set up monitoring and alerting</li> </ol>"},{"location":"12_ml_pipeline/#dependencies","title":"Dependencies","text":""},{"location":"12_ml_pipeline/#requirementstxt","title":"requirements.txt","text":"<pre><code>pandas&gt;=2.0.0\nnumpy&gt;=1.24.0\nscikit-learn&gt;=1.3.0\nxgboost&gt;=1.7.0\ntensorflow&gt;=2.13.0\nmlflow&gt;=2.5.0\nfastapi&gt;=0.100.0\nuvicorn&gt;=0.23.0\npydantic&gt;=2.0.0\njoblib&gt;=1.3.0\nmatplotlib&gt;=3.7.0\nseaborn&gt;=0.12.0\nplotly&gt;=5.15.0\npytest&gt;=7.0.0\n</code></pre>"},{"location":"12_ml_pipeline/#resources","title":"Resources","text":""},{"location":"12_ml_pipeline/#helpful-links","title":"Helpful Links","text":"<ul> <li>Scikit-learn - https://scikit-learn.org/</li> <li>XGBoost - https://xgboost.readthedocs.io/</li> <li>MLflow - https://mlflow.org/</li> <li>FastAPI - https://fastapi.tiangolo.com/</li> <li>Feature Engineering - https://www.featuretools.com/</li> <li>Model Deployment - https://mlflow.org/docs/latest/models.html</li> </ul>"},{"location":"12_ml_pipeline/#lets-build-ml-pipelines","title":"Let's Build ML Pipelines!","text":""},{"location":"12_ml_pipeline/#ready-to-start","title":"Ready to Start?","text":"<p>This assignment will teach you: - End-to-end ML pipeline development - Data preprocessing and feature engineering - Model training and evaluation - Model deployment and serving - ML model management and monitoring - Best practices for production ML systems</p> <p>Start with basic preprocessing and build up to a comprehensive ML pipeline!</p>"},{"location":"12_ml_pipeline/#next-steps","title":"Next Steps","text":""},{"location":"12_ml_pipeline/#after-completing-this-assignment","title":"After Completing This Assignment","text":"<ol> <li>Deploy your models - Set up production model serving</li> <li>Monitor performance - Track model performance in production</li> <li>Share your work - Document your ML pipeline and results</li> <li>Contribute to open source - Share your ML pipeline components</li> <li>Move to the next track - Try data visualization or advanced analytics next!</li> </ol> <p>Happy ML pipeline building! \ud83d\ude80</p>"}]}