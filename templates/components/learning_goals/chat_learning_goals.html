<!-- Chat Learning Goals Component -->
<div class="bg-white/10 backdrop-blur-sm rounded-2xl p-6">
    <div class="flex items-center justify-between cursor-pointer" 
         @click="showLearningGoals = !showLearningGoals"
         class="hover:bg-white/5 transition-colors rounded-lg p-4">
        <div class="flex items-center space-x-3">
            <div class="w-12 h-12 bg-white/20 rounded-full flex items-center justify-center">
                <svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.746 0 3.332.477 4.5 1.253v13C19.832 18.477 18.246 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"></path>
                </svg>
            </div>
            <div>
                <h2 class="text-2xl font-bold text-white">Learning Objectives</h2>
                <p class="text-blue-100">Click to explore the technical concepts behind this AI chat application</p>
            </div>
        </div>
        <div class="transform transition-transform duration-200" 
             :class="{'rotate-180': showLearningGoals}">
            <svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
            </svg>
        </div>
    </div>
    
    <!-- Learning Goals Content -->
    <div x-show="showLearningGoals" 
         x-transition:enter="transition ease-out duration-300"
         x-transition:enter-start="opacity-0 transform -translate-y-4"
         x-transition:enter-end="opacity-100 transform translate-y-0"
         x-transition:leave="transition ease-in duration-200"
         x-transition:leave-start="opacity-100 transform translate-y-0"
         x-transition:leave-end="opacity-0 transform -translate-y-4"
         class="mt-6 space-y-6">
        
        <!-- Internet Search Integration -->
        <div class="bg-white/5 rounded-xl p-6 border border-white/10">
            <div class="flex items-start space-x-4">
                <div class="w-12 h-12 bg-green-500/20 rounded-lg flex items-center justify-center flex-shrink-0">
                    <svg class="w-6 h-6 text-green-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path>
                    </svg>
                </div>
                <div class="flex-1">
                    <h3 class="text-xl font-bold text-white mb-3">Internet Search Integration with Tavily</h3>
                    <div class="space-y-3 text-blue-100">
                        <p><strong class="text-white">Problem with Traditional Web Search:</strong> Standard web search APIs return raw HTML, require complex parsing, and often provide irrelevant results that confuse LLMs.</p>
                        <p><strong class="text-white">Tavily Solution:</strong> Tavily provides structured, LLM-optimized search results with clean content extraction, relevance scoring, and direct answers.</p>
                        <p><strong class="text-white">Smart Triggering:</strong> This app automatically detects when users ask about current events using keywords like "latest", "current", "2024", "news", "price", "weather", etc.</p>
                        <div class="bg-white/10 rounded-lg p-4 mt-4">
                            <p class="text-sm font-mono text-green-300">ðŸ’¡ <strong>Technical Implementation:</strong> The system uses keyword detection in <code>WebSearchService.should_search()</code> and formats results for LLM context using <code>format_search_results_for_llm()</code>.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Streaming Responses -->
        <div class="bg-white/5 rounded-xl p-6 border border-white/10">
            <div class="flex items-start space-x-4">
                <div class="w-12 h-12 bg-blue-500/20 rounded-lg flex items-center justify-center flex-shrink-0">
                    <svg class="w-6 h-6 text-blue-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"></path>
                    </svg>
                </div>
                <div class="flex-1">
                    <h3 class="text-xl font-bold text-white mb-3">Server-Sent Events (SSE) Streaming</h3>
                    <div class="space-y-3 text-blue-100">
                        <p><strong class="text-white">Why Streaming?</strong> Instead of waiting for complete responses, streaming provides real-time feedback, making the chat feel more interactive and responsive.</p>
                        <p><strong class="text-white">Technical Benefits:</strong> Users see responses as they're generated, reducing perceived latency and improving user experience.</p>
                        <p><strong class="text-white">Implementation:</strong> Uses FastAPI's <code>EventSourceResponse</code> with OpenRouter's streaming API to send chunks as they arrive.</p>
                        <div class="bg-white/10 rounded-lg p-4 mt-4">
                            <p class="text-sm font-mono text-blue-300">ðŸ’¡ <strong>Code Flow:</strong> <code>chat_with_llama_stream()</code> â†’ <code>EventSourceResponse</code> â†’ Frontend processes <code>data: </code> events â†’ Real-time UI updates</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Chat History & Context Management -->
        <div class="bg-white/5 rounded-xl p-6 border border-white/10">
            <div class="flex items-start space-x-4">
                <div class="w-12 h-12 bg-purple-500/20 rounded-lg flex items-center justify-center flex-shrink-0">
                    <svg class="w-6 h-6 text-purple-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z"></path>
                    </svg>
                </div>
                <div class="flex-1">
                    <h3 class="text-xl font-bold text-white mb-3">Chat History & Context Management</h3>
                    <div class="space-y-3 text-blue-100">
                        <p><strong class="text-white">Context Window:</strong> This app sends the last <strong>20 messages</strong> to the LLM for context, balancing conversation continuity with token limits.</p>
                        <p><strong class="text-white">Token Trade-offs:</strong> Llama 3.3 70B has a 128k token context window, but we limit to 20 messages to ensure fast responses and manage costs.</p>
                        <p><strong class="text-white">Smart Retrieval:</strong> Uses <code>get_conversation_context()</code> to fetch recent messages in chronological order, maintaining conversation flow.</p>
                        <div class="bg-white/10 rounded-lg p-4 mt-4">
                            <p class="text-sm font-mono text-purple-300">ðŸ’¡ <strong>Database Design:</strong> Messages stored with <code>conversation_id</code>, <code>role</code>, <code>content</code>, and <code>created_at</code> for efficient retrieval and context building.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Markdown to HTML Conversion -->
        <div class="bg-white/5 rounded-xl p-6 border border-white/10">
            <div class="flex items-start space-x-4">
                <div class="w-12 h-12 bg-orange-500/20 rounded-lg flex items-center justify-center flex-shrink-0">
                    <svg class="w-6 h-6 text-orange-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4"></path>
                    </svg>
                </div>
                <div class="flex-1">
                    <h3 class="text-xl font-bold text-white mb-3">Server-Side Markdown to HTML Conversion</h3>
                    <div class="space-y-3 text-blue-100">
                        <p><strong class="text-white">Why Server-Side?</strong> Converting markdown to HTML on the server ensures consistent formatting, security, and reduces client-side processing.</p>
                        <p><strong class="text-white">Python Markdown Library:</strong> Uses the <code>markdown</code> library with extensions for code highlighting, tables, and line breaks.</p>
                        <p><strong class="text-white">Extensions Used:</strong> <code>fenced_code</code>, <code>codehilite</code>, <code>tables</code>, <code>nl2br</code> for rich formatting support.</p>
                        <div class="bg-white/10 rounded-lg p-4 mt-4">
                            <p class="text-sm font-mono text-orange-300">ðŸ’¡ <strong>Implementation:</strong> <code>markdown.markdown(content, extensions=['fenced_code', 'codehilite', 'tables', 'nl2br'])</code> converts LLM output to display-ready HTML.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Architecture Overview -->
        <div class="bg-white/5 rounded-xl p-6 border border-white/10">
            <div class="flex items-start space-x-4">
                <div class="w-12 h-12 bg-indigo-500/20 rounded-lg flex items-center justify-center flex-shrink-0">
                    <svg class="w-6 h-6 text-indigo-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11H5m14 0a2 2 0 012 2v6a2 2 0 01-2 2H5a2 2 0 01-2-2v-6a2 2 0 012-2m14 0V9a2 2 0 00-2-2M5 11V9a2 2 0 012-2m0 0V5a2 2 0 012-2h6a2 2 0 012 2v2M7 7h10"></path>
                    </svg>
                </div>
                <div class="flex-1">
                    <h3 class="text-xl font-bold text-white mb-3">Full-Stack Architecture</h3>
                    <div class="space-y-3 text-blue-100">
                        <p><strong class="text-white">Backend:</strong> FastAPI with SQLAlchemy, async/await patterns, and OpenRouter API integration.</p>
                        <p><strong class="text-white">Frontend:</strong> Alpine.js for reactivity, Tailwind CSS for styling, and vanilla JavaScript for API calls.</p>
                        <p><strong class="text-white">Database:</strong> SQLite with conversation and message storage, supporting conversation history and context retrieval.</p>
                        <div class="bg-white/10 rounded-lg p-4 mt-4">
                            <p class="text-sm font-mono text-indigo-300">ðŸ’¡ <strong>Key Services:</strong> <code>ChatService</code>, <code>WebSearchService</code>, <code>ChatHistoryService</code>, and <code>TitleGenerationService</code> work together for a complete chat experience.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
